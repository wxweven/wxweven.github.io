<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Guava Cache使用简介]]></title>
    <url>%2F2017%2F07%2F14%2FGuava-Cache%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[1. 概述缓存是我们日常开发中是必不可少的一种解决性能问题的方法。早期缓存只应用在CPU和内存之间，现在遍布在每一个角落：内存和磁盘，磁盘和网路都存在缓存。缓存同样是做Java应用必不可少的元素。 Cache（缓存）在很广泛的场景下都是很有用的。比如，当一个值的计算或者检索的代价很大，并且在稍后的特定输入发生后，你将不止一次的需要这个值的时候，就应当考虑使用Cache了。 Cache是和ConcurrentMap很相像的东西。最本质的不同就是，ConcurrentMap持有所有被添加进的元素，直到它们专门被移除。从另一方面来说，为了使得内存的使用可控，Cache通常来说是可配置来自动回收元素的。在一些情况下，即使LoadingCache也会很有用，虽然由于他的自动缓存加载机制，它不回收元素。 注意：如果你不需要Cache的一些特性，那么ConcurrentHashMap是更加有内存效率的－－但是使用任何旧的ConcurrentMap都会很难或者几乎不可能去完成Cache所支持的一些特性。 通常，Guava Cache组件在下面的场景中适用： 你想花费一些内存来提高速度。 你预期到一些key的值将被不止一次地被查询。 你的缓存将不会需要比内存能够存储的数据更多（Guava Cache对于一个单独运行的应用来说是本地的。它们不回将数据存储在文件中或者外部服务器上。如果这不适合你的需求，那么考虑使用其它的工具，比如Memcached或者Redis）。 如果上面的这些都符合你的需要，那么Guava Cache组件将适合你！ 2. Guava Cache的使用示例使用缓存时，最常遇到的场景需要就是：“获取缓存-如果没有-则计算”,即[get-if-absent-compute]的原子语义 具体含义： 从缓存中取； 缓存中存在该数据，直接返回。 缓存中不存在该数据，从数据源中取； 数据源中存在该数据，放入缓存，并返回。 数据源中不存在该数据，返回空。 Guava Cache有两种方式实现： 一种是CacheLoader，在定义的时候就设置好缓存的源； 另一种是Callable，在调用缓存的时候指定如果缓存中没有的获取的方式。 通过这两种方式创建的cache，和通常用map来缓存的做法比，不同在于，这两种方法都实现了一种逻辑：从缓存中取key 的值，如果该值已经缓存过了，则返回缓存中的值，如果没有缓存过，可以通过某个方法来获取这个值。 但不同的在于cacheloader的定义比较宽泛，是针对整个cache定义的，可以认为是统一的根据key值load value的方法。而callable的方式较为灵活，允许你在每次get的时候自定义获取Value的方式。 2.1. 准备工作预先准备好一个MockDB类，用来模拟缓存中没有的时候在数据库中获取。12345678910public class MockDB &#123; private static Map&lt;String, String&gt; mockPersistence = new HashMap&lt;String, String&gt;() &#123;&#123; this.put("github", "codedrinker"); &#125;&#125;; public static String loadFromPersistence(String key) &#123; System.out.println("load key from persistence : " + key); return mockPersistence.get(key); &#125;&#125; 2.2. 使用CacheLoader下面是使用CacheLoader的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.wxweven.cache.guavatest;import com.google.common.cache.CacheBuilder;import com.google.common.cache.CacheLoader;import com.google.common.cache.LoadingCache;import java.util.Optional;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;/** * CacheLoader demo * * @author wxweven * @date 2017/7/13 */public class GuavaLoadingCache &#123; public static void main(String[] args) &#123; LoadingCache&lt;String, Optional&lt;String&gt;&gt; loadingCache = CacheBuilder .newBuilder() .expireAfterWrite(3, TimeUnit.SECONDS) .removalListener(notification -&gt; System.out.println("cache expired, remove key : " + notification.getKey())) .build(new CacheLoader&lt;String, Optional&lt;String&gt;&gt;() &#123; @Override public Optional&lt;String&gt; load(String key) throws Exception &#123; return Optional.ofNullable(MockDB.loadFromPersistence(key)); &#125; &#125;); try &#123; System.out.println("load from cache once : " + loadingCache.get("github").orElse("Nothing")); Thread.sleep(2000); System.out.println("load from cache twice : " + loadingCache.get("github").orElse("Nothing")); Thread.sleep(2000); System.out.println("load from cache third : " + loadingCache.get("github").orElse("Nothing")); Thread.sleep(2000); System.out.println("load not exist key from cache : " + loadingCache.get("email").orElse("Nothing")); &#125; catch (ExecutionException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 我们逐行进行解释： expireAfterWrite(3, TimeUnit.SECONDS)：定义缓存3秒过期； removalListener：用来监听当缓存里面的key被移除时候触发的事件； build(new CacheLoader&lt;String, Optional&lt;String&gt;&gt;()：传入一个CacheLoader类，指定缓存中没有的时候调用 CacheLoader 类的load方法（所以一般需要重写该方法）； Optional：当CacheLoader尝试获取数据库中不存在的数据会抛出异常，所以我们这里使用Optional可空对象处理一下。 Thread.sleep(2000)：缓存我们设置3秒过期，所以两次Sleep以后就会重新获取数据库。 运行输出结果如下：12345678load key from persistence : githubload from cache once : codedrinkerload from cache twice : codedrinkercache expired, remove key : githubload key from persistence : githubload from cache third : codedrinkerload key from persistence : emailload not exist key from cache : Nothing 证明了再第三次获取的时候因为缓存过期了，所以需要重新在MockDB获取数据。 2.3. 使用Callable这里我们依然需要使用上面的MockDB类，具体代码如下。123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.wxweven.cache.guavatest;import com.google.common.cache.Cache;import com.google.common.cache.CacheBuilder;import java.util.Optional;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;/** * CallableCache demo * * @author wxweven * @date 2017/7/13 */public class GuavaCallableCache &#123; public static void main(String[] args) &#123; final String key = "github"; Cache&lt;String, Optional&lt;String&gt;&gt; cache = CacheBuilder.newBuilder() .expireAfterWrite(3, TimeUnit.SECONDS) .removalListener(notification -&gt; System.out.println("cache expired, remove key : " + notification.getKey())).build(); try &#123; Optional&lt;String&gt; optional; System.out.println("load from cache once : " + cache.get(key, () -&gt; Optional.ofNullable(MockDB.loadFromPersistence(key))).orElse("empty")); Thread.sleep(2000); System.out.println("load from cache twice : " + cache.get(key, () -&gt; Optional.ofNullable(MockDB.loadFromPersistence(key))).orElse(null)); Thread.sleep(2000); System.out.println("load from cache third : " + cache.get(key, () -&gt; Optional.ofNullable(MockDB.loadFromPersistence(key))).orElse(null)); Thread.sleep(2000); final String nullKey = "email"; optional = cache.get(nullKey, () -&gt; Optional.ofNullable(MockDB.loadFromPersistence(nullKey))); System.out.println("load not exist key from cache : " + optional.orElse(null)); &#125; catch (ExecutionException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 下面我们对程序进行解释: 与上面例子唯一的不同就是没有在build的时候传入CacheLoader，而是在cache.get使用Cache的时候用传入Callable对象。 这样做可以灵活配置每次获取的缓存源不一样，但是两种方案都各有好处，还是在使用的时候斟酌。 运行程序数据结果如下：12345678load key from persistence : githubload from cache once : codedrinkerload from cache twice : codedrinkercache expired, remove key : githubload key from persistence : githubload from cache third : codedrinkerload key from persistence : emailload not exist key from cache : null 3. 回收策略所有的cache都需要定期remove value，下面我们看看guava cache的回收策略。 3.1. 基于容量的回收(Eviction by Size)3.1.1. maximumSize限定缓存最大容量我们可以通过maximumSize()方法限制cache的size，如果cache达到了最大限制，默认情况下，Guava将会回收最老的缓存。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.wxweven.cache;import com.google.common.cache.CacheBuilder;import com.google.common.cache.CacheLoader;import com.google.common.cache.LoadingCache;import org.junit.Test;/** * Guava Cache 测试类 * * @author wxweven * @date 2017/7/13 */public class GuavaCacheTest &#123; private static CacheLoader&lt;String, String&gt; loader = new CacheLoader&lt;String, String&gt;() &#123; @Override public String load(String key) &#123; System.out.printf("loading cache：%s...\n", key); return key.toUpperCase(); &#125; &#125;; public void testMaximumSize() &#123; LoadingCache&lt;String, String&gt; cache; cache = CacheBuilder.newBuilder() .maximumSize(3) // 限制Cache的最大容量为3 .removalListener(notification -&gt; System.out.printf("key：%s removed \n", notification.getKey())) .build(loader); System.out.printf("缓存大小key：%d\n", cache.size()); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "first", cache.getUnchecked("first")); System.out.printf("第二次获取缓存key：%s，value：%s\n", "first", cache.getUnchecked("first")); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "second", cache.getUnchecked("second")); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "third", cache.getUnchecked("third")); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "forth", cache.getUnchecked("forth")); System.out.println("---------------------"); System.out.printf("缓存大小key：%d\n", cache.size()); System.out.println("---------------------"); System.out.printf("再次获取缓存key：%s，value：%s\n", "first", cache.getIfPresent("first")); &#125; 程序输出如下：12345678910111213141516171819缓存大小key：0---------------------loading cache：first...第一次获取缓存key：first，value：FIRST第二次获取缓存key：first，value：FIRST---------------------loading cache：second...第一次获取缓存key：second，value：SECOND---------------------loading cache：third...第一次获取缓存key：third，value：THIRD---------------------loading cache：forth...key：first removed 第一次获取缓存key：forth，value：FORTH---------------------缓存大小key：3---------------------再次获取缓存key：first，value：null 由于我们设定了缓存的最大大小为3，所以在获取 forth 时，Guava默认会将缓存中最老的key删除掉，即本例中的 first。当再次获取 first时，我们会发现得到的是null。 3.1.2. maximumWeight限定缓存最大容量我们也可以通过定制weight function来限制cache size，以下为自定义weight function实现的限制cache size 的示例：12345678910111213141516171819202122232425262728293031323334@Testpublic void testMaximumWeight() &#123; LoadingCache&lt;String, String&gt; cache; cache = CacheBuilder.newBuilder() .maximumWeight(11) // 限定缓存的最大“重量为16” // 自定义缓存的“重量”：字符串的长度 .weigher((Weigher&lt;String, String&gt;) (key, value) -&gt; value.length()) .removalListener(notification -&gt; System.out.printf("key：%s removed \n", notification.getKey())) .build(loader); System.out.printf("缓存大小：%d\n", cache.size()); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "first", cache.getUnchecked("first")); System.out.printf("第二次获取缓存key：%s，value：%s\n", "first", cache.getUnchecked("first")); System.out.println("---------------------"); System.out.printf("缓存大小：%d\n", cache.size()); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "second", cache.getUnchecked("second")); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "third", cache.getUnchecked("third")); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "forth", cache.getUnchecked("forth")); System.out.println("---------------------"); System.out.printf("缓存大小：%d\n", cache.size()); System.out.println("---------------------"); System.out.printf("再次获取缓存key：%s，value：%s\n", "first", cache.getIfPresent("first"));&#125; 程序输出如下：12345678910111213141516171819202122缓存大小：0---------------------loading cache：first...第一次获取缓存key：first，value：FIRST第二次获取缓存key：first，value：FIRST---------------------缓存大小：1---------------------loading cache：second...第一次获取缓存key：second，value：SECOND---------------------loading cache：third...key：first removed 第一次获取缓存key：third，value：THIRD---------------------loading cache：forth...key：second removed 第一次获取缓存key：forth，value：FORTH---------------------缓存大小：2---------------------再次获取缓存key：first，value：null 可以看到，由于我们指定了缓存的maximumWeight为11，而且是根据缓存中值的长度来计算weight，所以缓存最大能存放11个长度的字符串，所以当获取 third时容量就已经不足，就会让 first 失效。 3.2. 定时回收(Eviction by Time)除了通过size来回收记录，我们也可以选择定时回收。CacheBuilder提供两种定时回收的方法： expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于大小回收一样。 expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。 下面代码 将示例expireAfterAccess的用法：1234567891011121314151617181920212223242526@Testpublic void testExpireAfterAccess() throws InterruptedException &#123; LoadingCache&lt;String, String&gt; cache; cache = CacheBuilder.newBuilder() // 指定缓存 2 秒内没有被访问（读/写）就过期 .expireAfterAccess(2, TimeUnit.SECONDS) .build(loader); System.out.printf("缓存大小：%d\n", cache.size()); System.out.println("---------------------"); System.out.printf("第一次获取缓存key：%s，value：%s\n", "first", cache.getUnchecked("first")); System.out.println("---------------------"); Thread.sleep(3000); System.out.printf("第二次获取缓存key：%s，value：%s\n", "first", cache.getUnchecked("first")); System.out.println("---------------------"); Thread.sleep(3000); System.out.printf("第一次获取缓存key：%s，value：%s\n", "second", cache.getUnchecked("second")); System.out.println("---------------------"); System.out.printf("缓存大小：%d\n", cache.size());&#125; 程序输出如下：123456789101112缓存大小：0---------------------loading cache：first...第一次获取缓存key：first，value：FIRST---------------------loading cache：first...第二次获取缓存key：first，value：FIRST---------------------loading cache：second...第一次获取缓存key：second，value：SECOND---------------------缓存大小：1 可以看到，指定缓存访问过期时间为2秒，sleep 3秒后，first过期，第二次获取需要重新load；再sleep 3秒后，first又过期，从最后的缓存大小为1可以验证。 3.3. 基于引用的回收(Reference-based Eviction)通过使用弱引用的键、或弱引用的值、或软引用的值，Guava Cache可以把缓存设置为允许垃圾回收： CacheBuilder.weakKeys()：使用弱引用存储键。当键没有其它（强或软）引用时，缓存项可以被垃圾回收。因为垃圾回收仅依赖恒等式（==），使用弱引用键的缓存用==而不是equals比较键。 CacheBuilder.softValues()：使用软引用存储值。软引用只有在响应内存需要时，才按照全局最近最少使用的顺序回收。考虑到使用软引用的性能影响，我们通常建议使用更有性能预测性的缓存大小限定（见上文，基于容量回收）。使用软引用值的缓存同样用==而不是equals比较值。 3.4. 显式清除任何时候，你都可以显式地清除缓存项，而不是等到它被回收： 个别清除：Cache.invalidate(key) 批量清除：Cache.invalidateAll(keys) 清除所有缓存项：Cache.invalidateAll() 4. 移除监听(RemovalNotification)通过CacheBuilder.removalListener(RemovalListener)，你可以声明一个监听器，以便缓存项被移除时做一些额外操作。缓存项被移除时，RemovalListener会获取移除通知[RemovalNotification]，其中包含移除原因[RemovalCause]、键和值。 请注意，RemovalListener抛出的任何异常都会在记录到日志后被丢弃[swallowed]。1234567891011121314151617181920212223@Testpublic void whenEntryRemovedFromCache_thenNotify() &#123; RemovalListener&lt;String, String&gt; listener; listener = new RemovalListener&lt;String, String&gt;() &#123; @Override public void onRemoval(RemovalNotification&lt;String, String&gt; n) &#123; if (n.wasEvicted()) &#123; String cause = n.getCause().name(); assertEquals(RemovalCause.SIZE.toString(), cause); &#125; &#125; &#125;; LoadingCache&lt;String, String&gt; cache; cache = CacheBuilder.newBuilder() .maximumSize(3) .removalListener(listener) .build(loader); cache.getUnchecked("first"); cache.getUnchecked("second"); cache.getUnchecked("third"); cache.getUnchecked("last"); assertEquals(3, cache.size());&#125; 5. 刷新( Refresh the Cache)刷新和回收不太一样。正如LoadingCache.refresh(K)所声明，刷新表示为键加载新值，这个过程可以是异步的。在刷新操作进行时，缓存仍然可以向其他线程返回旧值，而不像回收操作，读缓存的线程必须等待新值加载完成。 如果刷新过程抛出异常，缓存将保留旧值，而异常会在记录到日志后被丢弃[swallowed]。重载CacheLoader.reload(K, V)可以扩展刷新时的行为，这个方法允许开发者在计算新值时使用旧的值。123456789101112131415161718192021222324@Testpublic void cache_reLoad() &#123; CacheLoader&lt;String, String&gt; loader; loader = new CacheLoader&lt;String, String&gt;() &#123; @Override public String load(String key) &#123; return key.toUpperCase(); &#125; /** * 重写reload方法可以定制自己的reload策略 * @param key * @param oldValue * @return * @throws Exception */ @Override public ListenableFuture&lt;String&gt; reload(String key, String oldValue) throws Exception &#123; return super.reload(key, oldValue); &#125; &#125;; LoadingCache&lt;String, String&gt; cache; cache = CacheBuilder.newBuilder() .build(loader);&#125; CacheBuilder.refreshAfterWrite(long, TimeUnit)可以为缓存增加自动定时刷新功能。和expireAfterWrite相反，refreshAfterWrite通过定时刷新可以让缓存项保持可用，但请注意：缓存项只有在被检索时才会真正刷新（如果CacheLoader.refresh实现为异步，那么检索不会被刷新拖慢）。因此，如果你在缓存上同时声明expireAfterWrite和refreshAfterWrite，缓存并不会因为刷新盲目地定时重置，如果缓存项没有被检索，那刷新就不会真的发生，缓存项在过期时间后也变得可以回收。1234567891011121314@Testpublic void whenLiveTimeEnd_thenRefresh() &#123; CacheLoader&lt;String, String&gt; loader; loader = new CacheLoader&lt;String, String&gt;() &#123; @Override public String load(String key) &#123; return key.toUpperCase(); &#125; &#125;; LoadingCache&lt;String, String&gt; cache; cache = CacheBuilder.newBuilder() .refreshAfterWrite(1, TimeUnit.MINUTES) .build(loader);&#125; 6. 处理空值(Handle null Values)实际上Guava整体设计思想就是拒绝null的，很多地方都会执行com.google.common.base.Preconditions.checkNotNull的检查。 By default, Guava Cache will throw exceptions if you try to load a null value – as it doesn’t make any sense to cache a null.But if null value means something in your code, then you can make good use of the Optional class as in the following example: 默认情况guava cache将会抛出异常，如果试图加载null value–因为cache null 是没有任何意义的。但是如果null value 对你的代码而已有一些特殊的含义，你可以尝试用Optional来表达，像下面这个例子： 123456789101112131415161718192021@Testpublic void whenNullValue_thenOptional() &#123; CacheLoader&lt;String, Optional&lt;String&gt;&gt; loader; loader = new CacheLoader&lt;String, Optional&lt;String&gt;&gt;() &#123; @Override public Optional&lt;String&gt; load(String key) &#123; return Optional.fromNullable(getSuffix(key)); &#125; &#125;; LoadingCache&lt;String, Optional&lt;String&gt;&gt; cache; cache = CacheBuilder.newBuilder().build(loader); assertEquals(&quot;txt&quot;, cache.getUnchecked(&quot;text.txt&quot;).get()); assertFalse(cache.getUnchecked(&quot;hello&quot;).isPresent());&#125;private String getSuffix(final String str) &#123; int lastIndex = str.lastIndexOf(&apos;.&apos;); if (lastIndex == -1) &#123; return null; &#125; return str.substring(lastIndex + 1);&#125; 7. 统计CacheBuilder.recordStats()用来开启Guava Cache的统计功能。统计打开后，Cache.stats()方法会返回CacheStats对象以提供如下统计信息： hitRate()：缓存命中率； averageLoadPenalty()：加载新值的平均时间，单位为纳秒； evictionCount()：缓存项被回收的总数，不包括显式清除。 此外，还有其他很多统计信息。这些统计信息对于调整缓存设置是至关重要的，在性能要求高的应用中我们建议密切关注这些数据。 8. getUnchecked什么时候用get，什么时候用getUnchecked官网文档说： If you have defined a CacheLoader that does not declare any checked exceptions then you can perform cache lookups using getUnchecked(K); However care must be taken not to call getUnchecked on caches whose CacheLoaders declare checked exceptions. 字面意思是，如果你的CacheLoader没有定义任何checked Exception，那你可以使用getUnchecked。但是 ，一定要注意，如果CacheLoader声明了checked exceptions，那就不要调用getUnchecked。 9. 总结在设计Java分布式应用程序的时候，针对一些基本不变的数据，或者是变化不大然而使用非常频繁的数据可以考虑采用Guava Cache实现Java应用内存级别缓存。]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>Guava</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Major GC和Full GC的区别]]></title>
    <url>%2F2017%2F07%2F14%2FMajor-GC%E5%92%8CFull-GC%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[作者：RednaxelaFX链接：https://www.zhihu.com/question/41922036/answer/93079526来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 1. 概述针对HotSpot VM的实现，它里面的GC其实准确分类只有两大种：Partial GC 和 Full GC。 2. Partial GCPartial GC 并不收集整个GC堆的模式。Partial GC 又包括以下几种： Young GC：只收集young gen的GC Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式 Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式 3. Full GCFull GC 收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。 Major GC通常是跟full GC是等价的，收集整个GC堆。但因为HotSpot VM发展了这么多年，外界对各种名词的解读已经完全混乱了，当有人说“major GC”的时候一定要问清楚他想要指的是上面的full GC还是old GC。 4. 触发条件最简单的分代式GC策略，按HotSpot VM的serial GC的实现来看，触发条件如下文所述。 4.1. Young GC触发条件当young gen中的eden区分配满的时候触发。 注意young GC中有部分存活对象会晋升到old gen，所以young GC后old gen的占用量通常会有所升高。 4.2. Full GC触发条件当准备要触发一次young GC时，如果发现统计数据说之前young GC的平均晋升大小比目前old gen剩余的空间大，则不会触发young GC，而是转为触发full GC（因为HotSpot VM的GC里，除了CMS的concurrent collection之外，其它能收集old gen的GC都会同时收集整个GC堆，包括young gen，所以不需要事先触发一次单独的young GC）； 或者，如果有perm gen的话，要在perm gen分配空间但已经没有足够空间时，也要触发一次full GC； 或者System.gc()、heap dump带GC，默认也是触发full GC。 HotSpot VM里其它非并发GC的触发条件复杂一些，不过大致的原理与上面说的其实一样。当然也总有例外。 Parallel Scavenge（-XX:+UseParallelGC）框架下，默认是在要触发full GC前先执行一次young GC，并且两次GC之间能让应用程序稍微运行一小下，以期降低full GC的暂停时间（因为young GC会尽量清理了young gen的死对象，减少了full GC的工作量）。控制这个行为的VM参数是-XX:+ScavengeBeforeFullGC。这是HotSpot VM里的奇葩嗯。可跳传送门围观：VM full GC的奇怪现象，求解惑？ - RednaxelaFX 的回答 并发GC的触发条件就不太一样。以CMS GC为例，它主要是定时去检查old gen的使用量，当使用量超过了触发比例就会启动一次CMS GC，对old gen做并发收集。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git分支]]></title>
    <url>%2F2017%2F07%2F14%2FGit%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。在很多版本控制系统中，这是个昂贵的过程，常常需要创建一个源代码目录的完整副本，对大型项目来说会花费很长时间。 有人把 Git 的分支模型称为“必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来。Git 有何特别之处呢？Git 的分支可谓是难以置信的轻量级，它的新建操作几乎可以在瞬间完成，并且在不同分支间切换起来也差不多一样快。和许多其他版本控制系统不同，Git 鼓励在工作流程中频繁使用分支与合并，哪怕一天之内进行许多次都没有关系。理解分支的概念并熟练运用后，你才会意识到为什么 Git 是一个如此强大而独特的工具，并从此真正改变你的开发方式。 1. 何谓分支为了理解 Git 分支的实现方式，我们需要回顾一下 Git 是如何储存数据的。或许你还记得第一章的内容，Git 保存的不是文件差异或者变化量，而只是一系列文件快照。 在 Git 中提交时，会保存一个提交（commit）对象，该对象包含一个指向暂存内容快照的指针，包含本次提交的作者等相关附属信息，包含零个或多个指向该提交对 象的父对象指针：首次提交是没有直接祖先的，普通提交有一个祖先，由两个或多个分支合并产生的提交则有多个祖先。 为直观起见，我们假设在工作目录中有三个文件，准备将它们暂存后提交。暂存操作会对每一个文件计算校验和（即第一章中提到的 SHA-1 哈希字串），然后把当前版本的文件快照保存到 Git 仓库中（Git 使用 blob 类型的对象存储这些快照），并将校验和加入暂存区域： $ git add README test.rb LICENSE$ git commit -m ‘initial commit of my project’当使用 git commit 新建一个提交对象前，Git 会先计算每一个子目录（本例中就是项目根目录）的校验和，然后在 Git 仓库中将这些目录保存为树（tree）对象。之后 Git 创建的提交对象，除了包含相关提交信息以外，还包含着指向这个树对象（项目根目录）的指针，如此它就可以在将来需要的时候，重现此次快照的内容了。 现在，Git 仓库中有五个对象：三个表示文件快照内容的 blob 对象；一个记录着目录树内容及其中各个文件对应 blob 对象索引的 tree 对象；以及一个包含指向 tree 对象（根目录）的索引和其他提交信息元数据的 commit 对象。概念上来说，仓库中的各个对象保存的数据和相互关系看起来如图 3-1 所示： Git详解之三 Git分支 图 3-1. 单个提交对象在仓库中的数据结构作些修改后再次提交，那么这次的提交对象会包含一个指向上次提交对象的指针（译注：即下图中的 parent 对象）。两次提交后，仓库历史会变成图 3-2 的样子： Git详解之三 Git分支 图 3-2. 多个提交对象之间的链接关系现在来谈分支。Git 中的分支，其实本质上仅仅是个指向 commit 对象的可变指针。Git 会使用 master 作为分支的默认名字。在若干次提交后，你其实已经有了一个指向最后一次提交对象的 master 分支，它在每次提交的时候都会自动向前移动。 Git详解之三 Git分支 图 3-3. 分支其实就是从某个提交对象往回看的历史那么，Git 又是如何创建一个新的分支的呢？答案很简单，创建一个新的分支指针。比如新建一个 testing 分支，可以使用 git branch 命令： $ git branch testing这会在当前 commit 对象上新建一个分支指针（见图 3-4）。 Git详解之三 Git分支 图 3-4. 多个分支指向提交数据的历史那么，Git 是如何知道你当前在哪个分支上工作的呢？其实答案也很简单，它保存着一个名为 HEAD 的特别指针。请注意它和你熟知的许多其他版本控制系统（比如 Subversion 或 CVS）里的 HEAD 概念大不相同。在 Git 中，它是一个指向你正在工作中的本地分支的指针（译注：将 HEAD 想象为当前分支的别名。）。运行git branch 命令，仅仅是建立了一个新的分支，但不会自动切换到这个分支中去，所以在这个例子中，我们依然还在 master 分支里工作（参考图 3-5）。 Git详解之三 Git分支 图 3-5. HEAD 指向当前所在的分支要切换到其他分支，可以执行 git checkout 命令。我们现在转换到新建的 testing 分支： $ git checkout testing这样 HEAD 就指向了 testing 分支（见图3-6）。 Git详解之三 Git分支 图 3-6. HEAD 在你转换分支时指向新的分支这样的实现方式会给我们带来什么好处呢？好吧，现在不妨再提交一次： $ vim test.rb$ git commit -a -m ‘made a change’图 3-7 展示了提交后的结果。 Git详解之三 Git分支 图 3-7. 每次提交后 HEAD 随着分支一起向前移动非常有趣，现在 testing 分支向前移动了一格，而 master 分支仍然指向原先 git checkout 时所在的 commit 对象。现在我们回到 master 分支看看： $ git checkout master图 3-8 显示了结果。 Git详解之三 Git分支 图 3-8. HEAD 在一次 checkout 之后移动到了另一个分支这条命令做了两件事。它把 HEAD 指针移回到 master 分支，并把工作目录中的文件换成了 master 分支所指向的快照内容。也就是说，现在开始所做的改动，将始于本项目中一个较老的版本。它的主要作用是将 testing 分支里作出的修改暂时取消，这样你就可以向另一个方向进行开发。 我们作些修改后再次提交： $ vim test.rb$ git commit -a -m ‘made other changes’现在我们的项目提交历史产生了分叉（如图 3-9 所示），因为刚才我们创建了一个分支，转换到其中进行了一些工作，然后又回到原来的主分支进行了另外一些工作。这些改变分别孤立在不同的分支里：我们可以 在不同分支里反复切换，并在时机成熟时把它们合并到一起。而所有这些工作，仅仅需要branch 和 checkout 这两条命令就可以完成。 Git详解之三 Git分支 图 3-9. 不同流向的分支历史由于 Git 中的分支实际上仅是一个包含所指对象校验和（40 个字符长度 SHA-1 字串）的文件，所以创建和销毁一个分支就变得非常廉价。说白了，新建一个分支就是向一个文件写入 41 个字节（外加一个换行符）那么简单，当然也就很快了。 这和大多数版本控制系统形成了鲜明对比，它们管理分支大多采取备份所有项目文件到特定目录的方式，所以根据项目文件数量和大小不同，可能花费的时间 也会有相当大的差别，快则几秒，慢则数分钟。而 Git 的实现与项目复杂度无关，它永远可以在几毫秒的时间内完成分支的创建和切换。同时，因为每次提交时都记录了祖先信息（译注：即parent 对象），将来要合并分支时，寻找恰当的合并基础（译注：即共同祖先）的工作其实已经自然而然地摆在那里了，所以实现起来非常容易。Git 鼓励开发者频繁使用分支，正是因为有着这些特性作保障。 接下来看看，我们为什么应该频繁使用分支。 3.2 分支的新建与合并现在让我们来看一个简单的分支与合并的例子，实际工作中大体也会用到这样的工作流程： 开发某个网站。 2. 为实现某个新的需求，创建一个分支。 3. 在这个分支上开展工作。 假设此时，你突然接到一个电话说有个很严重的问题需要紧急修补，那么可以按照下面的方式处理： 返回到原先已经发布到生产服务器上的分支。 2. 为这次紧急修补建立一个新分支，并在其中修复问题。 3. 通过测试后，回到生产服务器所在的分支，将修补分支合并进来，然后再推送到生产服务器上。 4. 切换到之前实现新需求的分支，继续工作。 分支的新建与切换首先，我们假设你正在项目中愉快地工作，并且已经提交了几次更新（见图 3-10）。 Git详解之三 Git分支 图 3-10. 一个简短的提交历史现在，你决定要修补问题追踪系统上的 #53 问题。顺带说明下，Git 并不同任何特定的问题追踪系统打交道。这里为了说明要解决的问题，才把新建的分支取名为 iss53。要新建并切换到该分支，运行git checkout 并加上 -b 参数： $ git checkout -b iss53Switched to a new branch “iss53”这相当于执行下面这两条命令： $ git branch iss53$ git checkout iss53图 3-11 示意该命令的执行结果。 Git详解之三 Git分支 图 3-11. 创建了一个新分支的指针接着你开始尝试修复问题，在提交了若干次更新后，iss53 分支的指针也会随着向前推进，因为它就是当前分支（换句话说，当前的 HEAD 指针正指向 iss53，见图 3-12）： $ vim index.html$ git commit -a -m ‘added a new footer [issue 53]’Git详解之三 Git分支 图 3-12. iss53 分支随工作进展向前推进现在你就接到了那个网站问题的紧急电话，需要马上修补。有了 Git ，我们就不需要同时发布这个补丁和 iss53 里作出的修改，也不需要在创建和发布该补丁到服务器之前花费大力气来复原这些修改。唯一需要的仅仅是切换回master 分支。 不过在此之前，留心你的暂存区或者工作目录里，那些还没有提交的修改，它会和你即将检出的分支产生冲突从而阻止 Git 为你切换分支。切换分支的时候最好保持一个清洁的工作区域。稍后会介绍几个绕过这种问题的办法（分别叫做 stashing 和 commit amending）。目前已经提交了所有的修改，所以接下来可以正常转换到master 分支： $ git checkout masterSwitched to branch “master”此时工作目录中的内容和你在解决问题 #53 之前一模一样，你可以集中精力进行紧急修补。这一点值得牢记：Git 会把工作目录的内容恢复为检出某分支时它所指向的那个提交对象的快照。它会自动添加、删除和修改文件以确保目录的内容和你当时提交时完全一样。 接下来，你得进行紧急修补。我们创建一个紧急修补分支 hotfix 来开展工作，直到搞定（见图 3-13）： $ git checkout -b ‘hotfix’Switched to a new branch “hotfix”$ vim index.html$ git commit -a -m ‘fixed the broken email address’[hotfix]: created 3a0874c: “fixed the broken email address” 1 files changed, 0 insertions(+), 1 deletions(-)Git详解之三 Git分支 图 3-13. hotfix 分支是从 master 分支所在点分化出来的有必要作些测试，确保修补是成功的，然后回到 master 分支并把它合并进来，然后发布到生产服务器。用 git merge 命令来进行合并： $ git checkout master$ git merge hotfixUpdating f42c576..3a0874cFast forward README | 1 - 1 files changed, 0 insertions(+), 1 deletions(-)请注意，合并时出现了“Fast forward”的提示。由于当前 master 分支所在的提交对象是要并入的 hotfix 分支的直接上游，Git 只需把master 分支指针直接右移。换句话说，如果顺着一个分支走下去可以到达另一个分支的话，那么 Git 在合并两者时，只会简单地把指针右移，因为这种单线的历史分支不存在任何需要解决的分歧，所以这种合并过程可以称为快进（Fast forward）。 现在最新的修改已经在当前 master 分支所指向的提交对象中了，可以部署到生产服务器上去了（见图 3-14）。 Git详解之三 Git分支 图 3-14. 合并之后，master 分支和 hotfix 分支指向同一位置。在那个超级重要的修补发布以后，你想要回到被打扰之前的工作。由于当前 hotfix 分支和 master 都指向相同的提交对象，所以hotfix 已经完成了历史使命，可以删掉了。使用 git branch 的 -d 选项执行删除操作： $ git branch -d hotfixDeleted branch hotfix (3a0874c).现在回到之前未完成的 #53 问题修复分支上继续工作（图 3-15）： $ git checkout iss53Switched to branch “iss53”$ vim index.html$ git commit -a -m ‘finished the new footer [issue 53]’[iss53]: created ad82d7a: “finished the new footer [issue 53]” 1 files changed, 1 insertions(+), 0 deletions(-)Git详解之三 Git分支 图 3-15. iss53 分支可以不受影响继续推进。不用担心之前 hotfix 分支的修改内容尚未包含到 iss53 中来。如果确实需要纳入此次修补，可以用git merge master 把 master 分支合并到 iss53；或者等 iss53 完成之后，再将iss53 分支中的更新并入 master。 分支的合并在问题 #53 相关的工作完成之后，可以合并回 master 分支。实际操作同前面合并 hotfix 分支差不多，只需回到master 分支，运行 git merge 命令指定要合并进来的分支： $ git checkout master$ git merge iss53Merge made by recursive. README | 1 + 1 files changed, 1 insertions(+), 0 deletions(-)请注意，这次合并操作的底层实现，并不同于之前 hotfix 的并入方式。因为这次你的开发历史是从更早的地方开始分叉的。由于当前 master 分支所指向的提交对象（C4）并不是 iss53 分支的直接祖先，Git 不得不进行一些额外处理。就此例而言，Git 会用两个分支的末端（C4 和 C5）以及它们的共同祖先（C2）进行一次简单的三方合并计算。图 3-16 用红框标出了 Git 用于合并的三个提交对象： Git详解之三 Git分支 图 3-16. Git 为分支合并自动识别出最佳的同源合并点。这次，Git 没有简单地把分支指针右移，而是对三方合并后的结果重新做一个新的快照，并自动创建一个指向它的提交对象（C6）（见图 3-17）。这个提交对象比较特殊，它有两个祖先（C4 和 C5）。 值得一提的是 Git 可以自己裁决哪个共同祖先才是最佳合并基础；这和 CVS 或 Subversion（1.5 以后的版本）不同，它们需要开发者手工指定合并基础。所以此特性让 Git 的合并操作比其他系统都要简单不少。 Git详解之三 Git分支 图 3-17. Git 自动创建了一个包含了合并结果的提交对象。既然之前的工作成果已经合并到 master 了，那么 iss53 也就没用了。你可以就此删除它，并在问题追踪系统里关闭该问题。 $ git branch -d iss53遇到冲突时的分支合并有时候合并操作并不会如此顺利。如果在不同的分支中都修改了同一个文件的同一部分，Git 就无法干净地把两者合到一起（译注：逻辑上说，这种问题只能由人来裁决。）。如果你在解决问题 #53 的过程中修改了hotfix 中修改的部分，将得到类似下面的结果： $ git merge iss53Auto-merging index.htmlCONFLICT (content): Merge conflict in index.htmlAutomatic merge failed; fix conflicts and then commit the result.Git 作了合并，但没有提交，它会停下来等你解决冲突。要看看哪些文件在合并时发生冲突，可以用 git status 查阅： [master*]$ git statusindex.html: needs merge 2. On branch master3. Changed but not updated:4. (use “git add...&quot; to update what will be committed) 5. (use “git checkout –...&quot; to discard changes in working directory) # 6. unmerged: index.html# 任何包含未解决冲突的文件都会以未合并（unmerged）的状态列出。Git 会在有冲突的文件里加入标准的冲突解决标记，可以通过它们来手工定位并解决这些冲突。可以看到此文件包含类似下面这样的部分： &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.html contact : email.support@github.com ======= please contact us at support@github.com iss53:index.html可以看到 ======= 隔开的上半部分，是 HEAD（即 master 分支，在运行merge 命令时所切换到的分支）中的内容，下半部分是在 iss53 分支中的内容。解决冲突的办法无非是二者选其一或者由你亲自整合到一起。比如你可以通过把这段内容替换为下面这样来解决： please contact us at email.support@github.com 这个解决方案各采纳了两个分支中的一部分内容，而且我还删除了 &lt;&lt;&lt;&lt;&lt;&lt;&lt;，======= 和 &gt;&gt;&gt;&gt;&gt;&gt;&gt; 这些行。在解决了所有文件里的所有冲突后，运行 git add 将把它们标记为已解决状态（译注：实际上就是来一次快照保存到暂存区域。）。因为一旦暂存，就表示冲突已经解决。如果你想用一个有图形界面的工具来解决这些问题，不妨运行git mergetool，它会调用一个可视化的合并工具并引导你解决所有冲突： $ git mergetoolmerge tool candidates: kdiff3 tkdiff xxdiff meld gvimdiff opendiff emerge vimdiffMerging the files: index.html Normal merge conflict for ‘index.html’: {local}: modified {remote}: modifiedHit return to start merge resolution tool (opendiff):如果不想用默认的合并工具（Git 为我默认选择了 opendiff，因为我在 Mac 上运行了该命令），你可以在上方”merge tool candidates”里找到可用的合并工具列表，输入你想用的工具名。我们将在第七章讨论怎样改变环境中的默认值。 退出合并工具以后，Git 会询问你合并是否成功。如果回答是，它会为你把相关文件暂存起来，以表明状态为已解决。 再运行一次 git status 来确认所有冲突都已解决： $ git status 7. On branch master8. Changes to be committed:9. (use “git reset HEAD...&quot; to unstage) # 10. modified: index.html# 如果觉得满意了，并且确认所有冲突都已解决，也就是进入了暂存区，就可以用 git commit 来完成这次合并提交。提交的记录差不多是这样： Merge branch ‘iss53’ Conflicts: index.html# 11. It looks like you may be committing a MERGE.12. If this is not correct, please remove the file13. .git/MERGE_HEAD14. and try again.#如果想给将来看这次合并的人一些方便，可以修改该信息，提供更多合并细节。比如你都作了哪些改动，以及这么做的原因。有时候裁决冲突的理由并不直接或明显，有必要略加注解。 3.3 分支的管理到目前为止，你已经学会了如何创建、合并和删除分支。除此之外，我们还需要学习如何管理分支，在日后的常规工作中会经常用到下面介绍的管理命令。 git branch 命令不仅仅能创建和删除分支，如果不加任何参数，它会给出当前所有分支的清单： $ git branch iss53 mastertesting注意看 master 分支前的 * 字符：它表示当前所在的分支。也就是说，如果现在提交更新，master 分支将随着开发进度前移。若要查看各个分支最后一个提交对象的信息，运行git branch -v： $ git branch -v iss53 93b412c fix javascript issue master 7a98805 Merge branch ‘iss53’testing 782fd34 add scott to the author list in the readmes要从该清单中筛选出你已经（或尚未）与当前分支合并的分支，可以用 –merge 和 –no-merged 选项（Git 1.5.6 以上版本）。比如用git branch –merge 查看哪些分支已被并入当前分支（译注：也就是说哪些分支是当前分支的直接上游。）： $ git branch –merged iss53 master之前我们已经合并了 iss53，所以在这里会看到它。一般来说，列表中没有 * 的分支通常都可以用 git branch -d 来删掉。原因很简单，既然已经把它们所包含的工作整合到了其他分支，删掉也不会损失什么。 另外可以用 git branch –no-merged 查看尚未合并的工作： $ git branch –no-merged testing它会显示还未合并进来的分支。由于这些分支中还包含着尚未合并进来的工作成果，所以简单地用 git branch -d 删除该分支会提示错误，因为那样做会丢失数据： $ git branch -d testingerror: The branch ‘testing’ is not an ancestor of your current HEAD.If you are sure you want to delete it, run ‘git branch -D testing’.不过，如果你确实想要删除该分支上的改动，可以用大写的删除选项 -D 强制执行，就像上面提示信息中给出的那样。 3.4 利用分支进行开发的工作流程现在我们已经学会了新建分支和合并分支，可以（或应该）用它来做点什么呢？在本节，我们会介绍一些利用分支进行开发的工作流程。而正是由于分支管理的便捷，才衍生出了这类典型的工作模式，你可以根据项目的实际情况选择一种用用看。 长期分支由于 Git 使用简单的三方合并，所以就算在较长一段时间内，反复多次把某个分支合并到另一分支，也不是什么难事。也就是说，你可以同时拥有多个开放的分支，每个分支用于完成特定的任务，随着开发的推进，你可以随时把某个特性分支的成果并到其他分支中。 许多使用 Git 的开发者都喜欢用这种方式来开展工作，比如仅在 master 分支中保留完全稳定的代码，即已经发布或即将发布的代码。与此同时，他们还有一个名为develop 或 next 的平行分支，专门用于后续的开发，或仅用于稳定性测试 — 当然并不是说一定要绝对稳定，不过一旦进入某种稳定状态，便可以把它合并到master 里。这样，在确保这些已完成的特性分支（短期分支，比如之前的 iss53 分支）能够通过所有测试，并且不会引入更多错误之后，就可以并到主干分支中，等待下一次的发布。 本质上我们刚才谈论的，是随着提交对象不断右移的指针。稳定分支的指针总是在提交历史中落后一大截，而前沿分支总是比较靠前（见图 3-18）。 Git详解之三 Git分支 图 3-18. 稳定分支总是比较老旧。或者把它们想象成工作流水线，或许更好理解一些，经过测试的提交对象集合被遴选到更稳定的流水线（见图 3-19）。 Git详解之三 Git分支 图 3-19. 想象成流水线可能会容易点。你可以用这招维护不同层次的稳定性。某些大项目还会有个 proposed（建议）或 pu（proposed updates，建议更新）分支，它包含着那些可能还没有成熟到进入next 或 master 的内容。这么做的目的是拥有不同层次的稳定性：当这些分支进入到更稳定的水平时，再把它们合并到更高层分支中去。再次说明下，使用多个长期分支的做法并非必需，不过一般来说，对于特大型项目或特复杂的项目，这么做确实更容易管理。 特性分支在任何规模的项目中都可以使用特性（Topic）分支。一个特性分支是指一个短期的，用来实现单一特性或与其相关工作的分支。可能你在以前的版本控 制系统里从未做过类似这样的事情，因为通常创建与合并分支消耗太大。然而在 Git 中，一天之内建立、使用、合并再删除多个分支是常见的事。 我们在上节的例子里已经见过这种用法了。我们创建了 iss53 和 hotfix 这两个特性分支，在提交了若干更新后，把它们合并到主干分支，然后删除。该技术允许你迅速且完全的进行语境切换 — 因为你的工作分散在不同的流水线里，每个分支里的改变都和它的目标特性相关，浏览代码之类的事情因而变得更简单了。你可以把作出的改变保持在特性分支中几 分钟，几天甚至几个月，等它们成熟以后再合并，而不用在乎它们建立的顺序或者进度。 现在我们来看一个实际的例子。请看图 3-20，由下往上，起先我们在 master 工作到 C1，然后开始一个新分支 iss91 尝试修复 91 号缺陷，提交到 C6 的时候，又冒出一个解决该问题的新办法，于是从之前 C4 的地方又分出一个分支iss91v2，干到 C8 的时候，又回到主干 master 中提交了 C9 和 C10，再回到 iss91v2 继续工作，提交 C11，接着，又冒出个不太确定的想法，从 master 的最新提交 C10 处开了个新的分支dumbidea 做些试验。 Git详解之三 Git分支 图 3-20. 拥有多个特性分支的提交历史。现在，假定两件事情：我们最终决定使用第二个解决方案，即 iss91v2 中的办法；另外，我们把 dumbidea 分支拿给同事们看了以后，发现它竟然是个天才之作。所以接下来，我们准备抛弃原来的iss91 分支（实际上会丢弃 C5 和 C6），直接在主干中并入另外两个分支。最终的提交历史将变成图 3-21 这样： Git详解之三 Git分支 图 3-21. 合并了 dumbidea 和 iss91v2 后的分支历史。请务必牢记这些分支全部都是本地分支，这一点很重要。当你在使用分支及合并的时候，一切都是在你自己的 Git 仓库中进行的 — 完全不涉及与服务器的交互。 3.5 远程分支远程分支（remote branch）是对远程仓库中的分支的索引。它们是一些无法移动的本地分支；只有在 Git 进行网络交互时才会更新。远程分支就像是书签，提醒着你上次连接远程仓库时上面各分支的位置。 我们用 (远程仓库名)/(分支名) 这样的形式表示远程分支。比如我们想看看上次同 origin 仓库通讯时master 的样子，就应该查看 origin/master 分支。如果你和同伴一起修复某个问题，但他们先推送了一个iss53 分支到远程仓库，虽然你可能也有一个本地的 iss53 分支，但指向服务器上最新更新的却应该是 origin/iss53 分支。 可能有点乱，我们不妨举例说明。假设你们团队有个地址为 git.ourcompany.com 的 Git 服务器。如果你从这里克隆，Git 会自动为你将此远程仓库命名为origin，并下载其中所有的数据，建立一个指向它的 master 分支的指针，在本地命名为 origin/master，但你无法在本地更改其数据。接着，Git 建立一个属于你自己的本地master 分支，始于 origin 上 master 分支相同的位置，你可以就此开始工作（见图 3-22）： Git详解之三 Git分支 图 3-22. 一次 Git 克隆会建立你自己的本地分支 master 和远程分支 origin/master，它们都指向 origin/master 分支的最后一次提交。如果你在本地 master 分支做了些改动，与此同时，其他人向 git.ourcompany.com 推送了他们的更新，那么服务器上的master 分支就会向前推进，而于此同时，你在本地的提交历史正朝向不同方向发展。不过只要你不和服务器通讯，你的 origin/master 指针仍然保持原位不会移动（见图 3-23）。 Git详解之三 Git分支 图 3-23. 在本地工作的同时有人向远程仓库推送内容会让提交历史开始分流。可以运行 git fetch origin 来同步远程服务器上的数据到本地。该命令首先找到 origin 是哪个服务器（本例为git.ourcompany.com），从上面获取你尚未拥有的数据，更新你本地的数据库，然后把 origin/master 的指针移到它最新的位置上（见图 3-24）。 Git详解之三 Git分支 图 3-24. git fetch 命令会更新 remote 索引。为了演示拥有多个远程分支（在不同的远程服务器上）的项目是如何工作的，我们假设你还有另一个仅供你的敏捷开发小组使用的内部服务器 git.team1.ourcompany.com。可以用第二章中提到的git remote add 命令把它加为当前项目的远程分支之一。我们把它命名为 teamone，以便代替原始的 Git 地址（见图 3-25）。 Git详解之三 Git分支 图 3-25. 把另一个服务器加为远程仓库现在你可以用 git fetch teamone 来获取小组服务器上你还没有的数据了。由于当前该服务器上的内容是你 origin 服务器上的子集，Git 不会下载任何数据，而只是简单地创建一个名为teamone/master 的分支，指向 teamone 服务器上 master 分支所在的提交对象31b8e（见图 3-26）。 Git详解之三 Git分支 图 3-26. 你在本地有了一个指向 teamone 服务器上 master 分支的索引。推送本地分支要想和其他人分享某个本地分支，你需要把它推送到一个你拥有写权限的远程仓库。你的本地分支不会被自动同步到你引入的远程服务器上，除非你明确执行推送操作。换句话说，对于无意分享的分支，你尽管保留为私人分支好了，而只推送那些协同工作要用到的特性分支。 如果你有个叫 serverfix 的分支需要和他人一起开发，可以运行 git push (远程仓库名) (分支名)： $ git push origin serverfixCounting objects: 20, done.Compressing objects: 100% (14/14), done.Writing objects: 100% (15/15), 1.74 KiB, done.Total 15 (delta 5), reused 0 (delta 0)To git@github.com:schacon/simplegit.git [new branch] serverfix -&gt; serverfix这其实有点像条捷径。Git 自动把 serverfix 分支名扩展为 refs/heads/serverfix:refs/heads/serverfix，意为“取出我在本地的 serverfix 分支，推送到远程仓库的 serverfix 分支中去”。我们将在第九章进一步介绍refs/heads/ 部分的细节，不过一般使用的时候都可以省略它。也可以运行 git push origin serverfix:serferfix 来实现相同的效果，它的意思是“上传我本地的 serverfix 分支到远程仓库中去，仍旧称它为 serverfix 分支”。通过此语法，你可以把本地分支推送到某个命名不同的远程分支：若想把远程分支叫作awesomebranch，可以用 git push origin serverfix:awesomebranch 来推送数据。 接下来，当你的协作者再次从服务器上获取数据时，他们将得到一个新的远程分支 origin/serverfix： $ git fetch originremote: Counting objects: 20, done.remote: Compressing objects: 100% (14/14), done.remote: Total 15 (delta 5), reused 0 (delta 0)Unpacking objects: 100% (15/15), done.From git@github.com:schacon/simplegit [new branch] serverfix -&gt; origin/serverfix值得注意的是，在 fetch 操作下载好新的远程分支之后，你仍然无法在本地编辑该远程仓库中的分支。换句话说，在本例中，你不会有一个新的serverfix 分支，有的只是一个你无法移动的 origin/serverfix 指针。 如果要把该内容合并到当前分支，可以运行 git merge origin/serverfix。如果想要一份自己的 serverfix 来开发，可以在远程分支的基础上分化出一个新的分支来： $ git checkout -b serverfix origin/serverfixBranch serverfix set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch “serverfix”这会切换到新建的 serverfix 本地分支，其内容同远程分支 origin/serverfix 一致，这样你就可以在里面继续开发了。 跟踪远程分支从远程分支 checkout 出来的本地分支，称为跟踪分支(tracking branch)。跟踪分支是一种和远程分支有直接联系的本地分支。在跟踪分支里输入git push，Git 会自行推断应该向哪个服务器的哪个分支推送数据。反过来，在这些分支里运行 git pull 会获取所有远程索引，并把它们的数据都合并到本地分支中来。 在克隆仓库时，Git 通常会自动创建一个名为 master 的分支来跟踪 origin/master。这正是git push 和 git pull 一开始就能正常工作的原因。当然，你可以随心所欲地设定为其它跟踪分支，比如origin 上除了 master 之外的其它分支。刚才我们已经看到了这样的一个例子：git checkout -b [分支名] [远程名]/[分支名]。如果你有 1.6.2 以上版本的 Git，还可以用–track 选项简化： $ git checkout –track origin/serverfixBranch serverfix set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch “serverfix”要为本地分支设定不同于远程分支的名字，只需在前个版本的命令里换个名字： $ git checkout -b sf origin/serverfixBranch sf set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch “sf”现在你的本地分支 sf 会自动向 origin/serverfix 推送和抓取数据了。 删除远程分支如果不再需要某个远程分支了，比如搞定了某个特性并把它合并进了远程的 master 分支（或任何其他存放稳定代码的地方），可以用这个非常无厘头的语法来删除它：git push [远程名] :[分支名]。如果想在服务器上删除serverfix 分支，运行下面的命令： $ git push origin :serverfixTo git@github.com:schacon/simplegit.git [deleted] serverfix咚！服务器上的分支没了。你最好特别留心这一页，因为你一定会用到那个命令，而且你很可能会忘掉它的语法。有种方便记忆这条命令的方法：记住我们不久前见过的 git push [远程名] [本地分支]:[远程分支] 语法，如果省略 [本地分支]，那就等于是在说“在这里提取空白然后把它变成[远程分支]”。 3.6 分支的衍合把一个分支整合到另一个分支的办法有两种：merge 和 rebase（译注：rebase 的翻译暂定为“衍合”，大家知道就可以了。）。在本章我们会学习什么是衍合，如何使用衍合，为什么衍合操作如此富有魅力，以及我们应该在什么情况下使用衍合。 基本的衍合操作请回顾之前有关合并的一节（见图 3-27），你会看到开发进程分叉到两个不同分支，又各自提交了更新。 Git详解之三 Git分支 图 3-27. 最初分叉的提交历史。之前介绍过，最容易的整合分支的方法是 merge 命令，它会把两个分支最新的快照（C3 和 C4）以及二者最新的共同祖先（C2）进行三方合并，合并的结果是产生一个新的提交对象（C5）。如图 3-28 所示： Git详解之三 Git分支 图 3-28. 通过合并一个分支来整合分叉了的历史。其实，还有另外一个选择：你可以把在 C3 里产生的变化补丁在 C4 的基础上重新打一遍。在 Git 里，这种操作叫做衍合（rebase）。有了 rebase 命令，就可以把在一个分支里提交的改变移到另一个分支里重放一遍。 在上面这个例子中，运行： $ git checkout experiment$ git rebase masterFirst, rewinding head to replay your work on top of it…Applying: added staged command它的原理是回到两个分支最近的共同祖先，根据当前分支（也就是要进行衍合的分支 experiment）后续的历次提交对象（这里只有一个 C3），生成一系列文件补丁，然后以基底分支（也就是主干分支master）最后一个提交对象（C4）为新的出发点，逐个应用之前准备好的补丁文件，最后会生成一个新的合并提交对象（C3’），从而改写 experiment 的提交历史，使它成为 master 分支的直接下游，如图 3-29 所示： Git详解之三 Git分支 图 3-29. 把 C3 里产生的改变到 C4 上重演一遍。现在回到 master 分支，进行一次快进合并（见图 3-30）： Git详解之三 Git分支 图 3-30. master 分支的快进。现在的 C3’ 对应的快照，其实和普通的三方合并，即上个例子中的 C5 对应的快照内容一模一样了。虽然最后整合得到的结果没有任何区别，但衍合能产生一个更为整洁的提交历史。如果视察一个衍合过的分支的历史记录，看起来会更 清楚：仿佛所有修改都是在一根线上先后进行的，尽管实际上它们原本是同时并行发生的。 一般我们使用衍合的目的，是想要得到一个能在远程分支上干净应用的补丁 — 比如某些项目你不是维护者，但想帮点忙的话，最好用衍合：先在自己的一个分支里进行开发，当准备向主项目提交补丁的时候，根据最新的origin/master 进行一次衍合操作然后再提交，这样维护者就不需要做任何整合工作（译注：实际上是把解决分支补丁同最新主干代码之间冲突的责任，化转为由提交补丁的人来解决。），只需根据你提供的仓库地址作一次快进合并，或者直接采纳你提交的补丁。 请注意，合并结果中最后一次提交所指向的快照，无论是通过衍合，还是三方合并，都会得到相同的快照内容，只不过提交历史不同罢了。衍合是按照每行的修改次序重演一遍修改，而合并是把最终结果合在一起。 有趣的衍合衍合也可以放到其他分支进行，并不一定非得根据分化之前的分支。以图 3-31 的历史为例，我们为了给服务器端代码添加一些功能而创建了特性分支 server，然后提交 C3 和 C4。然后又从 C3 的地方再增加一个client 分支来对客户端代码进行一些相应修改，所以提交了 C8 和 C9。最后，又回到 server 分支提交了 C10。 Git详解之三 Git分支 图 3-31. 从一个特性分支里再分出一个特性分支的历史。假设在接下来的一次软件发布中，我们决定先把客户端的修改并到主线中，而暂缓并入服务端软件的修改（因为还需要进一步测试）。这个时候，我们就可以把基于 server 分支而非 master 分支的改变（即 C8 和 C9），跳过 server 直接放到master 分支中重演一遍，但这需要用 git rebase 的 –onto 选项指定新的基底分支master： $ git rebase –onto master server client这好比在说：“取出 client 分支，找出 client 分支和 server 分支的共同祖先之后的变化，然后把它们在master 上重演一遍”。是不是有点复杂？不过它的结果如图 3-32 所示，非常酷（译注：虽然 client 里的 C8, C9 在 C3 之后，但这仅表明时间上的先后，而非在 C3 修改的基础上进一步改动，因为server 和 client 这两个分支对应的代码应该是两套文件，虽然这么说不是很严格，但应理解为在 C3 时间点之后，对另外的文件所做的 C8，C9 修改，放到主干重演。）： Git详解之三 Git分支 图 3-32. 将特性分支上的另一个特性分支衍合到其他分支。现在可以快进 master 分支了（见图 3-33）： $ git checkout master$ git merge clientGit详解之三 Git分支 图 3-33. 快进 master 分支，使之包含 client 分支的变化。现在我们决定把 server 分支的变化也包含进来。我们可以直接把 server 分支衍合到 master，而不用手工切换到 server 分支后再执行衍合操作 — git rebase [主分支] [特性分支] 命令会先取出特性分支server，然后在主分支 master 上重演： $ git rebase master server于是，server 的进度应用到 master 的基础上，如图 3-34 所示： Git详解之三 Git分支 图 3-34. 在 master 分支上衍合 server 分支。然后就可以快进主干分支 master 了： $ git checkout master$ git merge server现在 client 和 server 分支的变化都已经集成到主干分支来了，可以删掉它们了。最终我们的提交历史会变成图 3-35 的样子： $ git branch -d client$ git branch -d serverGit详解之三 Git分支 图 3-35. 最终的提交历史衍合的风险呃，奇妙的衍合也并非完美无缺，要用它得遵守一条准则： 一旦分支中的提交对象发布到公共仓库，就千万不要对该分支进行衍合操作。 如果你遵循这条金科玉律，就不会出差错。否则，人民群众会仇恨你，你的朋友和家人也会嘲笑你，唾弃你。 在进行衍合的时候，实际上抛弃了一些现存的提交对象而创造了一些类似但不同的新的提交对象。如果你把原来分支中的提交对象发布出去，并且其他人更新下载后在其基础上开展工作，而稍后你又用git rebase 抛弃这些提交对象，把新的重演后的提交对象发布出去的话，你的合作者就不得不重新合并他们的工作，这样当你再次从他们那里获取内容时，提交历史就会变得一团糟。 下面我们用一个实际例子来说明为什么公开的衍合会带来问题。假设你从一个中央服务器克隆然后在它的基础上搞了一些开发，提交历史类似图 3-36 所示： Git详解之三 Git分支 图 3-36. 克隆一个仓库，在其基础上工作一番。现在，某人在 C1 的基础上做了些改变，并合并他自己的分支得到结果 C6，推送到中央服务器。当你抓取并合并这些数据到你本地的开发分支中后，会得到合并结果 C7，历史提交会变成图 3-37 这样： Git详解之三 Git分支 图 3-37. 抓取他人提交，并入自己主干。接下来，那个推送 C6 上来的人决定用衍合取代之前的合并操作；继而又用 git push –force 覆盖了服务器上的历史，得到 C4’。而之后当你再从服务器上下载最新提交后，会得到： Git详解之三 Git分支 图 3-38. 有人推送了衍合后得到的 C4’，丢弃了你作为开发基础的 C4 和 C6。下载更新后需要合并，但此时衍合产生的提交对象 C4’ 的 SHA-1 校验值和之前 C4 完全不同，所以 Git 会把它们当作新的提交对象处理，而实际上此刻你的提交历史 C7 中早已经包含了 C4 的修改内容，于是合并操作会把 C7 和 C4’ 合并为 C8（见图 3-39）: Git详解之三 Git分支 图 3-39. 你把相同的内容又合并了一遍，生成一个新的提交 C8。C8 这一步的合并是迟早会发生的，因为只有这样你才能和其他协作者提交的内容保持同步。而在 C8 之后，你的提交历史里就会同时包含 C4 和 C4’，两者有着不同的 SHA-1 校验值，如果用git log 查看历史，会看到两个提交拥有相同的作者日期与说明，令人费解。而更糟的是，当你把这样的历史推送到服务器后，会再次把这些衍合后的提交引入到中央服务 器，进一步困扰其他人（译注：这个例子中，出问题的责任方是那个发布了 C6 后又用衍合发布 C4’ 的人，其他人会因此反馈双重历史到共享主干，从而混淆大家的视听。）。 如果把衍合当成一种在推送之前清理提交历史的手段，而且仅仅衍合那些尚未公开的提交对象，就没问题。如果衍合那些已经公开的提交对象，并且已经有人基于这些提交对象开展了后续开发工作的话，就会出现叫人沮丧的麻烦。 3.7 小结读到这里，你应该已经学会了如何创建分支并切换到新分支，在不同分支间转换，合并本地分支，把分支推送到共享服务器上，使用共享分支与他人协作，以及在分享之前进行衍合。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Git分支</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用操作]]></title>
    <url>%2F2017%2F07%2F14%2FGit%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[1. clone1git clone git远程仓库地址 2. 分支分支是Git的重要特性。 2.1. 本地分支12345678// 1. 新建分支git branch 分支名// 2. 切换到分支git checkout 分支名// 3. 删除分支git branch -D 分支名 2.2. 远程分支2.2.1. 新建远程分支可以直接在仓库里面新建远程分支，也可以直接将本地分支推送到远程分支，如果本地分支对应的远程分支不存在，会自动创建同名的远程分支，如下所示：1git push origin server_branch 运行上面的命令，会在远程仓库创建server_branch分支，同时将本地分支推送到远程仓库的server_branch。 2.2.2. 本地分支跟踪远程分支1git branch --set-upstream-to=origin/远程分支名 本地分支名 将本地分支跟踪远程分支后，就可以直接在当前分支使用 git push / git pull 来 推送 / 拉取 代码了。 反之，如果没有跟踪远程分支，则需要手动指定远程仓库和分支：12git push origin 分支名git pull ogigin 分支名 当然，git clone 后，会自动将master分支跟踪 origin/master，所以如果是master分支，则可以直接使用 git push / git pull。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[debug]]></title>
    <url>%2F2017%2F07%2F07%2Fdebug%2F</url>
    <content type="text"><![CDATA[这是一篇测试文档以上会显示在摘要中以下不会显示在摘要中 1. 标题测试以下是标题测试 1.1. 二级标题二级标题的内容 2. 功能测试以下是功能测试 2.1. 代码块以下是代码块 12345public class SitemapDom &#123; public static void main(String[] args) &#123; System.out.println("Hello, world!"); &#125; &#125; 代码块结束 2.2. 引用块以下是引用块 引用块 2.3. 特殊引用块这里是特殊引用，样式为 default 这里是特殊引用，样式为 primary 这里是特殊引用，样式为 success 这里是特殊引用，样式为 info 这里是特殊引用，样式为 warning 这里是特殊引用，样式为 danger 其中，class_name 可以是以下列表中的一个值： default primary success info warning danger 2.4. 文本居中引用 blah blah blah blah blah blah blah blah blah 2.5. 有序列表有序列表如下： 列表1 列表2 列表3 列表4 列表5 content]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Executor详解]]></title>
    <url>%2F2017%2F07%2F06%2FExecutor%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. 概述Executor 框架是 juc 里提供的线程池的实现。前两天看了下 Executor 框架的一些源码，做个简单的总结。 线程池大概的思路是维护一个可复用的资源池用于执行提交的任务。我理解池的技术的主要意义有两个： 资源的控制，如并发量限制。像数据库连接池这种是对数据库资源的保护； 资源的有效利用，如线程复用，避免频繁创建线程和线程上下文切换。 那么想象中设计一个线程池就需要有线程池大小、线程生命周期管理、等待队列等等功能，下面结合代码看看原理。 Excutor 整体结构如下：Executor 接口定义了最基本的 execute 方法，用于接收用户提交任务。 ExecutorService 定义了线程池终止和创建及提交 futureTask 任务支持的方法。 AbstractExecutorService 是抽象类，主要实现了 ExecutorService 和 futureTask 相关的一些任务创建和提交的方法。 ThreadPoolExecutor 是最核心的一个类，是线程池的内部实现。线程池的功能都在这里实现了，平时用的最多的基本就是这个了。其源码很精练，远没当时想象的多。 ScheduledThreadPoolExecutor 在 ThreadPoolExecutor 的基础上提供了支持定时调度的功能。线程任务可以在一定延时时间后才被触发执行。 2. ThreadPoolExecutor 原理2.1. ThreadPoolExecutor重要属性首先介绍ThreadPoolExecutor内部的几个重要属性，详见下文所述。 2.1.1. 线程池本身的状态12345volatile int runState; static final int RUNNING = 0; static final int SHUTDOWN = 1; static final int STOP = 2; static final int TERMINATED = 3; 2.1.2. 等待任务队列和工作集12private final BlockingQueue&lt;Runnable&gt; workQueue; //等待被执行的Runnable任务 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //正在被执行的Worker任务集 2.1.3. 线程池的主要状态锁。线程池内部的状态变化 ( 如线程大小 ) 都需要基于此锁。1private final ReentrantLock mainLock = new ReentrantLock(); 2.1.4. 线程的存活时间和大小123456private volatile long keepAliveTime;// 线程存活时间 private volatile boolean allowCoreThreadTimeOut;// 是否允许核心线程存活 private volatile int corePoolSize;// 核心池大小 private volatile int maximumPoolSize; // 最大池大小 private volatile int poolSize; //当前池大小 private int largestPoolSize; //最大池大小，区别于maximumPoolSize，是用于记录线程池曾经达到过的最大并发,理论上小于等于maximumPoolSize。 2.1.5. 线程工厂和拒绝策略12private volatile RejectedExecutionHandler handler;// 拒绝策略，用于当线程池无法承载新线程是的处理策略。 private volatile ThreadFactory threadFactory;// 线程工厂，用于在线程池需要新创建线程的时候创建线程 2.1.6. 线程池完成任务数1private long completedTaskCount;//线程池运行到当前完成的任务数总和 2.2. ThreadPoolExecutor 的内部工作原理有了以上定义好的数据，下面来看看内部是如何实现的 。 Doug Lea 的整个思路总结起来就是 5 句话： 如果当前池大小 poolSize 小于 corePoolSize ，则创建新线程执行任务。 如果当前池大小 poolSize 大于 corePoolSize ，且等待队列未满，则进入等待队列 如果当前池大小 poolSize 大于 corePoolSize 且小于 maximumPoolSize ，且等待队列已满，则创建新线程执行任务。 如果当前池大小 poolSize 大于 corePoolSize 且大于 maximumPoolSize ，且等待队列已满，则调用拒绝策略来处理该任务。 线程池里的每个线程执行完任务后不会立刻退出，而是会去检查下等待队列里是否还有线程任务需要执行，如果在 keepAliveTime 里等不到新的任务了，那么线程就会退出。 下面看看代码实现。线程池最重要的方法是由 Executor 接口定义的 execute 方法 , 是任务提交的入口。我们看看 ThreadPoolExecutor.execute(Runnable cmd) 的实现： 123456789101112public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated &#125; &#125; 解释如下：当提交一个新的 Runnable 任务： 2.2.1. 分支1如果当前池大小小于 corePoolSize, 执行 addIfUnderCorePoolSize(command) , 如果线程池处于运行状态且 poolSize &lt; corePoolSize addIfUnderCorePoolSize(command) 会做如下事情，将 Runnable 任务封装成 Worker 任务 , 创建新的 Thread ，执行 Worker 任务。如果不满足条件，则返回 false 。代码如下： 123456789101112131415private boolean addIfUnderCorePoolSize(Runnable firstTask) &#123; Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); &#125; finally &#123; mainLock.unlock(); &#125; if (t == null) return false; t.start(); return true; &#125; 2.2.2. 分支2如果大于 corePoolSize 或 1 失败失败，则： 如果等待队列未满，把 Runnable 任务加入到 workQueue 等待队列 workQueue .offer(command); 如多等待队列已经满了，调用 addIfUnderMaximumPoolSize(command) ，和 addIfUnderCorePoolSize 基本类似，只不过判断条件是 poolSize &lt; maximumPoolSize 。 如果大于 maximumPoolSize ，则把 Runnable 任务交由 RejectedExecutionHandler 来处理。 问题：如何实现线程的复用 ? Doug Lea 的实现思路是 线程池里的每个线程执行完任务后不立刻退出，而是去检查下等待队列里是否还有线程任务需要执行，如果在 keepAliveTime 里等不到新的任务了，那么线程就会退出。这个功能的实现 关键在于 Worker 。线程池在执行 Runnable 任务的时候，并不是单纯地把 Runnable 任务交给一个创建的 Thread 。而是会把 Runnable 任务封装成 Worker 任务。 下面看看 Worker 的实现。代码很简单，可以看出， worker 里面包装了 firstTask 属性，在构造worker 的时候传进来的那个 Runnable 任务就是 firstTask 。 同时也实现了Runnable接口，所以是个代理模式，看看代理增加了哪些功能。 关键看 woker 的 run 方法： 123456789101112public void run() &#123; try &#123; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); &#125; &#125; 可以看出 worker 的 run 方法是一个循环，第一次循环运行的必然是 firstTask ，在运行完 firstTask 之后，并不会立刻结束，而是会调用 getTask 获取新的任务（ getTask 会从等待队列里获取等待中的任务），如果 keepAliveTime 时间内得到新任务则继续执行，得不到新任务则那么线程才会退出。这样就保证了多个任务可以复用一个线程，而不是每次都创建新任务。 keepAliveTime 的逻辑在哪里实现的呢？主要是利用了 BlockingQueue 的 poll 方法支持等待。可看 getTask 的代码段： 123456if (state == SHUTDOWN) // Help drain queue r = workQueue.poll(); else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS); else r = workQueue.take(); 2.3. ThreadFactory 和R ejectedExecutionHandlerThreadFactory 和 RejectedExecutionHandler是ThreadPoolExecutor的两个属性，也 可以认为是两个简单的扩展点 . ThreadFactory 是创建线程的工厂。默认的线程工厂会创建一个带有“ pool-poolNumber-thread-threadNumber ”为名字的线程，如果我们有特别的需要，如线程组命名、优先级等，可以定制自己的ThreadFactory 。 RejectedExecutionHandler 是拒绝的策略。常见有以下几种： AbortPolicy ：不执行，会抛出 RejectedExecutionException 异常。 CallerRunsPolicy ：由调用者（调用线程池的主线程）执行。 DiscardOldestPolicy ：抛弃等待队列中最老的。 DiscardPolicy: 不做任何处理，即抛弃当前任务。 2.4. ScheduledThreadPoolExecutorScheduleThreadPoolExecutor 是对ThreadPoolExecutor的集成。增加了定时触发线程任务的功能。需要注意从内部实现看， ScheduleThreadPoolExecutor 使用的是 corePoolSize 线程和一个无界队列的固定大小的池，所以调整 maximumPoolSize 没有效果。无界队列是一个内部自定义的 DelayedWorkQueue 。 ScheduleThreadPoolExecutor 线程池接收定时任务的方法是 schedule ，看看内部实现： 123456789101112public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); delayedExecute(t); return t; &#125; 以上代码会初始化一个 RunnableScheduledFuture 类型的任务 t, 并交给 delayedExecute 方法。 delayedExecute(t) 方法实现如下： 12345678910private void delayedExecute(Runnable command) &#123; if (isShutdown()) &#123; reject(command); return; &#125; if (getPoolSize() &lt; getCorePoolSize()) prestartCoreThread(); super.getQueue().add(command); &#125; 如果当前线程池大小 poolSize 小于 CorePoolSize ，则创建一个新的线程，注意这里创建的线程是空的，不会把任务直接交给线程来做，而是把线程任务放到队列里。因为任务是要定时触发的，所以不能直接交给线程去执行。 问题： 那如何做到定时触发呢？ 关键在于DelayedWorkQueue,它代理了 DelayQueue 。可以认为 DelayQueue 是这样一个队列（具体可以去看下源码，不详细分析）： 队列里的元素按照任务的 delay 时间长短升序排序， delay 时间短的在队头， delay 时间长的在队尾。 从 DelayQueue 里 FIFO 的获取一个元素的时候，不会直接返回 head 。可能会阻塞，等到 head 节点到达 delay 时间后才能被获取。可以看下 DelayQueue 的 take 方法实现： 12345678910111213141516171819202122232425public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; E first = q.peek(); if (first == null) &#123; available.await(); &#125; else &#123; long delay = first.getDelay(TimeUnit.NANOSECONDS); if (delay &gt; 0) &#123; long tl = available.awaitNanos(delay);//等待delay时间 &#125; else &#123; E x = q.poll(); assert x != null; if (q.size() != 0) available.signalAll(); // wake up other takers return x; &#125; &#125; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; 3. 线程池使用策略通过以上的详解基本上能够定制出自己需要的策略了，下面简单介绍下Executors里面提供的一些常见线程池策略： 3.1. FixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 实际上就是个不支持keepalivetime，且corePoolSize和maximumPoolSize相等的线程池。 3.2. SingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 实际上就是个不支持keepalivetime，且corePoolSize和maximumPoolSize都等1的线程池。 3.3. CachedThreadPool12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 实际上就是个支持keepalivetime时间是60秒（线程空闲存活时间），且corePoolSize为0，maximumPoolSize无穷大的线程池。 3.4. SingleThreadScheduledExecutor1234public static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory) &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1, threadFactory)); &#125; 实际上是个corePoolSize为1的ScheduledExecutor。上文说过ScheduledExecutor采用无界等待队列，所以maximumPoolSize没有作用。 3.5. ScheduledThreadPool123public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125; 实际上是corePoolSize课设定的ScheduledExecutor。上文说过ScheduledExecutor采用无界等待队列，所以maximumPoolSize没有作用。 以上还不一定满足你的需要，完全可以根据自己需要去定制。 4. 参考资料 ITEye博客]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShadowsocksX使用指南]]></title>
    <url>%2F2016%2F10%2F21%2FShadowsocksX%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[0.1. Mac篇 0.1.1. 安装ShadowsocksX可以自行去官网下载最新的ShadowsocksX客户端，也可以用下面提供的链接下载： 点我下载 点击上面的链接下载之后，安装即可 0.1.2. 配置第一次打开就会提示让输入服务器，密码之类的信息，咱们先关闭它。 找到小飞机菜单，在屏幕右上角状态栏。（注意，有些小伙伴发现有两个甚至三个小飞机，要把它们退出才可以正常使用的） 找到服务器-打开服务器设定 打开服务器设定后，点击+号 添加服务器信息，依次输入地址、端口（图上的808要就是端口）、加密选项以及密码，然后点击确定保存 最后确认下 小飞机在打开状态下，代理模式为自动模式，而且已选中刚才配置的服务器，打开浏览器试试谷歌YouTube吧。。 0.2. 其他配置说明0.2.1. 代理模式从上图中我们看到，ShadowsocksX有两种工作模式： 自动代理模式 全局模式 自动代理模式，简单来说就是墙内的网址不会走ShadowsocksX代理，而墙外的网址会走ShadowsocksX代理。自动代理模式比较智能，也比较省流量（墙内的流量不计入ShadowsocksX代理）。 而ShadowsocksX是如何区分墙内还是墙外的呢？可以看到上图中的GFW List Pac,是根据这个文件来区分的，详细的可以自己去百度、谷歌。 总结一点，一般日常使用自动代理模式，如果代理模式下某些网站打不开，可以切换到全局模式（这种模式会强制所有请求都走ShadowsocksX代理，也就是说访问百度等国内网站也会走代理，所以会比较慢），记得使用完后要切回自动代理模式！]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java内存模型（五）——锁]]></title>
    <url>%2F2016%2F10%2F17%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%E9%94%81%2F</url>
    <content type="text"><![CDATA[0.1. 锁的释放-获取建立的happens before 关系锁是java并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。下面是锁释放-获取的示例代码：123456789101112class MonitorExample &#123; int a = 0; public synchronized void writer() &#123; //1 a++; //2 &#125; //3 public synchronized void reader() &#123; //4 int i = a; //5 …… &#125; //6&#125; 假设线程A执行writer()方法，随后线程B执行reader()方法。根据happens before规则，这个过程包含的happens before 关系可以分为3类： 根据程序次序规则，1 happens before 2, 2 happens before 3; 4 happens before 5, 5 happens before 6。 根据监视器锁规则，3 happens before 4。 根据happens before 的传递性，2 happens before 5。 上述happens before 关系的图形化表现形式如下： 在上图中，每一个箭头链接的两个节点，代表了一个happens before 关系。黑色箭头表示程序顺序规则；橙色箭头表示监视器锁规则；蓝色箭头表示组合这些规则后提供的happens before保证。 上图表示在线程A释放了锁之后，随后线程B获取同一个锁。在上图中，2 happens before 5。因此，线程A在释放锁之前所有可见的共享变量，在线程B获取同一个锁之后，将立刻变得对B线程可见。 0.2. 锁释放和获取的内存语义当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。以上面的MonitorExample程序为例，A线程释放锁后，共享数据的状态示意图如下： 当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须要从主内存中去读取共享变量。下面是锁获取的状态示意图： 对比锁释放-获取的内存语义与volatile写-读的内存语义，可以看出：锁释放与volatile写有相同的内存语义；锁获取与volatile读有相同的内存语义。 下面对锁释放和锁获取的内存语义做个总结： 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。 0.3. 锁内存语义的实现本文将借助ReentrantLock的源代码，来分析锁内存语义的具体实现机制。 请看下面的示例代码：1234567891011121314151617181920212223class ReentrantLockExample &#123; int a = 0; ReentrantLock lock = new ReentrantLock(); public void writer() &#123; lock.lock(); //获取锁 try &#123; a++; &#125; finally &#123; lock.unlock(); //释放锁 &#125; &#125; public void reader () &#123; lock.lock(); //获取锁 try &#123; int i = a; // …… &#125; finally &#123; lock.unlock(); //释放锁 &#125; &#125;&#125; 在ReentrantLock中，调用lock()方法获取锁；调用unlock()方法释放锁。 ReentrantLock的实现依赖于java同步器框架AbstractQueuedSynchronizer（本文简称之为AQS）。AQS使用一个整型的volatile变量（命名为state）来维护同步状态，马上我们会看到，这个volatile变量是ReentrantLock内存语义实现的关键。 下面是ReentrantLock的类图（仅画出与本文相关的部分）： ReentrantLock分为公平锁和非公平锁，我们首先分析公平锁。 0.3.1. 公平锁 使用公平锁时，加锁方法lock()的方法调用轨迹如下：1234ReentrantLock : lock()FairSync : lock()AbstractQueuedSynchronizer : acquire(int arg)ReentrantLock : tryAcquire(int acquires) 在第4步真正开始加锁，下面是该方法的源代码：1234567891011121314151617181920protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); //获取锁的开始，首先读volatile变量state if (c == 0) &#123; if (isFirst(current) &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 从上面源代码中我们可以看出，加锁方法首先读volatile变量state。 在使用公平锁时，解锁方法unlock()的方法调用轨迹如下：123ReentrantLock : unlock()AbstractQueuedSynchronizer : release(int arg)Sync : tryRelease(int releases) 在第3步真正开始释放锁，下面是该方法的源代码：123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); //释放锁的最后，写volatile变量state return free;&#125; 从上面的源代码我们可以看出，在释放锁的最后写volatile变量state。 公平锁在释放锁的最后写volatile变量state；在获取锁时首先读这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变的对获取锁的线程可见。 0.3.2. 非公平锁 现在我们分析非公平锁的内存语义的实现。 非公平锁的释放和公平锁完全一样，所以这里仅仅分析非公平锁的获取。 使用公平锁时，加锁方法lock()的方法调用轨迹如下：123ReentrantLock : lock()NonfairSync : lock()AbstractQueuedSynchronizer : compareAndSetState(int expect, int update) 在第3步真正开始加锁，下面是该方法的源代码：123protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 该方法以原子操作的方式更新state变量，本文把java的compareAndSet()方法调用简称为CAS。JDK文档对该方法的说明如下：如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值。此操作具有 volatile 读和写的内存语义。 这里我们分别从编译器和处理器的角度来分析,CAS如何同时具有volatile读和volatile写的内存语义。 前文我们提到过，编译器不会对volatile读与volatile读后面的任意内存操作重排序；编译器不会对volatile写与volatile写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现volatile读和volatile写的内存语义，编译器不能对CAS与CAS前面和后面的任意内存操作重排序。 下面我们来分析在常见的intel x86处理器中，CAS是如何同时具有volatile读和volatile写的内存语义的。 下面是sun.misc.Unsafe类的compareAndSwapInt()方法的源代码：123public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 可以看到这是个本地方法调用。这个本地方法在openjdk中依次调用的c++代码为：123unsafe.cppatomic.cppatomicwindowsx86.inline.hpp 这个本地方法的最终实现在openjdk的如下位置： openjdk-7-fcs-src-b147-27jun2011\openjdk\hotspot\src\oscpu\windowsx86\vm\ atomicwindowsx86.inline.hpp （对应于windows操作系统，X86处理器）。下面是对应于intel x86处理器的源代码的片段：1234567891011121314151617181920// Adding a lock prefix to an instruction on MP machine// VC++ doesn't like the lock prefix to be on a single line// so we can't insert a label after the lock prefix.// By emitting a lock prefix, we can define a label after it.#define LOCK_IF_MP(mp) __asm cmp mp, 0 \ __asm je L0 \ __asm _emit 0xF0 \ __asm L0:inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm &#123; mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx &#125;&#125; 如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。 intel的手册对lock前缀的说明如下： 确保对内存的读-改-写操作原子执行。在Pentium及Pentium之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存。很显然，这会带来昂贵的开销。从Pentium 4，Intel Xeon及P6处理器开始，intel在原有总线锁的基础上做了一个很有意义的优化：如果要访问的内存区域（area of memory）在lock前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或以修改状态），并且该内存区域被完全包含在单个缓存行（cache line）中，那么处理器将直接执行该指令。由于在指令执行期间该缓存行会一直被锁定，其它处理器无法读/写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做缓存锁定（cache locking），缓存锁定将大大降低lock前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线。 禁止该指令与之前和之后的读和写指令重排序。 把写缓冲区中的所有数据刷新到内存中。 上面的第2点和第3点所具有的内存屏障效果，足以同时实现volatile读和volatile写的内存语义。 经过上面的这些分析，现在我们终于能明白为什么JDK文档说CAS同时具有volatile读和volatile写的内存语义了。 现在对公平锁和非公平锁的内存语义做个总结： 公平锁和非公平锁释放时，最后都要写一个volatile变量state。 公平锁获取时，首先会去读这个volatile变量。 非公平锁获取时，首先会用CAS更新这个volatile变量,这个操作同时具有volatile读和volatile写的内存语义。 从本文对ReentrantLock的分析可以看出，锁释放-获取的内存语义的实现至少有下面两种方式： 利用volatile变量的写-读所具有的内存语义。 利用CAS所附带的volatile读和volatile写的内存语义。 0.4. concurrent包的实现由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式： A线程写volatile变量，随后B线程读这个volatile变量。 A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式： 首先，声明共享变量为volatile； 然后，使用CAS的原子条件更新来实现线程之间的同步； 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。 AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下：]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java内存模型（四）——volatile]]></title>
    <url>%2F2016%2F10%2F17%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94volatile%2F</url>
    <content type="text"><![CDATA[0.1. volatile的特性当我们声明共享变量为volatile后，对这个变量的读/写将会很特别。理解volatile特性的一个好方法是：把对volatile变量的单个读/写，看成是使用同一个监视器锁对这些单个读/写操作做了同步。下面我们通过具体的示例来说明，请看下面的示例代码：123456789101112131415class VolatileFeaturesExample &#123; volatile long vl = 0L; //使用volatile声明64位的long型变量 public void set(long l) &#123; vl = l; //单个volatile变量的写 &#125; public void getAndIncrement () &#123; vl++; //复合（多个）volatile变量的读/写 &#125; public long get() &#123; return vl; //单个volatile变量的读 &#125;&#125; 假设有多个线程分别调用上面程序的三个方法，这个程序在语意上和下面程序等价：1234567891011121314151617class VolatileFeaturesExample &#123; long vl = 0L; // 64位的long型普通变量 public synchronized void set(long l) &#123; //对单个的普通 变量的写用同一个监视器同步 vl = l; &#125; public void getAndIncrement () &#123; //普通方法调用 long temp = get(); //调用已同步的读方法 temp += 1L; //普通写操作 set(temp); //调用已同步的写方法 &#125; public synchronized long get() &#123; //对单个的普通变量的读用同一个监视器同步 return vl; &#125;&#125; 如上面示例程序所示，对一个volatile变量的单个读/写操作，与对一个普通变量的读/写操作使用同一个监视器锁来同步，它们之间的执行效果相同。 监视器锁的happens-before规则保证释放监视器和获取监视器的两个线程之间的内存可见性，这意味着对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 监视器锁的语义决定了临界区代码的执行具有原子性。这意味着即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读写就将具有原子性。如果是多个volatile操作或类似于volatile++这种复合操作，这些操作整体上不具有原子性。 简而言之，volatile变量自身具有下列特性： 可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。 0.2. volatile写-读建立的happens before关系上面讲的是volatile变量自身的特性，对程序员来说，volatile对线程的内存可见性的影响比volatile自身的特性更为重要，也更需要我们去关注。 从JSR-133开始，volatile变量的写-读可以实现线程之间的通信。 从内存语义的角度来说，volatile与监视器锁有相同的效果：volatile写和监视器的释放有相同的内存语义；volatile读与监视器的获取有相同的内存语义。 请看下面使用volatile变量的示例代码：12345678910111213141516class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; //1 flag = true; //2 &#125; public void reader() &#123; if (flag) &#123; //3 int i = a; //4 …… &#125; &#125;&#125; 假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens before规则，这个过程建立的happens before 关系可以分为两类： 根据程序次序规则，1 happens before 2; 3 happens before 4; 根据volatile规则，2 happens before 3; 根据happens before 的传递性规则，1 happens before 4。 上述happens before 关系的图形化表现形式如下： 在上图中，每一个箭头链接的两个节点，代表了一个happens before 关系。黑色箭头表示程序顺序规则；橙色箭头表示volatile规则；蓝色箭头表示组合这些规则后提供的happens before保证。 这里A线程写一个volatile变量后，B线程读同一个volatile变量。A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，将立即变得对B线程可见。 0.3. volatile写-读的内存语义volatile写的内存语义如下： 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。 以上面示例程序VolatileExample为例，假设线程A首先执行writer()方法，随后线程B执行reader()方法，初始时两个线程的本地内存中的flag和a都是初始状态。下图是线程A执行volatile写后，共享变量的状态示意图： 如上图所示，线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值被刷新到主内存中。此时，本地内存A和主内存中的共享变量的值是一致的。 volatile读的内存语义如下： 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 下面是线程B读同一个volatile变量后，共享变量的状态示意图： 如上图所示，在读flag变量后，本地内存B已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值也变成一致的了。 如果我们把volatile写和volatile读这两个步骤综合起来看的话，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。 下面对volatile写和volatile读的内存语义做个总结： 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所在修改的）消息。 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。 0.4. volatile内存语义的实现下面，让我们来看看JMM如何实现volatile写/读的内存语义。 前文我们提到过重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型。下面是JMM针对编译器制定的volatile重排序规则表： 举例来说，第三行最后一个单元格的意思是：在程序顺序中，当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作。 从上表我们可以看出： 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略： 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图： 上图中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。 这里比较有意思的是volatile写后面的StoreLoad屏障。这个屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面，是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。 为了保证能正确实现volatile的内存语义，JMM在这里采取了保守策略：在每个volatile写的后面或在每个volatile读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里我们可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。 下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图： 上图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。 上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面我们通过具体的示例代码来说明：123456789101112131415class VolatileBarrierExample &#123; int a; volatile int v1 = 1; volatile int v2 = 2; void readAndWrite() &#123; int i = v1; //第一个volatile读 int j = v2; // 第二个volatile读 a = i + j; //普通写 v1 = i + 1; // 第一个volatile写 v2 = j * 2; //第二个 volatile写 &#125; … //其他方法&#125; 针对readAndWrite()方法，编译器在生成字节码时可以做如下的优化：! 注意，最后的StoreLoad屏障不能省略。因为第二个volatile写之后，方法立即return。此时编译器可能无法准确断定后面是否会有volatile读或写，为了安全起见，编译器常常会在这里插入一个StoreLoad屏障。 上面的优化是针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以x86处理器为例，上图中除最后的StoreLoad屏障外，其它的屏障都会被省略。 前面保守策略下的volatile读和写，在 x86处理器平台可以优化成： 前文提到过，x86处理器仅会对写-读操作做重排序。X86不会对读-读，读-写和写-写操作做重排序，因此在x86处理器中会省略掉这三种操作类型对应的内存屏障。在x86中，JMM仅需在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。这意味着在x86处理器中，volatile写的开销比volatile读的开销会大很多（因为执行StoreLoad屏障开销会比较大）。 0.5. JSR-133为什么要增强volatile的内存语义在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量之间重排序。在旧的内存模型中，VolatileExample示例程序可能被重排序成下列时序来执行： 在旧的内存模型中，当1和2之间没有数据依赖关系时，1和2之间就可能被重排序（3和4类似）。其结果就是：读线程B执行4时，不一定能看到写线程A在执行1时对共享变量的修改。 因此在旧的内存模型中 ，volatile的写-读没有监视器的释放-获所具有的内存语义。为了提供一种比监视器锁更轻量级的线程之间通信的机制，JSR-133专家组决定增强volatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序，确保volatile的写-读和监视器的释放-获取一样，具有相同的内存语义。从编译器重排序规则和处理器内存屏障插入策略来看，只要volatile变量与普通变量之间的重排序可能会破坏volatile的内存语意，这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。 由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而监视器锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，监视器锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。如果读者想在程序中用volatile代替监视器锁，请一定谨慎。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java内存模型（三）——顺序一致性]]></title>
    <url>%2F2016%2F10%2F16%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%2F</url>
    <content type="text"><![CDATA[0.1. 数据竞争与顺序一致性保证当程序未正确同步时，就会存在数据竞争。java内存模型规范对数据竞争的定义如下： 在一个线程中写一个变量， 在另一个线程读同一个变量， 而且写和读没有通过同步来排序。 当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果（前一章的示例正是如此）。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。 JMM对正确同步的多线程程序的内存一致性做了如下保证： 如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially consistent）—即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同（马上我们将会看到，这对于程序员来说是一个极强的保证）。 这里的同步是指广义上的同步，包括对常用同步原语（lock，volatile和final）的正确使用。 0.2. 顺序一致性内存模型顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 顺序一致性内存模型为程序员提供的视图如下： 在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程。同时，每一个线程必须按程序的顺序来执行内存读/写操作。从上图我们可以看出，在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，图中的开关装置能把所有线程的所有内存读/写操作串行化。 为了更好的理解，下面我们通过两个示意图来对顺序一致性模型的特性做进一步的说明。 假设有两个线程A和B并发执行。其中A线程有三个操作，它们在程序中的顺序是：A1-&gt;A2-&gt;A3。B线程也有三个操作，它们在程序中的顺序是：B1-&gt;B2-&gt;B3。 假设这两个线程使用监视器来正确同步：A线程的三个操作执行后释放监视器，随后B线程获取同一个监视器。那么程序在顺序一致性模型中的执行效果将如下图所示： 现在我们再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的执行示意图： 未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程A和B看到的执行顺序都是：B1-&gt;A1-&gt;A2-&gt;B2-&gt;A3-&gt;B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。 但是，在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。 0.3. 同步程序的顺序一致性效果下面我们对前面的示例程序ReorderExample用监视器来同步，看看正确同步的程序如何具有顺序一致性。 请看下面的示例代码：12345678910111213141516class SynchronizedExample &#123; int a = 0; boolean flag = false; public synchronized void writer() &#123; a = 1; flag = true; &#125; public synchronized void reader() &#123; if (flag) &#123; int i = a; // ... &#125; &#125;&#125; 上面示例代码中，假设A线程执行writer()方法后，B线程执行reader()方法。这是一个正确同步的多线程程序。根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。下面是该程序在两个内存模型中的执行时序对比图： 在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM中，临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM会在退出监视器和进入监视器这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图（具体细节后文会说明）。虽然线程A在临界区内做了重排序，但由于监视器的互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 从这里我们可以看到JMM在具体实现上的基本方针：在不改变（正确同步的）程序执行结果的前提下，尽可能的为编译器和处理器的优化打开方便之门。 0.4. 未同步程序的执行特性对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false），JMM保证线程读操作读取到的值不会无中生有（out of thin air）的冒出来。为了实现最小安全性，JVM在堆上分配对象时，首先会清零内存空间，然后才会在上面分配对象（JVM内部会同步这两个操作）。因此，在以清零的内存空间（pre-zeroed memory）分配对象时，域的默认初始化已经完成了。 JMM不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。因为未同步程序在顺序一致性模型中执行时，整体上是无序的，其执行结果无法预知。保证未同步程序在两个模型中的执行结果一致毫无意义。 和顺序一致性模型一样，未同步程序在JMM中的执行时，整体上也是无序的，其执行结果也无法预知。同时，未同步程序在这两个模型中的执行特性有下面几个差异： 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。 JMM不保证对64位的long型和double型变量的读/写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。 第3个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。 总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和I/O设备执行内存的读/写。下面让我们通过一个示意图来说明总线的工作机制： 如上图所示，假设处理器A，B和C同时向总线发起总线事务，这时总线仲裁（bus arbitration）会对竞争作出裁决，这里我们假设总线在仲裁后判定处理器A在竞争中获胜（总线仲裁会确保所有处理器都能公平的访问内存）。 此时处理器A继续它的总线事务，而其它两个处理器则要等待处理器A的总线事务完成后才能开始再次执行内存访问。假设在处理器A执行总线事务期间（不管这个总线事务是读事务还是写事务），处理器D向总线发起了总线事务，此时处理器D的这个请求会被总线禁止。 总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行；在任意时间点，最多只能有一个处理器能访问内存。这个特性确保了单个总线事务之中的内存读/写操作具有原子性。 在一些32位的处理器上，如果要求对64位数据的读/写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的读/写具有原子性。当JVM在这种处理器上运行时，会把一个64位long/ double型变量的读/写操作拆分为两个32位的读/写操作来执行。这两个32位的读/写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的读/写将不具有原子性。 当单个内存操作不具有原子性，将可能会产生意想不到后果。请看下面示意图： 如上图所示，假设处理器A写一个long型变量，同时处理器B要读这个long型变量。处理器A中64位的写操作被拆分为两个32位的写操作，且这两个32位的写操作被分配到不同的写事务中执行。同时处理器B中64位的读操作被拆分为两个32位的读操作，且这两个32位的读操作被分配到同一个的读事务中执行。当处理器A和B按上图的时序来执行时，处理器B将看到仅仅被处理器A“写了一半“的无效值。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java内存模型（二）——重排序]]></title>
    <url>%2F2016%2F10%2F16%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E9%87%8D%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[0.1. 数据依赖性如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型：写后读、写后写、读后写。上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。 前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序 时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。 注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。 0.2. as-if-serial 语义as-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。 为了遵守 as-if-serial 语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。 为了具体说明，请看下面计算圆面 积的代码示例：123double pi = 3.14; // A double r = 1.0; // B double area = pi * r * r; // C 上面三个操作的数据依赖关系如下图所示：如上图所示，A 和 C 之间存在数据依赖关系，同时 B 和 C 之间也存在数据依赖关 系。因此在最终执行的指令序列中，C 不能被重排序到 A 和 B 的前面（C 排到 A 和 B 的前面，程序的结果将会被改变）。但 A 和 B 之间没有数据依赖关系，编译器和 处理器可以重排序 A 和 B 之间的执行顺序。下图是该程序的两种执行顺序：as-if-serial 语义把单线程程序保护了起来，遵守 as-if-serial 语义的编译器，runtime 和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。 0.3. 程序顺序规则根据 happens- before 的程序顺序规则，上面计算圆的面积的示例代码存在三个 happens- before 关系： A happens- before B； B happens- before C； A happens- before C； 这里的第 3 个 happens- before 关系，是根据 happens- before 的传递性推导出 来的。 这里 A happens- before B，但实际执行时 B 却可以排在 A 之前执行（看上面的 重排序后的执行顺序）。在第一章提到过: 如果 A happens- before B，JMM 并 不要求 A 一定要在 B 之前执行。JMM 仅仅要求前一个操作（执行的结果）对后一 个操作可见，且前一个操作按顺序排在第二个操作之前。 这里操作 A 的执行结果不 需要对操作 B 可见；而且重排序操作 A 和操作 B 后的执行结果，与操作 A 和操作 B 按 happens- before 顺序执行的结果一致。在这种情况下，JMM 会认为这种重 排序并不非法（not illegal），JMM 允许这种重排序。 在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前 提下，尽可能的开发并行度。编译器和处理器遵从这一目标，从 happens- before 的定义我们可以看出，JMM 同样遵从这一目标。 0.4. 重排序对多线程的影响现在让我们来看看，重排序是否会改变多线程程序的执行结果。请看下面的示例代码：12345678910111213141516class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // 1 flag = true; // 2 &#125; public void reader() &#123; if (flag) &#123; //3 int i = a * a; //4 // ... &#125; &#125;&#125; flag 变量是个标记，用来标识变量 a 是否已被写入。这里假设有两个线程 A 和 B， A 首先执行 writer()方法，随后 B 线程接着执行 reader()方法。线程 B 在执行操作 4 时，能否看到线程 A 在操作 1 对共享变量 a 的写入？ 答案是：不一定能看到。 由于操作 1 和操作 2 没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作 3 和操作 4 没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。让我们先来看看，当操作 1 和操作 2 重排序时，可能会产生什么效果？ 请看下面的程序执行时序图：如上图所示，操作 1 和操作 2 做了重排序。程序执行时，线程 A 首先写标记变量flag，随后线程 B 读这个变量。由于条件判断为真，线程 B 将读取变量 a。此时， 变量 a 还根本没有被线程 A 写入，在这里多线程程序的语义被重排序破坏了！ 注：本文统一用红色的虚箭线标识错误的读操作，用绿色的虚箭线标识正确的读 操作。 下面再让我们看看，当操作 3 和操作 4 重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。下面是操作 3 和操作 4 重排序后，程序的执行时 序图：在程序中，操作 3 和操作 4 存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执 行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程 B 的处 理器可以提前读取并计算 a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作 3 的条件判断为真时，就把 该计算结果写入变量 i 中。 从图中我们可以看出，猜测执行实质上对操作 3 和 4 做了重排序。重排序在这里破 坏了多线程程序的语义！ 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是 as- if-serial 语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中， 对存在控制依赖的操作重排序，可能会改变程序的执行结果。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java内存模型（一）——基础篇]]></title>
    <url>%2F2016%2F10%2F15%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[0.1. 并发编程模型的分类在并发编程中，我们需要处理两个关键问题： 1. 线程之间如何通信 2. 线程之间如何同步这里的线程是指并发执行的活动实体，通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种： 1. 共享内存 2. 消息传递 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信；在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之 间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前， 因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行的，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 0.2. Java 内存模型的抽象在java中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指实例域，静态域和数组元素）。 局部变量（Local variables）、方法定义参数（java语言规范称之为formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间 共享，它们不会有内存可见性问题，也不受内存模型的影响。 Java 线程之间的通信由 Java 内存模型（Java Memory Model，简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系： 线程之间的共享变量存储在主内存（Ｍain Memory）中，每个线程都有一个私有的本地内存(Local Memory)，本地内存中存储了该线程以读/写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 Java 内存模型的抽象示意图如下：从上图来看，线程 A 与线程 B 之间如要通信的话，必须要经历下面 2 个步骤： 1. 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去； 2. 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。 下面通过示意图来说明这两个步骤：如上图所示，本地内存 A 和 B 有主内存中共享变量 x 的副本。假设初始时，这三个内存中的 x 值都为 0。线程 A 在执行时，把更新后的 x 值（假设值为 1）临时存放在自己的本地内存 A 中。当线程 A 和线程 B 需要通信时，线程 A 首先会把自己本地内存中修改后的 x 值刷新到主内存中，此时主内存中的 x 值变为了 1。随后，线程 B 到主内存中去读取线程 A 更新后的 x 值，此时线程 B 的本地内存的 x 值也变为了 1。 从整体来看，这两个步骤实质上是线程 A 在向线程 B 发送消息，而且这个通信过程 必须要经过主内存。JMM 通过控制主内存与每个线程的本地内存之间的交互，来 为 java 程序员提供内存可见性保证。 0.3. 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安 排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器 可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操 作看上去可能是在乱序执行。 从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止 特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁 止）。 JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上， 通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见 性保证。 0.4. 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地 址的多次写，可以减少对内存总线的占用。 虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！ 为了具体说明，请看下面示例： 假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时把共享变量写入自己的写缓冲区（A1，B1）， 然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到 x = y = 0 的结果。 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写 缓冲区，因此现代的处理器都会允许对写-读操作重排序。 下面是常见处理器允许的重排序类型的列表： 上表单元格中的“N”表示处理器不允许两个操作重排序，“Y”表示允许重排序。 从上表我们可以看出：常见的处理器都允许 Store-Load 重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO 和 x86 拥有相对较强的处理器内存模型，它们仅允许对写-读操作做重排序（因为它们都使用了写缓冲区）。 注 1：sparc-TSO 是指以 TSO(Total Store Order)内存模型运行时，sparc 处理 器的特性。 注 2：上表中的 x86 包括 x64 及 AMD64。 注 3：由于 ARM 处理器的内存模型与 PowerPC 处理器的内存模型非常类似，本文将忽 略它。 注 4：数据依赖性后文会专门说明。 为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令 来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为下列四类： StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执 行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内 存中（buffer fully flush）。 0.5. happens-before从 JDK5 开始，java 使用新的 JSR-133 内存模型（本文除非特别说明，针对的都是 JSR-133 内存模型）。JSR-133 使用 happens-before 的概念来阐述操作之间的内存可见性。在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在 happens-before 关系。 另外，如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 这里提到的两个操作既可以 是在一个线程之内，也可以是在不同线程之间。与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器的解锁，happens- before 于随后对这个监视器 的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对 这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 注意，两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在 后一个操作之前执行！happens-before 仅仅要求前一个操作执行的结果对后 一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens- before 的定义很微妙，后文会具 体说明 happens-before 为什么要这么定义。 这8条原则摘自《深入理解Java虚拟机》。这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。下面我们来解释一下前4条规则： 第一条规则，程序次序规则，就是一段程序代码的执行在单个线程中看起来是有序的，不管虚拟机或处理器如何对程序代码进行指令重排序，前一个操作的执行结果对后续操作可见。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，而且它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，监视器或锁释放以后，如果后续再获得同一个监视器或锁，那么锁释放之前所作的操作，对获得锁以后的代码可见。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个volatile变量，然后另一个线程去进行读取，那么写入操作的执行结果肯定会对后续的读操作可见。 第四条规则实际上就是体现happens-before原则具备传递性。 happens-before 与 JMM 的关系如下图所示： 如上图所示，一个 happens-before 规则对应于一个或多个编译器和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免 java 程序 员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则 的具体实现。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程：CountDownLatch、CyclicBarrier和Semaphore]]></title>
    <url>%2F2016%2F10%2F13%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ACountDownLatch%E3%80%81CyclicBarrier%E5%92%8CSemaphore%2F</url>
    <content type="text"><![CDATA[在Java 1.5中，提供了一些非常有用的辅助类来帮助我们进行并发编程，比如CountDownLatch，CyclicBarrier和Semaphore，今天我们就来学习一下这三个辅助类的用法。 1. CountDownLatch用法直译过来就是倒计数(CountDown)门闩(Latch)。倒计数不用说，门闩的意思顾名思义就是阻止前进。在这里就是指 CountDownLatch.await() 方法在倒计数为0之前会阻塞当前线程。 CountDownLatch 的作用和 Thread.join() 方法类似，可用于一组线程和另外一组线程的协作。例如，主线程在做一项工作之前需要一系列的准备工作，只有这些准备工作都完成，主线程才能继续它的工作。这些准备工作彼此独立，所以可以并发执行以提高速度。在这个场景下就可以使用 CountDownLatch 协调线程之间的调度了。在直接创建线程的年代（Java 5.0 之前），我们可以使用 Thread.join()。在 JUC 出现后，因为线程池中的线程不能直接被引用，所以就必须使用 CountDownLatch 了。 1.1. CountDownLatch接口CountDownLatch类只提供了一个构造器：1public CountDownLatch(int count) &#123; &#125;; // 参数count为计数值 然后下面这3个方法是CountDownLatch类中最重要的方法：12345678// 调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行public void await() throws InterruptedException &#123; &#125;;// 和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; // 将count值减1public void countDown() &#123; &#125;; 1.2. CountDownLatch应用例子下面看一个例子大家就清楚CountDownLatch的用法了： 下面的这个例子可以理解为 F1 赛车的维修过程，只有 startSignal （可以表示停车，可能名字不太贴合）命令下达之后，维修工才开始干活，只有等所有工人完成工作之后，赛车才能继续。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.wxweven.concurrent;import java.util.concurrent.CountDownLatch;/** * 下面的这个例子可以理解为 F1 赛车的维修过程， 只有 startSignal命令下达之后，维修工才开始干活， * 只有等所有工人（doneSignal）完成工作之后，赛车才能继续 * * * CountDownLatch 适用于一组线程和另一个主线程之间的工作协作。 * 一个主线程等待一组工作线程的任务完毕才继续它的执行是使用CountDownLatch 的主要场景 * * @author wxweven * @date 2016年8月28日 * @version 1.0 * @email wxweven@qq.com * @blog wxweven.com * @Copyright: Copyright (c) wxweven 2009 - 2016 */public class CountDownLatchTest &#123; private static final int WORKER_SIZE = 5; // 定义维修线程的数量 private static CountDownLatch startSignal = new CountDownLatch(1); // 发号施令的计数器 private static CountDownLatch fixSignal = new CountDownLatch(WORKER_SIZE); // 维修线程计数器 public static void main(String[] args) throws InterruptedException &#123; CountDownLatchTest test = new CountDownLatchTest(); System.out.println("正在执行准备工作..."); for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; new Thread(test.new Worker()).start(); &#125; System.out.println("开始修车吧..."); startSignal.countDown(); fixSignal.await(); System.out.println("修车完成了，开始继续上路吧！！！"); &#125; class Worker implements Runnable &#123; @Override public void run() &#123; try &#123; startSignal.await(); // 阻塞在 startSignal上，即等待主线程发号开始维修的施令 beginFix(); // 执行真正的修车方法 fixSignal.countDown(); // 修车完成之后，将Signal减1，用于通知阻塞在fixSignal上的线程 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void beginFix() throws InterruptedException &#123; System.out.println("工作线程 " + Thread.currentThread().getName() + " 在工作..."); Thread.sleep(500); &#125; &#125;&#125; 执行结果：12345678正在执行准备工作...开始修车吧...工作线程 Thread-3 在工作...工作线程 Thread-1 在工作...工作线程 Thread-2 在工作...工作线程 Thread-4 在工作...工作线程 Thread-0 在工作...修车完成了，开始继续上路吧！！！ 2. CyclicBarrier用法CyclicBarrier 翻译过来叫循环栅栏、循环障碍什么的。它主要的方法就是一个：await()。await() 方法每被调用一次，计数便会减少1，并阻塞住当前线程。当计数减至0时，阻塞解除，所有在此 CyclicBarrier 上面阻塞的线程开始运行。在这之后，如果再次调用 await() 方法，计数就又会变成 N-1，新一轮重新开始，这便是 Cyclic 的含义所在。 CyclicBarrier 的使用并不难，但需要注意它所相关的异常。除了常见的异常，CyclicBarrier.await() 方法会抛出一个独有的 BrokenBarrierException。这个异常发生在当某个线程在等待本 CyclicBarrier 时被中断或超时或被重置时，其它同样在这个 CyclicBarrier 上等待的线程便会受到 BrokenBarrierException。意思就是说，同志们，别等了，有个小伙伴已经挂了，咱们如果继续等有可能会一直等下去，所有各回各家吧。 CyclicBarrier.await() 方法带有返回值，用来表示当前线程是第几个到达这个 Barrier 的线程。 和 CountDownLatch 一样，CyclicBarrier 同样可以可以在构造函数中设定总计数值。与 CountDownLatch 不同的是，CyclicBarrier 的构造函数还可以接受一个 Runnable，会在 CyclicBarrier 被释放时执行。 2.1. CyclicBarrier接口CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器：12345public CyclicBarrier(int parties, Runnable barrierAction) &#123;&#125; public CyclicBarrier(int parties) &#123;&#125; 参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容。 然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本：12public int await() throws InterruptedException, BrokenBarrierException &#123; &#125;;public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException &#123; &#125;; 第一个版本比较常用，用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务； 第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。 2.2. CyclicBarrier应用例子下面举几个例子就明白了： 假若有若干个线程对一个数组的不同部分进行赋值，并且只有所有线程都完成赋值之后，才能对数组进行最后的汇总，此时就可以利用CyclicBarrier了：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com.wxweven.concurrent;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;/** * CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例如同时开始一个工作。 * 另外，CyclicBarrier的循环特性和构造函数所接受的 Runnable 参数也是 CountDownLatch 所不具备的 * * 假若有若干个线程对一个数组的不同部分进行赋值，并且只有所有线程都完成赋值之后，才能对数组进行最后的汇总 * * @author wxweven * @date 2016年8月28日 * @version 1.0 * @email wxweven@qq.com * @blog wxweven.com * @Copyright: Copyright (c) wxweven 2009 - 2016 */public class CylicBarrierTest &#123; private static int WORKER_SIZE = 5; private int[] numbers = new int[WORKER_SIZE]; private int sum = 0; private CyclicBarrier cyclicBarrier = new CyclicBarrier(WORKER_SIZE, new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; sum += numbers[i]; &#125; System.out.println(Thread.currentThread().getName() + "最后汇总的结果是：" + sum); &#125; &#125;); public static void main(String[] args) &#123; CylicBarrierTest test = new CylicBarrierTest(); System.out.println("正在执行准备工作..."); for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; new Thread(test.new Worker(i), "线程" + i).start(); &#125; &#125; class Worker implements Runnable &#123; private int index; public Worker(int index) &#123; this.index = index; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + "开始计算..."); try &#123; Thread.sleep(2000); numbers[index] = index; System.out.println(Thread.currentThread().getName() + "完成计算..."); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.println("所有线程都已完成计算，开始汇总..."); &#125; &#125;&#125; 执行结果：1234567891011121314151617正在执行准备工作...线程0开始计算...线程1开始计算...线程2开始计算...线程3开始计算...线程4开始计算...线程2完成计算...线程0完成计算...线程1完成计算...线程3完成计算...线程4完成计算...线程3最后汇总的结果是：10所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总... 从上面输出结果可以看出，每个写入线程对数组赋值完成之后，就在等待其他线程赋值完毕。 当所有线程线程赋值完毕之后，就可以对数组进行汇总操作了。 CyclicBarrier提供的Runnable参数，用于在所有线程工作完成后需要执行的任务，（比如上述例子中，所有线程执行完对数组的赋任务后，还需要执行一个汇总的任务），CyclicBarrier会将该任务 随机分配 给已完成工作的线程去执行（这一点设计也是很优秀的，直接复用之前的线程，而不是再去起新的线程了！），比如示例运行中的线程3。 2.3. CyclicBarrier设置等待超时下面看一下为await指定时间的效果：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.wxweven.concurrent;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.TimeUnit;import java.util.concurrent.TimeoutException;/** * CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例如同时开始一个工作。 * 另外，CyclicBarrier的循环特性和构造函数所接受的 Runnable 参数也是 CountDownLatch 所不具备的 * * 假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情 * * @author wxweven * @date 2016年8月28日 * @version 1.0 * @email wxweven@qq.com * @blog wxweven.com * @Copyright: Copyright (c) wxweven 2009 - 2016 */public class CylicBarrierTest &#123; private static int WORKER_SIZE = 5; private int[] numbers = new int[WORKER_SIZE]; private int sum = 0; private CyclicBarrier cyclicBarrier = new CyclicBarrier(WORKER_SIZE, new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; sum += numbers[i]; &#125; System.out .println(Thread.currentThread().getName() + "最后汇总的结果是：" + sum); &#125; &#125;); public static void main(String[] args) &#123; CylicBarrierTest test = new CylicBarrierTest(); System.out.println("正在执行准备工作..."); for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; if (i == WORKER_SIZE - 1) &#123; try &#123; // 故意让最后一个线程延时5秒启动 Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; new Thread(test.new Worker(i), "线程" + i).start(); &#125; &#125; class Worker implements Runnable &#123; private int index; public Worker(int index) &#123; this.index = index; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + "开始计算..."); try &#123; Thread.sleep(2000); numbers[index] = index; System.out.println(Thread.currentThread().getName() + "完成计算..."); cyclicBarrier.await(2, TimeUnit.SECONDS); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; System.out.println("所有线程都已完成计算，开始汇总..."); &#125; &#125;&#125; 执行结果：1234567891011121314151617181920212223242526272829303132333435363738394041正在执行准备工作...线程0开始计算...线程1开始计算...线程2开始计算...线程3开始计算...线程3完成计算...线程2完成计算...线程0完成计算...线程1完成计算...java.util.concurrent.BrokenBarrierException所有线程都已完成计算，开始汇总... at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250) at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435) at com.wxweven.concurrent.CylicBarrierTest$Worker.run(CylicBarrierTest.java:73) at java.lang.Thread.run(Thread.java:745)java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250) at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435) at com.wxweven.concurrent.CylicBarrierTest$Worker.run(CylicBarrierTest.java:73) at java.lang.Thread.run(Thread.java:745)java.util.concurrent.TimeoutException at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:257) at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435) at com.wxweven.concurrent.CylicBarrierTest$Worker.run(CylicBarrierTest.java:73) at java.lang.Thread.run(Thread.java:745)java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250) at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435) at com.wxweven.concurrent.CylicBarrierTest$Worker.run(CylicBarrierTest.java:73) at java.lang.Thread.run(Thread.java:745)所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...线程4开始计算...线程4完成计算...java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:207) at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435) at com.wxweven.concurrent.CylicBarrierTest$Worker.run(CylicBarrierTest.java:73) at java.lang.Thread.run(Thread.java:745)所有线程都已完成计算，开始汇总... 上面的代码46行中，故意让最后一个线程启动延迟，因为在前面三个线程都达到barrier之后，等待了指定的时间发现第四个线程还没有达到barrier，就抛出异常并继续执行后面的任务。 2.4. CyclicBarrier重用另外CyclicBarrier是可以重用的，看下面这个例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.wxweven.concurrent;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.TimeUnit;import java.util.concurrent.TimeoutException;/** * CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例如同时开始一个工作。 * 另外，CyclicBarrier的循环特性和构造函数所接受的 Runnable 参数也是 CountDownLatch 所不具备的 * * 假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情 * * @author wxweven * @date 2016年8月28日 * @version 1.0 * @email wxweven@qq.com * @blog wxweven.com * @Copyright: Copyright (c) wxweven 2009 - 2016 */public class CylicBarrierTest &#123; private static int WORKER_SIZE = 5; private int[] numbers = new int[WORKER_SIZE]; private int sum = 0; private CyclicBarrier cyclicBarrier = new CyclicBarrier(WORKER_SIZE, new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; sum += numbers[i]; &#125; System.out .println(Thread.currentThread().getName() + "最后汇总的结果是：" + sum); &#125; &#125;); public static void main(String[] args) &#123; CylicBarrierTest test = new CylicBarrierTest(); System.out.println("正在执行准备工作..."); for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; new Thread(test.new Worker(i), "线程" + i).start(); &#125; try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("CylicBarrier重用..."); for (int i = 0; i &lt; WORKER_SIZE; i++) &#123; new Thread(test.new Worker(i), "线程" + i).start(); &#125; &#125; class Worker implements Runnable &#123; private int index; public Worker(int index) &#123; this.index = index; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + "开始计算..."); try &#123; Thread.sleep(2000); numbers[index] = index; System.out.println(Thread.currentThread().getName() + "完成计算..."); cyclicBarrier.await(2, TimeUnit.SECONDS); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; System.out.println("所有线程都已完成计算，开始汇总..."); &#125; &#125;&#125; 执行结果：12345678910111213141516171819202122232425262728293031323334正在执行准备工作...线程0开始计算...线程1开始计算...线程2开始计算...线程3开始计算...线程4开始计算...线程0完成计算...线程1完成计算...线程2完成计算...线程4完成计算...线程3完成计算...线程2最后汇总的结果是：10所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...CylicBarrier重用...线程0开始计算...线程1开始计算...线程2开始计算...线程3开始计算...线程4开始计算...线程2完成计算...线程3完成计算...线程4完成计算...线程1完成计算...线程0完成计算...线程0最后汇总的结果是：20所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总...所有线程都已完成计算，开始汇总... 从执行结果可以看出，在初次的4个线程越过barrier状态后，又可以用来进行新一轮的使用。而CountDownLatch无法进行重复使用。 3. Semaphore用法Semaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 3.1. Semaphore接口Semaphore类位于java.util.concurrent包下，它提供了2个构造器：12345678public Semaphore(int permits) &#123; // 参数permits表示许可数目，即同时可以允许多少线程进行访问 sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; // 这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可 sync = (fair)? new FairSync(permits) : new NonfairSync(permits);&#125; 下面说一下Semaphore类中比较重要的几个方法，首先是acquire()、release()方法：1234public void acquire() throws InterruptedException &#123; &#125; // 获取一个许可public void acquire(int permits) throws InterruptedException &#123; &#125; // 获取permits个许可public void release() &#123; &#125; // 释放一个许可public void release(int permits) &#123; &#125; // 释放permits个许可 acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。 release()用来释放许可。注意，在释放许可之前，必须先获获得许可。 这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法：1234567891011// 尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire() &#123; &#125;; // 尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; // 尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(int permits) &#123; &#125;; // 尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回falsepublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; 另外还可以通过availablePermits()方法得到可用的许可数目。 3.2. Semaphore应用例子 下面通过一个例子来看一下Semaphore的具体使用： 假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.wxweven.concurrent;import java.util.concurrent.Semaphore;/** * Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 * * 假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。 * * @author wxweven * @date 2016年8月28日 * @version 1.0 * @email wxweven@qq.com * @blog wxweven.com * @Copyright: Copyright (c) wxweven 2009 - 2016 */public class SemaphoreTest &#123; private static int workerSize = 8; // 工人数量 private static int machineSize = 5; // 机器数量 private Semaphore semaphore = new Semaphore(machineSize); public static void main(String[] args) &#123; SemaphoreTest test = new SemaphoreTest(); for (int i = 0; i &lt; workerSize; i++) &#123; new Thread(test.new Worker(i + 1)).start(); &#125; &#125; class Worker implements Runnable &#123; int num; public Worker(int num) &#123; this.num = num; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println("工人" + num + "开始工作，占用一台机器..."); Thread.sleep(500); System.out.println("工人" + num + "结束工作，释放一台机器..."); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 执行结果：12345678910111213141516工人1开始工作，占用一台机器...工人2开始工作，占用一台机器...工人3开始工作，占用一台机器...工人4开始工作，占用一台机器...工人5开始工作，占用一台机器...工人3结束工作，释放一台机器...工人5结束工作，释放一台机器...工人4结束工作，释放一台机器...工人1结束工作，释放一台机器...工人2结束工作，释放一台机器...工人8开始工作，占用一台机器...工人7开始工作，占用一台机器...工人6开始工作，占用一台机器...工人8结束工作，释放一台机器...工人7结束工作，释放一台机器...工人6结束工作，释放一台机器... 4. 总结CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行； 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。 Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。 5. 参考资料http://www.cnblogs.com/dolphin0520/p/3920397.html]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程：Callable、Future和FutureTask]]></title>
    <url>%2F2016%2F10%2F12%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ACallable%E3%80%81Future%E5%92%8CFutureTask%2F</url>
    <content type="text"><![CDATA[在前面的文章中我们讲述了创建线程的2种方式，一种是直接继承Thread，另外一种就是实现Runnable接口。 这2种方式都有一个缺陷就是：在执行完任务之后无法获取执行结果。 如果需要获取执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦。 而自从Java 1.5开始，就提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果。 今天我们就来讨论一下Callable、Future和FutureTask三个类的使用方法 0.1. Callable与Runnable先说一下java.lang.Runnable吧，它是一个接口，在它里面只声明了一个run()方法：123public interface Runnable &#123; public abstract void run();&#125; 由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。 Callable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个方法，只不过这个方法叫做call()：123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 可以看到，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。 那么怎么使用Callable呢？一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本：123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); 第一个submit方法里面的参数类型就是Callable。 暂时只需要知道Callable一般是和ExecutorService配合来使用的，具体的使用方法讲在后面讲述。 一般情况下我们使用第一个submit方法和第三个submit方法，第二个submit方法很少使用。 0.2. Future Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 Future类位于java.util.concurrent包下，它是一个接口：12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 在Future接口中声明了5个方法，下面依次解释每个方法的作用： cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 isDone方法表示任务是否已经完成，若任务完成，则返回true； get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 也就是说Future提供了三种功能： 1. 判断任务是否完成； 2. 能够中断任务； 3. 能够获取任务执行结果。 因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。 0.3. FutureTask我们先来看一下FutureTask的实现：1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; FutureTask类实现了RunnableFuture接口，我们看一下RunnableFuture接口的实现：123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 FutureTask提供了2个构造器：1234public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125; 事实上，FutureTask是Future接口的一个唯一实现类。 0.4. 使用示例0.4.1. 使用Callable+Future获取执行结果 1234567891011121314151617181920212223242526272829303132333435363738public class Test &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newCachedThreadPool(); Callable&lt;Integer&gt; task = new Task(); Future&lt;Integer&gt; result = executor.submit(task); executor.shutdown(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("主线程在执行任务"); try &#123; System.out.println("task运行结果"+result.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("所有任务执行完毕"); &#125;&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println("子线程在进行计算"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125; 执行结果：1234子线程在进行计算主线程在执行任务task运行结果4950所有任务执行完毕 0.4.2. 使用Callable+FutureTask获取执行结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Test &#123; public static void main(String[] args) &#123; //第一种方式 ExecutorService executor = Executors.newCachedThreadPool(); Callable&lt;Integer&gt; task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); executor.submit(futureTask); executor.shutdown(); // 第二种方式，注意这种方式和第一种方式效果是类似的， // 只不过一个使用的是ExecutorService，一个使用的是Thread // Task task = new Task(); // FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); // Thread thread = new Thread(futureTask); // thread.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("主线程在执行任务"); try &#123; System.out.println("task运行结果"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("所有任务执行完毕"); &#125;&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println("子线程在进行计算"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125; 如果为了可取消性而使用 Future 但又不提供可用的结果，则可以声明 Future&lt;?&gt; 形式类型、并返回 null 作为底层任务的结果 原文：http://www.cnblogs.com/dolphin0520/p/3949310.html]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO详解]]></title>
    <url>%2F2016%2F10%2F10%2FJava-NIO%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. 基础概念1.1. 缓冲区操作缓冲区及操作是所有I/O的基础，进程执行I/O操作，归结起来就是向操作系统发出请求，让它要么把缓冲区里的数据排干（写），要么把缓冲区填满（读）。如下图 1.2. 内核空间、用户空间上图简单描述了数据从磁盘到用户进程的内存区域移动的过程，其间涉及到了内核空间与用户空间。这两个空间有什么区别呢？ 用户空间就是常规进程（如JVM）所在区域，用户空间是非特权区域，如不能直接访问硬件设备。内核空间是操作系统所在区域，那肯定是有特权啦，如能与设备控制器通讯，控制用户区域的进程运行状态。进程执行I/O操作时，它执行一个系统调用把控制权交由内核。 1.3. I/O模型常见的I/O模型有以下几种 1.3.1. 同步阻塞I/O最常用的一个模型是同步阻塞I/O模型。在这个模型中，用户空间的应用程序执行一个系统调用，这会导致应用程序阻塞。这意味着应用程序会一直阻塞，直到系统调用完成为止（数据传输完成或发生错误）。调用应用程序处于一种不再消费 CPU 而只是简单等待响应的状态，因此从处理的角度来看，这是非常有效的。下图给出了传统的阻塞I/O模型，这也是目前应用程序中最为常用的一种模型。其行为非常容易理解，其用法对于典型的应用程序来说都非常有效。在调用 read 系统调用时，应用程序会阻塞并对内核进行上下文切换。然后会触发读操作，当响应返回时（从我们正在从中读取的设备中返回），数据就被移动到用户空间的缓冲区中。然后应用程序就会解除阻塞（read 调用返回）。 从应用程序的角度来说，read 调用会延续很长时间。实际上，在内核执行读操作和其他工作时，应用程序的确会被阻塞。 1.3.2. 同步非阻塞I/O同步阻塞I/O的一种效率稍低的变种是同步非阻塞I/O。在这种模型中，设备是以非阻塞的形式打开的。这意味着I/O操作不会立即完成，read 操作可能会返回一个错误代码，说明这个命令不能立即满足（EAGAIN 或 EWOULDBLOCK），如下图所示。 非阻塞的实现是I/O命令可能并不会立即满足，需要应用程序调用许多次来等待操作完成。这可能效率不高，因为在很多情况下，当内核执行这个命令时，应用程序必须要进行忙碌等待，直到数据可用为止，或者试图执行其他工作。正如图 3 所示的一样，这个方法可以引入I/O操作的延时，因为数据在内核中变为可用到用户调用 read 返回数据之间存在一定的间隔，这会导致整体数据吞吐量的降低。 1.3.3. 异步阻塞I/O另外一个阻塞解决方案是带有阻塞通知的非阻塞I/O。在这种模型中，配置的是非阻塞I/O，然后使用阻塞 select 系统调用来确定一个I/O描述符何时有操作。使 select 调用非常有趣的是它可以用来为多个描述符提供通知，而不仅仅为一个描述符提供通知。对于每个提示符来说，我们可以请求这个描述符可以写数据、有读数据可用以及是否发生错误的通知。 select 调用的主要问题是它的效率不是非常高。尽管这是异步通知使用的一种方便模型，但是对于高性能的I/O操作来说不建议使用。 1.3.4. 异步非阻塞I/O最后，异步非阻塞I/O模型是一种处理与I/O重叠进行的模型。读请求会立即返回，说明 read 请求已经成功发起了。在后台完成读操作时，应用程序然后会执行其他处理操作。当 read 的响应到达时，就会产生一个信号或执行一个基于线程的回调函数来完成这次I/O处理过程。 在一个进程中为了执行多个I/O请求而对计算操作和I/O处理进行重叠处理的能力利用了处理速度与I/O速度之间的差异。当一个或多个I/O请求挂起时，CPU 可以执行其他任务；或者更为常见的是，在发起其他I/O的同时对已经完成的I/O进行操作。 2. NIO开始讲NIO之前，了解为什么会有NIO，相比传统流I/O的优势在哪，它可以用来做什么等等的问题，还是很有必要的。 传统流I/O是基于字节的，所有I/O都被视为单个字节的移动；而NIO是基于块的，大家可能猜到了，NIO的性能肯定优于流I/O。没错！其性能的提高 要得益于其使用的结构更接近操作系统执行I/O的方式：通道和缓冲器。 我们可以把它想象成一个煤矿，通道是一个包含煤层（数据）的矿藏，而缓冲器则是派送 到矿藏的卡车。卡车载满煤炭而归，我们再从卡车上获得煤炭。也就是说，我们并没有直接和通道交互；我们只是和缓冲器交互，并把缓冲器派送到通道。通道要么 从缓冲器获得数据，要么向缓冲器发送数据。（这段比喻出自Java编程思想）。 NIO的主要应用在高性能、高容量服务端应用程序，典型的Netty就是基于它的。 NIO也叫作 None Blocking IO 或者 New IO，在Java1.4纳入JDK中，具有以下特征： 为所有的原始类型提供（buffer）缓存支持； 使用Charset作为字符集编码解码解决方案； 增加了通道（Channel）对象，作为新的原始I/O抽象； 支持锁和内存访问文件的文件访问接口； 提供了基于Selector的异步网络I/O； NIO是基于块（Block）的，它以块为基本单位处理数据。在NIO中，最重要的两个组件是buffer缓冲和channel通道。缓冲是一块连续的内存区域，是NIO读写数据的中转站。通道表示缓冲数据的源头或目的地，它用于向缓冲读取或写入数据，是访问缓冲的接口。通道和缓冲的关系如图： 2.1. 缓冲区Buffer概述缓冲区实质上就是一个数组，但它不仅仅是一个数组，缓冲区还提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。为什么这么说呢？下面来看看缓冲区的细节。讲缓冲区细节之前，我们先来看一下缓冲区“家谱”： 2.1.1. Buffer属性Buffer对象有四个基本属性： 容量Capacity：缓冲区能容纳的数据元素的最大数量，在缓冲区创建时设定，无法更改 上界Limit：缓冲区的第一个不能被读或写的元素的索引 位置Position：下一个要被读或写的元素的索引 标记Mark：备忘位置，调用mark()来设定mark=position，调用reset()设定position=mark 这四个属性总是遵循这样的关系：0&lt;=mark&lt;=position&lt;=limit&lt;=capacity。 2.2. Buffer类和ChannelJDK为每一种java原生类型都提供了一种Buffer，除了ByteBuffer外，其他每一种Buffer都具有完全一样的操作，除了操作类型不一样以外。ByteBuffer可以用于绝大多数标准I/O操作的接口。 在NIO中和Buffer配合使用的还有Channel。Channel是一个双向通道，既可以读也可以写。有点类似Stream，但是Stream是单向的。应用程序不能直接对Channel进行读写操作，而必须通过Buffer来进行。 下面以一个文件复制为例，简单介绍NIO的Buffer和Channel的用法，代码如下： 12345678910111213141516171819202122232425public class NioCopyFileTest &#123; public static void main(String[] args) throws Exception &#123; NioCopyFileTest.copy("test.txt", "test2.txt"); &#125; public static void copy(String resource,String destination) throws Exception&#123; FileInputStream fis = new FileInputStream(resource); FileOutputStream fos = new FileOutputStream(destination); FileChannel inputFileChannel = fis.getChannel();//读文件通道 FileChannel outputFileChannel = fos.getChannel();//写文件通道 ByteBuffer byteBuffer = ByteBuffer.allocate(1024);//读写数据缓冲 while(true)&#123; byteBuffer.clear(); int length = inputFileChannel.read(byteBuffer);//读取数据 if(length == -1)&#123; break;//读取完毕 &#125; byteBuffer.flip(); outputFileChannel.write(byteBuffer);//写入数据 &#125; inputFileChannel.close(); outputFileChannel.close(); &#125;&#125; 代码中注释写的很详细了，输入流和输出流都对应一个Channel通道，将数据通过读文件channel读取到缓冲中，然后再通过写文件channel写入到缓冲中。这样就完成了文件复制。注意：缓冲在文件传输中起到的作用十分大，可以缓解内存和硬盘之间的性能差异，提升系统性能。 3. Buffer详解Buffer是NIO中最核心的对象，它的一系列的操作和使用也需要重点掌握，这里简单概括一下，也可以参考相关API查看。下面将对Buffer进行详解，包括常用API、使用实例等。 3.1. Buffer APIBuffer中常用的接口有put(), clear(), flip(), rewind()等，这些实际上都是在对Buffer四个基本属性的操作，下面我们来看详细的代码。 clear: 清空缓冲区 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; flip: 读写交换 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 3.2. Buffer的创建Buffer的常见有两种方式，使用静态方法allocate()从堆中分配缓冲区，或者从一个既有数组中创建缓冲区。 123ByteBuffer buffer = ByteBuffer.allocate(1024);//从堆中分配byte[] arrays = new byte[1024];//从既有数组中创建ByteBuffer buffer2 = ByteBuffer.wrap(arrays); 3.3. 重置或清空缓冲区：Buffer还提供了一些用于重置和清空缓冲区的方法：rewind()，clear()，flip()。它们的作用如下： 3.4. 读写缓冲区：对Buffer对象进行读写操作是Buffer最重要的操作，buffer提供了许多读写操作的缓冲区。具体参考API。 3.5. 标记mark缓冲区标记（mark）缓冲区是一个在数据处理时很有用的功能，它就像书签一样，可以在数据处理中随时记录当前位置，然后再任意时刻回到这个位置，从而简化或加快数据处理的流程。相关函数为：mark()和reset()。mark()用于记录当前位置，reset()用于恢复到mark标记的位置。 代码如下：1234567891011121314151617ByteBuffer buffer = ByteBuffer.allocate(15);//设置缓冲区大小为15for (int i = 0; i &lt; 10; i++) &#123; buffer.put((byte) i);&#125;buffer.flip();//重置positionfor (int i = 0; i &lt; buffer.limit(); i++) &#123; System.out.print(buffer.get()); if (i == 4) &#123; buffer.mark(); System.out.print("mark at" + i); &#125;&#125;System.out.println();buffer.reset();while (buffer.hasRemaining()) &#123; System.out.print(buffer.get());&#125; 输出结果：1201234 mark at 45678956789 3.6. 复制缓冲区复制缓冲区是以原缓冲区为基础，生成一个完全一样的缓冲区。方法为：duplicate()。这个函数对于处理复杂的Buffer数据很有好处。因为新生成的缓冲区和元缓冲区共享相同的内存数据。并且，任意一方的改动都是互相可见的，但是两者又各自维护者自己的position、limit和capacity。这大大增加了程序的灵活性，为多方同时处理数据提供了可能。12345678910111213141516ByteBuffer buffer = ByteBuffer.allocate(15);//设置缓冲区大小为15for (int i = 0; i &lt; 10; i++) &#123; buffer.put((byte) i);&#125;ByteBuffer buffer2 = buffer.duplicate();//复制当前缓冲区System.out.println("after buffer duplicate");System.out.println(buffer);System.out.println(buffer2);buffer2.flip();System.out.println("after buffer2 flip");System.out.println(buffer);System.out.println(buffer2);buffer2.put((byte)100);System.out.println("after buffer2 put");System.out.println(buffer.get(0));System.out.println(buffer2.get(0)); 输出如下：123456789after buffer duplicatejava.nio.HeapByteBuffer[pos=10 lim=15 cap=15]java.nio.HeapByteBuffer[pos=10 lim=15 cap=15]after buffer2 flipjava.nio.HeapByteBuffer[pos=10 lim=15 cap=15]java.nio.HeapByteBuffer[pos=0 lim=10 cap=15]after buffer2 put100100 3.7. 缓冲区分片缓冲区分片使用slice()方法，它将现有的缓冲区创建新的子缓冲区，子缓冲区和父缓冲区共享数据，子缓冲区具有完整的缓冲区模型结构。当处理一个buffer的一个片段时，可以使用一个slice()方法取得一个子缓冲区，然后就像处理普通缓冲区一样处理这个子缓冲区，而无需考虑边界问题，这样有助于系统模块化。 1234567891011121314151617ByteBuffer buffer = ByteBuffer.allocate(15);//设置缓冲区大小为15for (int i = 0; i &lt; 10; i++) &#123; buffer.put((byte) i);&#125;buffer.position(2);buffer.limit(6);ByteBuffer subBuffer = buffer.slice();//复制缓冲区for (int i = 0; i &lt; subBuffer.limit(); i++) &#123; byte b = subBuffer.get(i); b = (byte) (b * 10); subBuffer.put(i, b);&#125;buffer.limit(buffer.capacity());buffer.position(0);for (int i = 0; i &lt; buffer.limit(); i++) &#123; System.out.print(buffer.get(i) + " ");&#125; 输出结果： 10 1 20 30 40 50 6 7 8 9 0 0 0 0 0 3.8. 只读缓冲区可以使用缓冲区对象的asReadOnlyBuffer()方法得到一个与当前缓冲区一致的，并且共享内存数据的只读缓冲区，只读缓冲区对于数据安全非常有用。使用只读缓冲区可以保证数据不被修改，同时，只读缓冲区和原始缓冲区是共享内存块的，因此，对于原始缓冲区的修改，只读缓冲区也是可见的。 代码如下：12345678910111213ByteBuffer buffer = ByteBuffer.allocate(15);//设置缓冲区大小为15for (int i = 0; i &lt; 10; i++) &#123; buffer.put((byte) i);&#125;ByteBuffer readBuffer = buffer.asReadOnlyBuffer();for (int i = 0; i &lt; readBuffer.limit(); i++) &#123; System.out.print(readBuffer.get(i) + " ");&#125;System.out.println();buffer.put(2, (byte) 20);for (int i = 0; i &lt; readBuffer.limit(); i++) &#123; System.out.print(readBuffer.get(i) + " ");&#125; 结果：120 1 2 3 4 5 6 7 8 9 0 0 0 0 0 0 1 20 3 4 5 6 7 8 9 0 0 0 0 0 由此可见，只读缓冲区并不是原始缓冲区在某一时刻的快照，而是和原始缓冲区共享内存数据的。当修改只读缓冲区时，会报ReadOnlyBufferException异常。 3.9. 文件映射到内存：NIO提供了一种将文件映射到内存的方法进行I/O操作，它可以比常规的基于流的I/O快很多。这个操作主要是由FileChannel.map()方法实现的。 使用文件映射的方式，将文本文件通过FileChannel映射到内存中。然后在内存中读取文件内容。还可以修改Buffer，将实际数据写到对应的硬盘中。12345678RandomAccessFile raf = new RandomAccessFile("D:\\test.txt", "rw");FileChannel fc = raf.getChannel();MappedByteBuffer mbf = fc.map(MapMode.READ_WRITE, 0, raf.length());//将文件映射到内存while (mbf.hasRemaining()) &#123; System.out.println(mbf.get());&#125;mbf.put(0, (byte) 98);//修改文件raf.close(); 3.10. 处理结构化数据NIO还提供了处理结构化数据的方法，称为散射和聚集。散射是将一组数据读入到一组buffer中，聚集是将数据写入到一组buffer中。聚集和散射的基本使用方法和对单个buffer操作的使用方法类似。这一组缓冲区类似于一个大的缓冲区。 散射/聚集IO对处理结构化数据非常有用。例如，对于一个具有固定格式的文件的读写，在已知文件具体结构的情况下，可以构造若干个符合文件结构的buffer，使得各个buffer的大小恰好符合文件各段结构的大小。 例如，将”姓名：张三,年龄：18”,通过聚集写创建该文件，然后再通过散射都来解析。123456789101112131415161718192021222324ByteBuffer nameBuffer = ByteBuffer.wrap("姓名：张三,".getBytes("utf-8"));ByteBuffer ageBuffer = ByteBuffer.wrap("年龄：18".getBytes("utf-8"));int nameLength = nameBuffer.limit();int ageLength = ageBuffer.limit();ByteBuffer[] bufs = new ByteBuffer[]&#123;nameBuffer,ageBuffer&#125;;File file = new File("D:\\name.txt");if(!file.exists())&#123; file.createNewFile();&#125;FileOutputStream fos = new FileOutputStream(file);FileChannel channel = fos.getChannel();channel.write(bufs);channel.close();ByteBuffer nameBuffer2 = ByteBuffer.allocate(nameLength);ByteBuffer ageBuffer2 = ByteBuffer.allocate(ageLength);ByteBuffer[] bufs2 = new ByteBuffer[]&#123;nameBuffer2,ageBuffer2&#125;;FileInputStream fis = new FileInputStream("D:\\name.txt");FileChannel channel2 = fis.getChannel();channel2.read(bufs2);String name = new String(bufs2[0].array(),"utf-8");String age = new String(bufs2[1].array(),"utf-8");System.out.println(name+age); 通过和通道的配合使用，可以简化Buffer对于结构化数据处理的难度。 注意，ByteBuffer是将文件一次性读入内存再做处理，而Stream方式则是边读取文件边处理数据，这也是两者性能差异的主要原因。 3.11. 直接内存访问NIO的Buffer还提供了一个可以直接访问系统物理内存的类–DirectBuffer。普通的ByteBuffer依然在JVM堆上分配空间，其最大内存，受最大堆的限制。而DirecBuffer直接分配在物理内存中，并不占用堆空间。创建DirectBuffer的方法是：ByteBuffer.allocateDirect(capacity)。 在对普通的ByteBuffer的访问，系统总会使用一个”内核缓冲区”进行间接操作。而ByteBuffer所处的位置，就相当于这个”内核缓冲区”。因此，DirecBuffer是一种更加接近底层的操作。 DirectBuffer的访问速度远高于ByteBuffer，但是其创建和销毁所消耗的时间却远大于ByteBuffer。在需要频繁创建和销毁Buffer的场合，显然不适合DirectBuffer的使用，但是如果能将DirectBuffer进行复用，那么在读写频繁的场合下，它完全可以大幅度改善系统性能。 4. Buffer操作实例下面例子很好的解释了Buffer的工作原理： 12345678910111213ByteBuffer buffer = ByteBuffer.allocate(15);//设置缓冲区大小为15System.out.println("position:"+buffer.position()+"limit:"+buffer.limit()+"capacity"+buffer.capacity());for (int i = 0; i &lt; 10; i++) &#123; buffer.put((byte) i);&#125;System.out.println("position:"+buffer.position()+"limit:"+buffer.limit()+"capacity"+buffer.capacity());buffer.flip();//重置positionfor (int i = 0; i &lt; 5; i++) &#123; System.out.println(buffer.get());&#125;System.out.println("position:"+buffer.position()+"limit:"+buffer.limit()+"capacity"+buffer.capacity());buffer.flip();System.out.println("position:"+buffer.position()+"limit:"+buffer.limit()+"capacity"+buffer.capacity()); 以上代码，先分配了15个字节大小的缓冲区。在初始阶段，position为0，capacity为15，limit为15。注意，position是从0开始的，所以索引为15的位置实际上是不存在的。 接着往缓冲区放入10个元素，position始终指向下一个即将放入的位置，所有position为10，capacity和limit依然为15。 进行flip()操作，会重置position的位置，并且将limit设置到当前position的位置，这时Buffer从写模式进入读模式，这样就可以防止读操作读取到没有进行操作的位置。所有此时，position为0，limit为10，capacity为15。 接着进行五次读操作，读操作会设置position的位置，所以，position为5，limit为10，capacity为15。 在进行一次flip()操作，此时可想而知position为0，limit为5，capacity为15。]]></content>
      <categories>
        <category>Java IO</category>
      </categories>
      <tags>
        <tag>Java NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java要求]]></title>
    <url>%2F2016%2F09%2F22%2FJava%E8%A6%81%E6%B1%82%2F</url>
    <content type="text"><![CDATA[1. Java工程师的一些要求Java工程师的一些要求，搜集于网络，给Java工程师们一个学习的方向。 1.1. 要求实例一 掌握扎实的 Java 基础，熟悉集合类，I/O 及多线程/协程编程，理解各种容器类的内部实现 三年以上 Java 进行 Web，API 或中间件的全流程开发经验，熟悉 Spring，iBatis，缓存，连接池等常见基础框架的使用、原理和实现 熟悉常用设计模式，熟悉基本 JVM 原理、参数及问题排查，掌握 JVM 性能调优的常见方法及故障排查方法 熟练掌握 SQL 和 MySQL，对 SQL 优化有一定经验，掌握事务的基本原理及实现熟练掌握 Linux 下常用的 shell 命令，掌握 Linux 基础性能指标及线上问题排查与解决方法 对分布式系统及分布式存储理论，如 CAP，一致性哈希，MVCC 等原理及算法有一定了解 熟悉日常开发流程，熟悉常用开发、调试工具、代码管理工具，如 Git、Maven、Eclipse 等 思路清晰，良好的沟通能力与技术学习能力 有线上大规模分布式系统开发、部署或运维经验者优先 有 Python、Perl 等其它脚本语言开发经验者优先 1.2. 要求实例二 JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解 3年及以上使用JAVA Web开发的经验，对Spring,ibatis,struts等开源框架熟悉 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制 有全栈开发经验的优先考虑 熟悉互联网共享经济业务，具有电商CRM系统设计开发相关经验者优先考虑 有大型分布式、高并发、高负载、高可用性系统设计开发维护经验优先考虑 有GrowthHacking的数据驱动产品开发的思维，有相关实际经验的优先考虑 具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计问题，并给出有效的解决措施和方法]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[魔方教程]]></title>
    <url>%2F2016%2F03%2F10%2F%E9%AD%94%E6%96%B9%2F</url>
    <content type="text"><![CDATA[0.1. 第一步：白面十字kkk 0.2. 第二步：全白面和四个侧面的T字形啦啦啦 0.3. 第三步：第二层的四个棱色块-对好前两层科技发达啦是 0.4. 第四步：黄色顶面画十字目标： 0.4.1. 第一种情况黄面只有一中心个点 底部三个白色到左边 底部两个白色到前面 顶层顺时针转90度（也就是转一次，前面转到左边） 前面两个白色还原到底面 顶层逆时针还原 左边三个白色还原到底面 经过上面的旋转，可以将魔方变化成下面的第二种情况 0.4.2. 第二种情况黄面是一个拐弯 拐弯按照图示方向摆放（先往上，再往右） 重复第一种情况的步骤1-6 经过上面的旋转，可以将魔方变化成下面的第三种情况 0.4.3. 第三种情况黄面是一字形 拐弯按照图示方向摆放（从左往右形成一字形） 重复第一种情况的步骤1-6 经过上面的旋转，可以将魔方变化成我们想要的 0.5. 第五步：调整顶层角色块的朝向，对好顶层黄色面0.5.1. 小鱼1 黄色缺失3个小鱼的右侧黄色看不见 鱼头在左上角，且鱼头不能被破坏 底部三个白色到后边（因为后边黄色看不见） 顶层逆时针转90度（也就是转一次，前面转到右边） 后边的两个白色还原到底部 顶层逆时针转90度（也就是转一次，前面转到右边），让那一个白色到前面来 底部两个白色到后边，目的是接前面的那一个白色 逆时针转180度，也就是把前面的那一个白色转到后面，三个白色在一线 三个白色还原到底部 关键点，底部白色转到后边和还原，顶层逆时针环游（不会破坏鱼头），这两组动作交替执行 0.5.2. 小鱼2 黄色缺失3个小鱼的左侧黄色看不见 鱼头在左上角，且鱼头不能被破坏 底部三个白色到左边（因为左边黄色看不见） 顶层顺时针转90度（也就是转一次，前面转到左边） 左边的两个白色还原到底部 顶层顺时针转90度（也就是转一次，前面转到左边），让那一个白色到右边来 底部两个白色到左边，目的是接右边的那一个白色 顺时针转180度，也就是把右边的那一个白色转到左边，三个白色在一线 三个白色还原到底部 0.5.3. 顶部有2个或4个黄色缺失口诀：2后4左 选一个非黄色的块 A 在左上角； 如果缺失2个黄色，那么 A 包含的黄色应该在后面；如果缺失4个黄色，那么 A 包含的黄色应该在左边； 将 A 当作鱼头，采用 小鱼1 的方式来旋转 0.6. 第六步 调整顶层角色块顺序目标：四个角的8条线，都是已经旋转好的 0.6.1. 第一种情况：一条两脚同色的边 把全黄色的面，摆放到前面，两脚同色的边，放到右边； 转右边，把后面的白色转到前面来 转底边，把后面的两个白色转到前面来，白色形成一个反L _| 前面三个白色，转到底部 转上面，后面的两个白色转到左边 把底部的三个白色转到前面来，白色形成一个反L _| 前面的两个白色转到后面 前面三个白色，转到底部 左边的两个白色转到后面 底部的三个白色转到后面 0.6.2. 第二种情况：没有两脚同色的边 黄色朝前面，任意一个缺失的叫朝右边 重复 第一种情况 的10个步骤 这时可以找到两脚同色的边，再重复 第一种情况 的10个步骤 0.6.3. 第3种情况：4条两脚同色的边这种情况就是目标情况，随意转动下顶层就可以达到目标 0.7. 第七步 调整顶层棱色块顺序，将魔方最后还原黄色朝上 0.7.1. 第一种情况： 顶层已经有一条边对齐，还有三个色块没有还原，逆时针3轮换用小鱼1的方式摆放方式：底部三个白色转到后面后，黄色可以切开已经还原的那一面 0.7.2. 第二种情况： 顶层已经有一条边对齐，还有三个色块没有还原，顺时针3轮换用小鱼2摆放方式：底部三个白色转到左边后，黄色可以切开已经还原的那一面 0.7.3. 第三种情况： 还有4个色块没有还原，两两对面交换假装只缺三个，利用第一种或第二种方式来一次，转化成顺时针或逆时针 0.7.4. 第三种情况： 还有4个色块没有还原，非两两对面交换假装只缺三个，利用第一种或第二种方式来一次，转化成顺时针或逆时针]]></content>
      <categories>
        <category>娱乐</category>
      </categories>
      <tags>
        <tag>魔方</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程：深入剖析ThreadLocal]]></title>
    <url>%2F2016%2F03%2F04%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90ThreadLocal%2F</url>
    <content type="text"><![CDATA[想必很多朋友对ThreadLocal并不陌生，今天我们就来一起探讨下ThreadLocal的使用方法和实现原理。首先，本文先谈一下对ThreadLocal的理解，然后根据ThreadLocal类的源码分析了其实现原理和使用需要注意的地方，最后给出了两个应用场景。 本文转载于：http://www.cnblogs.com/dolphin0520/p/3920407.html 0.1. 对ThreadLocal的理解ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，其实意思差不多。可能很多朋友都知道ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。 这句话从字面上看起来很容易理解，但是真正理解并不是那么容易。我们还是先来看一个例子：12345678910111213141516class ConnectionManager &#123; private static Connection connect = null; public static Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public static void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; 假设有这样一个数据库链接管理类，这段代码在单线程中使用是没有任何问题的，但是如果在多线程中使用呢？很显然，在多线程中使用会存在线程安全问题： 第一，这里面的2个方法都没有进行同步，很可能在openConnection方法中会多次创建connect； 第二，由于connect是共享变量，那么必然在调用connect的地方需要使用到同步来保障线程安全，因为很可能一个线程在使用connect进行数据库操作，而另外一个线程调用closeConnection关闭链接。 所以出于线程安全的考虑，必须将这段代码的两个方法进行同步处理，并且在调用connect的地方需要进行同步处理。这样将会大大影响程序执行效率，因为一个线程在使用connect进行数据库操作的时候，其他线程只有等待。 那么大家来仔细分析一下这个问题，这地方到底需不需要将connect变量进行共享？事实上，是不需要的。假如每个线程中都有一个connect变量，各个线程之间对connect变量的访问实际上是没有依赖关系的，即一个线程不需要关心其他线程是否对这个connect进行了修改的。 到这里，可能会有朋友想到，既然不需要在线程之间共享这个变量，可以直接这样处理，在每个需要使用数据库连接的方法中具体使用时才创建数据库链接，然后在方法调用完毕再释放这个连接。比如下面这样： 123456789101112131415161718192021222324252627class ConnectionManager &#123; private Connection connect = null; public Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; class Dao&#123; public void insert() &#123; ConnectionManager connectionManager = new ConnectionManager(); Connection connection = connectionManager.openConnection(); //使用connection进行操作 connectionManager.closeConnection(); &#125;&#125; 这样处理确实也没有任何问题，由于每次都是在方法内部创建的连接，那么线程之间自然不存在线程安全问题。但是这样会有一个致命的影响：导致服务器压力非常大，并且严重影响程序执行性能。由于在方法中需要频繁地开启和关闭数据库连接，这样不尽严重影响程序执行效率，还可能导致服务器压力巨大。 那么这种情况下使用ThreadLocal是再适合不过的了，因为ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。 但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 0.2. 深入解析ThreadLocal类在上面谈到了对ThreadLocal的一些理解，那我们下面来看一下具体ThreadLocal是如何实现的。 0.2.1. ThreadLocal API先了解一下 ThreadLocal 类提供的几个方法： get public T get() 返回此线程局部变量的当前线程副本中的值。如果这是线程第一次调用该方法，则创建并初始化此副本。 返回：此线程局部变量的当前线程的值 setpublic void set(T value) 将此线程局部变量的当前线程副本中的值设置为指定值。许多应用程序不需要这项功能，它们只依赖于 initialValue() 方法来设置线程局部变量的值。 参数： value - 存储在此线程局部变量的当前线程副本中的值。 initialValueprotected T initialValue() 返回此线程局部变量的当前线程的初始值。最多在每次访问线程来获得每个线程局部变量时调用此方法一次，即线程第一次使用 get() 方法访问变量的时候。如果线程先于 get 方法调用 set(T) 方法，则不会在线程中再调用 initialValue 方法。该实现只返回 null；如果程序员希望将线程局部变量初始化为 null 以外的某个值，则必须为 ThreadLocal 创建子类，并重写此方法。通常，将使用匿名内部类。initialValue 的典型实现将调用一个适当的构造方法，并返回新构造的对象。 返回： 返回此线程局部变量的初始值 removepublic void remove() 移除此线程局部变量的值。这可能有助于减少线程局部变量的存储需求。如果再次访问此线程局部变量，那么在默认情况下它将拥有其 initialValue。 首先我们来看一下ThreadLocal类是如何为每个线程创建一个变量的副本的。先看下get方法的实现： 第一句是取得当前线程，然后通过getMap(t)方法获取到一个map，map的类型为ThreadLocalMap。然后接着下面获取到键值对，注意这里获取键值对传进去的是 this，而不是当前线程t。 如果获取成功，则返回value值。如果map为空，则调用setInitialValue方法返回value。我们上面的每一句来仔细分析：首先看一下getMap方法中做了什么： 可能大家没有想到的是，在getMap中，是调用当期线程t，返回当前线程t中的一个成员变量threadLocals。 那么我们继续取Thread类中取看一下成员变量threadLocals是什么： 实际上就是一个ThreadLocalMap，这个类型是ThreadLocal类的一个内部类，我们继续取看ThreadLocalMap的实现：可以看到ThreadLocalMap的Entry继承了WeakReference，并且使用ThreadLocal作为键值。然后再继续看setInitialValue方法的具体实现：很容易了解，就是如果map不为空，就设置键值对，为空，再创建Map，看一下createMap的实现：至此，可能大部分朋友已经明白了ThreadLocal是如何为每个线程创建变量的副本的： 首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。 然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。 下面通过一个例子来证明通过ThreadLocal能达到在每个线程中创建变量副本的效果： 1234567891011121314151617181920212223242526272829303132333435363738394041public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(); ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(); public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;&#125; 这段代码的输出结果为： 从这段代码的输出结果可以看出，在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。最后一次在main线程再次打印副本值是为了证明在main线程中和thread1线程中的副本值确实是不同的。 0.2.2. ThreadLocal 总结0.2.2.1. ThreadLocal 框架图 实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的； 为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal； 在进行get之前，必须先set，否则会报空指针异常； 如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。因为在上面的代码分析过程中，我们发现如果没有先set的话，即在map中查找不到对应的存储，则会通过调用setInitialValue方法返回i，而在setInitialValue方法中，有一个语句是T value = initialValue()， 而默认情况下，initialValue方法返回的是null。 看下面这个例子： 12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(); ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(); public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;&#125; 在main线程中，没有先set，直接get的话，运行时会报空指针异常。但是如果改成下面这段代码，即重写了initialValue方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;()&#123; protected Long initialValue() &#123; return Thread.currentThread().getId(); &#125;; &#125;; ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;()&#123;; protected String initialValue() &#123; return Thread.currentThread().getName(); &#125;; &#125;; public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;&#125; 就可以直接不用先set而直接调用get了。 0.3. ThreadLocal的应用场景最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。如： 123456789101112131415161718192021222324private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;; public static Connection getConnection() &#123; return connectionHolder.get();&#125; private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125;]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activity 生命周期]]></title>
    <url>%2F2016%2F03%2F01%2FActivity-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[0.1. Activity生命周期的回调方法 12345678910111213141516171819202122232425262728293031323334353637383940//Activity创建public void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState);&#125;//Activity可见@Overrideprotected void onStart() &#123; super.onStart();&#125;//Activity变成可交互@Overrideprotected void onResume() &#123; super.onResume();&#125;//Activity失去焦点，不可交互@Overrideprotected void onPause() &#123; super.onPause();&#125;//Activity不再可见，处于停止状态@Overrideprotected void onStop() &#123; super.onStop();&#125;//Activity销毁@Overrideprotected void onDestroy() &#123; super.onDestroy()；&#125;//Activity由不可见到可见的一个过渡@Overrideprotected void onRestart() &#123; super.onRestart()；&#125; 这些方法定义了Activity完整的生命周期，实现这些方法，我们能监控Activity生命周期中的三个嵌套循环(monitor three nested loops in the activity lifecycle) Activity的entire lifetime（全部的生命期）发生在调用onCreate()和调用onDestory()之间。在onCreate()方法中执行全局状态的建立(例如定义布局)，在onDestroy()方法中释放所有保存的资源。 Activity的visible lifetime(可见的生命期)发生在调用onStart()和onStop（)之间。在这个期间，用户能在屏幕上看见Activity，和它进行交互。系统在Activity的完整寿命中可能多次调用onStart()和onStop(),正如Activity交替地对用户可见或隐藏。 Activity的foreground lifetime (前台的生命期)发生在调用onResume()和onPause()之间。在这期间，Activity在屏幕上所有其他Activity的前面，有用户输入焦点。一个Activity能频繁的在前台进入和出去之间转变。 0.2. 生命周期图下面这张图很好的讲解了Activity的生命周期和上面说的三种生命期： 0.3. Demo代码下面通过一个Demo来学习以下Activity的生命周期。Demo很简单，就只有两个Activity，MainActivity和SecondActivity和一个按钮。点击按钮，由MainActivity跳转到SecondActivity。 0.3.1. MainActivity1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.example.activitytest;import android.app.Activity;import android.content.Intent;import android.os.Bundle;import android.util.Log;import android.view.View;import android.view.View.OnClickListener;import android.widget.Button;public class MainActivity extends Activity &#123; private Button btn; private static final String TAG = "ActivityTest"; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); Log.d(TAG, "MainActivity onCreate"); setContentView(R.layout.activity_main); btn = (Button)findViewById(R.id.btn); btn.setOnClickListener(new OnClickListener() &#123; @Override public void onClick(View v) &#123; Intent intent = new Intent(MainActivity.this,SecondActivity.class); startActivity(intent); &#125; &#125;); &#125; @Override protected void onPause() &#123; Log.d(TAG, "MainActivity onPause "); super.onPause(); &#125; @Override protected void onResume() &#123; Log.d(TAG, "MainActivity onResume "); super.onResume(); &#125; @Override protected void onStart() &#123; super.onStart(); Log.d(TAG,"MainActivity onStart "); &#125; @Override protected void onStop() &#123; super.onStop(); Log.d(TAG, "MainActivity onStop "); &#125; @Override protected void onDestroy() &#123; super.onDestroy(); Log.d(TAG, "MainActivity onDestroy "); &#125; @Override protected void onRestart() &#123; super.onRestart(); Log.d(TAG, "MainActivity onRestart "); &#125;&#125; 0.3.2. SecondActivity1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.example.activitytest;import android.app.Activity;import android.os.Bundle;import android.util.Log;public class SecondActivity extends Activity &#123; private static final String TAG = "ActivityTest"; @Override protected void onCreate(Bundle savedInstanceState) &#123; setContentView(R.layout.second_layout); super.onCreate(savedInstanceState); Log.d(TAG,"SecondActivity onCreate"); &#125; @Override protected void onStart() &#123; super.onStart(); Log.d(TAG, "SecondActivity onStart"); &#125; @Override protected void onResume() &#123; super.onResume(); Log.d(TAG, "SecondActivity onResume"); &#125; @Override protected void onPause() &#123; super.onPause(); Log.d(TAG, "SecondActivity onPause"); &#125; @Override protected void onStop() &#123; super.onStop(); Log.d(TAG, "SecondActivity onStop"); &#125; @Override protected void onDestroy() &#123; super.onDestroy(); Log.d(TAG, "SecondActivity onDestroy"); &#125; @Override protected void onRestart() &#123; super.onRestart(); Log.d(TAG, "SecondActivity onRestart"); &#125;&#125; 0.3.3. Manifest.xml使用Activity需要在Manifest.xml文件中注册： 12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;manifest xmlns:android="http://schemas.android.com/apk/res/android" package="com.example.activitytest" android:versionCode="1" android:versionName="1.0" &gt; &lt;uses-sdk android:minSdkVersion="8" android:targetSdkVersion="21" /&gt; &lt;application android:allowBackup="true" android:icon="@drawable/ic_launcher" android:label="@string/app_name" android:theme="@style/AppTheme" &gt; &lt;activity android:name=".MainActivity" android:label="@string/app_name" &gt; &lt;intent-filter&gt; &lt;action android:name="android.intent.action.MAIN" /&gt; &lt;category android:name="android.intent.category.LAUNCHER" /&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;activity android:name=".SecondActivity" android:label="SecondActivity" android:theme="@android:style/Theme.Dialog" &gt; &lt;/activity&gt; &lt;/application&gt; 0.4. 生命周期详解0.4.1. 运行应用，MainActivity运行从下图中的日志我们可以看出一个Activity运行调用的回调方法是:onCreate()-&gt;onStart()-&gt;onResume()，即创建-&gt;可见-&gt;可交互 0.4.2. 点击跳转按钮，由MainActivity跳转到 SecondActivity根据 SecondActivity 是否为 Dialog， 有以下两种情况： 0.4.2.1. SecondActivity 为 Dialog 由于SecondActivity是Dialog，所以 MainActivity 依然可见，但是不能交互（即失去焦点），所以只调用了 MainActivity 的onPause()方法。 0.4.2.2. SecondActivity 不是 Dialog（只需在Manifest.xml文件中删掉 android:theme=”@android:style/Theme.Dialog”这一行即可），再点击跳转按钮: 对于MainActivity,由于不可见，状态由运行变为停止，但是并没有销毁。依次调用了它的回调方法:onPause()-&gt;onStop() 0.4.3. Activity处于运行状态时，点击返回按钮 点击返回按钮，Activity由运行状态变为死亡状态，依次调用它的回调方法:onPause()-&gt;onStop()-&gt;onDestroy()，即失去焦点-&gt;不可见-&gt;销毁 0.4.4. Activity处于运行状态，点击主页按钮，返回桌面 Activity由运行状态变为停止状态，依次调用它的回调方法:onPause()-&gt;onStop() 0.4.5. Activity处于停止状态，由桌面返回到Activity 停止-&gt;运行，从不可见到可见，onRestart 是一个过渡，依次调用回调方法：onRestart()-&gt;onStart()-&gt;onResume() 0.4.6. Activity处于运行状态，旋转屏幕可以看出，旋转屏幕是一个销毁Activity然后重新创建Activity的过程。运行-&gt;暂停-&gt;停止-&gt;死亡-&gt;运行依次调用回调方法:onPause()-&gt;onStop-&gt;onDestroy()-&gt;onCreate()-&gt;onStart()-&gt;onResume() 0.4.7. Activity处于运行状态，手机此时锁屏 可以看出，手机锁屏，此时由于Activity不可见，会进入停止状态。依次调用回调方法：onPause()-&gt;onStop() 0.4.8. 当应用正在运行时，手机锁屏，然后解锁回到应用界面 可以看出应用从停止状态恢复到运行状态。 依次调用回调方法：onRestart()-&gt;onStart()-&gt;onResume()]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Activity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android 数据库操作]]></title>
    <url>%2F2016%2F02%2F22%2FAndroid-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[0.1. 事务 1234567891011121314151617SQLiteDatabase db = myOpenHelper.getReadableDatabase();// 1.开启事务db.beginTransaction(); try &#123; // 2.实现具体的业务逻辑，这里以转账为例 db.execSQL("update info set money = money - 100 where name = ?", new Object[] &#123; "张三" &#125;); db.execSQL("update info set money = money + 100 where name = ?", new Object[] &#123; "李四" &#125;); // 3.给当前事务设置一个成功的标记，即提交事务 db.setTransactionSuccessful();&#125; catch (Exception e) &#123; Toast.makeText(getApplicationContext(), "服务器忙,请稍后再转", 1).show();&#125; finally &#123; // 4.在finally块中关闭事务 db.endTransaction();&#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android 文件保存位置]]></title>
    <url>%2F2016%2F02%2F11%2FAndroid-%E6%96%87%E4%BB%B6%E4%BF%9D%E5%AD%98%E4%BD%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[0.1. 上下文对象FileOutputStream fos = context.openFileOutput("infoo.txt", 0); 文件保存的位置是：/data/data/当前应用包名/files/infoo.txt 0.2. cache缓存File file = new File(getCacheDir(), "cache.txt"); 文件保存的位置是：/data/data/当前应用包名/cache/cache.txt 0.3. sd卡0.3.1. 判断sd卡状态是否已挂载String sdCardState = Environment.getExternalStorageState(); if(Environment.MEDIA_MOUNTED.equals(sdCardState)) { //sd卡已挂载，可用 }; 0.3.2. 获取sd目录String sdPath = Environment.getExternalStorageDirectory().getPath(); File file = new File(sdPath,"haha.txt"); 文件保存的位置是：/storage/sdcard/haha.txt 0.3.3. 获取sd卡总大小和可用空间File file = Environment.getExternalStorageDirectory(); long totalSpace = file.getTotalSpace(); //总大小，单位是字节 long usableSpace = file.getUsableSpace(); //可用空间 0.3.4. 转换数据格式将上文获取到的字节大小转化为可读形式，MB，GB形式 String formatToatalSpace = Formatter.formatFileSize(this, totalSpace); String formatusableSpace = Formatter.formatFileSize(this,usableSpace); 0.3.5. sd卡写权限写入sd卡，需要在Android清单文件中加上权限： &lt;!-- 往SDCard写入数据权限 --&gt; &lt;uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" /&gt; 0.4. SharedPreferences0.4.1. 初始化sp的实例/** * name 会帮助我们生成一个xml文件 * mode 模式 */ sp = getSharedPreferences("config", MODE_PRIVATE); 文件保存的位置是：/data/data/当前应用包名/shared_prefs/config.xml 0.4.2. 获取sp的编辑器Editor edit = sp.edit(); edit.putString("name", name); edit.putString("pwd", pwd); 0.4.3. 提交editedit.commit(); 注意：使用完Editor实例后，一定要记得提交！！！]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[启动android模拟器报错]]></title>
    <url>%2F2015%2F12%2F07%2F%E5%90%AF%E5%8A%A8android%E6%A8%A1%E6%8B%9F%E5%99%A8%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[启动android模拟器时.有时会报The connection to adb is down, and a severe error has occured.的错误.在网友说在任务管理器上把所有adb.exe关闭掉.重启eclipse.但试过不管用.所以在外国网站上找到一种可行的方法: 先把eclipse关闭. 在管理器转到你的android SDK 的platform-tools下, 如图: 键入adb kill-server ,如果adb关闭了会提示 server not running * 再输入 adb start-server 如果不成功会提示 daemon not running. starting it now on port *的而如果成功的话不提示任何语句的.这时再重新打开eclipse就可以正常运行模拟器的了. 还有一种情况,真机调试的时候,你开了腕豆夹,导致端口冲突了,前面一直没留意这个问题 ，解决办法：安装完手机的驱动后，关闭腕豆夹,重启eclipse，应该就可以了。腕豆夹与eclipse一般不同时打开！]]></content>
      <categories>
        <category>Android工具</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Andriod学习笔记]]></title>
    <url>%2F2015%2F11%2F25%2FAndriod%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[0.1. 四大组件0.1.1. 活动活动（Activity），其中活动是所有 Android 应用程序的门面，凡是在应用中你看得到的东西，都是放在活动中的。 0.1.2. 服务服务（Service），服务就比较低调了，你无法看到它，但它会一直在后台默默地运行，即使用户退出了应用，服务仍然是可以继续运行的 0.1.3. 广播接收器广播接收器（BroadcastReceiver）可以允许你的应用接收来自各处的广播消息，比如电话、短信等，当然你的应用同样也可以向外发出广播消息。 0.1.4. 内容提供器内容提供器（Content Provider）则为应用程序之间共享数据提供了可能，比如你想要读取系统电话簿中的联系人，就需要通过内容提供器来实现。 12]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android开发更新 SDK 的国内镜像]]></title>
    <url>%2F2015%2F11%2F22%2F%E5%9B%BD%E5%86%85%E6%97%A0%E7%BC%9D%E6%9B%B4%E6%96%B0Android-SDK%2F</url>
    <content type="text"><![CDATA[打开Android SDK Manager， 打开设置 设置代理可选取下面之一 大连东软信息学院镜像服务器地址（推荐使用，本人亲测可用） 服务器: http://mirrors.neusoft.edu.cn 端口:80 北京化工大学镜像服务器地址 IPv4: http://ubuntu.buct.edu.cn 端口：80IPv4: http://ubuntu.buct.cn 端口：80IPv6: http://ubuntu.buct6.edu.cn 端口：80 上海GDG镜像服务器地址 服务器: http://sdk.gdgshanghai.com 端口：8000 中国科学院开源协会镜像站地址 IPV4/IPV6: http://mirrors.opencas.cn 端口：80IPV4/IPV6: http://mirrors.opencas.org 端口：80IPV4/IPV6: http://mirrors.opencas.ac.cn 端口：80 腾讯Bugly 镜像 http://android-mirror.bugly.qq.com 端口：8080腾讯镜像使用方法:http://android-mirror.bugly.qq.com:8080/include/usage.html 关闭设置页， 选择Packages-&gt;Reload 重新加载， 接下来你就可以无阻碍的更新各种SDK了。 AndroidDevTools 还提供了很多Android 相关工具的下载地址， 推荐给您]]></content>
      <categories>
        <category>Android工具</category>
      </categories>
      <tags>
        <tag>SDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从理论到实践，全方位认识DNS（实践篇）]]></title>
    <url>%2F2015%2F11%2F16%2F%E4%BB%8E%E7%90%86%E8%AE%BA%E5%88%B0%E5%AE%9E%E8%B7%B5%EF%BC%8C%E5%85%A8%E6%96%B9%E4%BD%8D%E8%AE%A4%E8%AF%86DNS%EF%BC%88%E5%AE%9E%E8%B7%B5%E7%AF%87%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1. 前言在理论篇中，我们基本了解了DNS的整个协议原理，但是可能还会有着下面的疑问： 为什么我想申请的域名都没了？ DNS 域名还要备案，这是为什么啊？ 如何将刚申请的域名绑定到自己的网站呢？ 怎么才能看到那些在背后默默给我解析的域名服务器呢？ 他们说用一个什么文件就可以访问好多好多不存在的网站，是真的吗？ 可信任的域名服务器是怎么一回事，难道有些域名服务器会做坏事？ 怎么知道我现在用的域名服务器有没有使坏呢？ …… 我不准备一个一个地去回答这些问题，不过相信我，读完本文，对于上面问题的答案你会有一个清晰的认识，并且可以解决其他各种各样关于 DNS 方面的问题。 2. 域名注册、绑定首先明确一点，每个人都可以去注册域名。大多数时候我们希望去注册一个顶级域名（比如selfboot.cn, google.com等），那些二级域名毕竟不够好记（比如github托管博客的域名：username.github.io）。有的顶级域名（比如.tk域名）提供免费的一年域名试用，不过绝大多时候还是要为自己的域名付费的（一般是按年付费，也不是很贵）。要想去注册域名，首先得找到域名注册商，国内的比较著名的有DNSpod等，国外的有godaddy等。相信注册过域名的人都知道绝大多数我们能想到的自己喜欢的域名都已名花有主了，只剩那些不是那么惹人关注的域名供我们选择。所以，注册域名时，发现自己每想到一个域名都显示被人注册后，那太正常不过了，说明你的品味比较正常。 这里一点个人建议，选中一个域名后不要轻易去改了，因为换域名成本挺高的（我猜现在就算给淘宝一千万，它也不会换另成一个域名吧）。所以，最好不要去用免费的域名，因为指不定啥时候就不让你用了。你应该相信这么一个观点：天下没有免费的午餐。拓展一下就是，掏钱买服务，心里踏实。 接下来你可能会希望将自己的站点或者博客挂在自己选中的域名下，这其实很简单，只需要找到一个提供域名解析的服务商，然后填写相应的域名解析记录。大多时候，你注册域名的服务商都会免费提供域名解析服务。 2.1. 个人博客现实中，大部分人可能会拥有个人博客，以前我们都是依赖一个博客平台（如CSDN），或者是买一台VPS托管自己的博客。不过自从Github推出了Blog服务，好多程序员都转而将博客托管在上面。 这里顺便推荐大家一款十分优秀的基于github的个人博客系统 hexo Github Blog支持绑定个人域名，并提供了详细的绑定文档：Adding a CNAME file to your repository。假设你的博客已经可以通过 username.github.io 访问，接下来只需要用 CNAME 告诉Github你的博客绑定了哪个域名（比如说是 selfboot.cn），然后在域名解析商那里添加解析记录即可，下图是我个人博客在DNSpod的解析记录： 现在当我们访问 selfboot.cn 时，DNSpod就会将请求解析到 Github 提供的 IP 地址上。之后 Github 上面的博客托管服务器在所有用户的 CNAME 记录中，找到本次请求的域名对应的博客项目地址，比如说是 xuelangZF.github.io，然后返回博客内容。 3. 域名解析我们都知道一个域名的解析过程中，可能会有多台域名服务器给我们帮助，那么我们怎么能看到这些背后的功臣呢？先介绍两个常用的关于DNS的命令： dignslookup 3.1. digdig(Domain Information Groper), 是 UNIX/BSD 系统自带的 DNS 诊断工具，使用十分灵活、方便。查询 selfboot.cn 的A记录，并返回简短的结果： 123$ dig selfboot.cn -t A +short192.30.252.153192.30.252.154 用 dig 还可以查询某一 ip 对应的域名，如下： 12$ dig -x 192.30.252.153 +shortpages.github.com. 这里返回的是pages.github.com，因为当你访问博客地址 selfboot.cn 时，其实是Github的pages 服务器（域名是：pages.github.com）在后台返回该博客内容的（根据 CNAME 确定返回哪个博客）。 3.2. nslookupnslookup 也是一个 DNS 诊断工具，几乎所有平台都自带该工具，使用也很简答，可以用 man 查询手册。 3.3. 解析路径查询接下来用 dig 命令查看从根域名到指定域名中间可能经过的所有域名服务器，使用 +trace 选项即可。1234567891011121314151617181920212223242526dig selfboot.cn +trace @8.8.8.8 ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; selfboot.cn +trace @8.8.8.8;; global options: +cmd. 474418 IN NS j.root-servers.net.. 474418 IN NS g.root-servers.net........ 474418 IN NS l.root-servers.net.. 474418 IN NS m.root-servers.net.;; Received 496 bytes from 8.8.8.8#53(8.8.8.8) in 12 ms cn. 172800 IN NS a.dns.cn.......cn. 172800 IN NS e.dns.cn.cn. 172800 IN NS ns.cernet.net.;; Received 292 bytes from 2001:500:1::803f:235#53(2001:500:1::803f:235) in 382 ms selfboot.cn. 86400 IN NS f1g1ns2.dnspod.net.selfboot.cn. 86400 IN NS f1g1ns1.dnspod.net.;; Received 83 bytes from 203.119.25.1#53(203.119.25.1) in 816 ms selfboot.cn. 14400 IN A 192.30.252.153selfboot.cn. 14400 IN A 192.30.252.154selfboot.cn. 600 IN NS f1g1ns1.dnspod.net.selfboot.cn. 600 IN NS f1g1ns2.dnspod.net.;; Received 125 bytes from 115.236.137.40#53(115.236.137.40) in 31 ms 可以看到最开始是13台顶级域名服务器的NS记录（中间省去一些记录减少行数，方便观察更清楚），接下来是顶级域名 cn. 的权威域名服务器（省略一些输出），然后是 selfboot.cn 的 NS 记录，即 DNSpod 的两条 NS 记录，最后从 f1g1ns2.dnspod.net 找到 selfboot.cn 的 A 记录。 seveas 提供了一个可视化的路径查询工具：dnsgraph，可以在线绘制跟域名到指定域名的所有可能路径。 当然，实际查询过程中，大多时候我们在本地缓存或者本地域名服务器缓存就能直接找到需要的域名记录，不需要每次都向根域名服务器发起请求，然后重复迭代或者递归查询过程。 4. DNS 缺陷域名系统设计的很理想很美好，然而仍有一些小的瑕疵，可能会给我们带来些许困扰。 4.1. 域名抢注首先，有些域名对注册人没有限制，而另外一些域名则对谁可以得到一个域名空间中的名字有限制。比如pro域名是分配给合适的专业人员，但问题是谁才是专业的呢？显然医生、工程师是专业人员，但理发师、管道工呢？ 此外，域名也可以被倒卖。黄牛们会批量注册大量域名（据说com域名下几乎每一个普通词都被人尝试注册了域名），然后转身就以高价转卖给那些对该域名感兴趣的人，这就是所谓的域名抢注。所以，现在你想注册一个符合自己网站特点的域名是很难的。 这个问题其实还不算严重，更要命的是下面两个问题。 4.2. DNS 劫持我们知道一个域名服务器对其区域内的用户解析请求负责，但是并没有一个机制去监督它有没有真地负责。也就是说域名服务器的权力并没有被关在笼子里，所以它既可以认真地“为人民服务”，也可以“指鹿为马”。于是有些流氓的域名服务器故意更改一些域名的解析结果，将用户引向一个错误的目标地址。这就叫作 DNS 劫持，主要用来阻止用户访问某些特定的网站，或者是将用户引导到广告页面。 下面验证下我所用的域名服务器有没有干这种坏事，只需要一条简单的命令即可：1234567➜ ~ nslookup google.comServer: 10.8.4.4Address: 10.8.4.4#53 Non-authoritative answer:Name: google.comAddress: 120.196.0.5 我的DNS服务器地址为10.8.4.4，他告诉我google.com的地址是120.196.0.5，我才不信呢。于是用whois 120.196.0.5一看，果真不是Google的地址。针对DNS劫持，我们可以简单地更换域名服务器，比较靠谱的一个是Google提供的8.8.8.8。下面用 8.8.8.8 来解析一下 www.google.com 就能看到正确的地址了。1234567$ nslookup www.google.com 8.8.8.8Server: 8.8.8.8Address: 8.8.8.8#53 Non-authoritative answer:Name: www.google.comAddress: 216.58.221.68 4.3. DNS 欺骗DNS 劫持通过简单的切换域名服务器就可以绕过，不过一旦你遇上了 DNS 欺骗，就无法简单地绕过了。下面我们用不同的域名服务器来查看 fb 的 IP 地址，结果都返回了同一个地址，看起来好像是真的一样，不过也仅仅是看起来而已。123456789101112131415$ nslookup facebook.comServer: 10.8.4.4Address: 10.8.4.4#53 Non-authoritative answer:Name: facebook.comAddress: 159.106.121.75 $ nslookup facebook.com 8.8.8.8Server: 8.8.8.8Address: 8.8.8.8#53 Non-authoritative answer:Name: facebook.comAddress: 159.106.121.75 这个地址并不是 fb 的服务器地址（可以在 ViewDNS 查询所有域名真实的域名资源记录，ViewDNS是个很好玩的网站，里面有许多有意思的工具）。其实我Google了一下这个地址，竟然发现了一篇不错的译文，看来这个地址早在 2011 年就有了特殊的含义（英文原文是相关阅读第一个）。 DNS 欺骗简单来说就是用一个假的 DNS 应答来欺骗用户计算机，让其相信这个假的地址，并且抛弃真正的 DNS 应答。在一台主机发出 DNS 请求后，它就开始等待应答，如果此时有一个看起来正确（拥有和DNS请求一样的序列号）的应答包，它就会信以为真，并且丢弃稍晚一点到达的应答。 实施 DNS 欺骗的关键在于伪造一个有特定序列号的应答包，并且让其抢先一步到达发起请求的主机。这对于个人来说还有点难度，但是对于拥有骨干网节点的组织来说，实在是易如反掌，所以这么多网站都已沦陷。不过使用网上流传的那些 hosts文件，就可以在本机缓存许多网站的ip地址，进而可以和部分网站通信。但是通过hosts文件并不能完全跨功夫网，因为人家还有很多其他手段。 5. 参考 DNS cache poisoning DNS Spoofing vs DNS Cache Poisoning Reset the DNS cache in OS X 人为网络故障 DNS欺骗原理及工作工程分析 DNS污染与劫持之个人小见 【转载】 http://blog.jobbole.com/94614/]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从理论到实践，全方位认识DNS（理论篇）]]></title>
    <url>%2F2015%2F11%2F15%2F%E4%BB%8E%E7%90%86%E8%AE%BA%E5%88%B0%E5%AE%9E%E8%B7%B5%EF%BC%8C%E5%85%A8%E6%96%B9%E4%BD%8D%E8%AE%A4%E8%AF%86DNS%EF%BC%88%E7%90%86%E8%AE%BA%E7%AF%87%EF%BC%89%2F</url>
    <content type="text"><![CDATA[对于 DNS(Domain Name System) 大家肯定不陌生，不就是用来将一个网站的域名转换为对应的IP吗。当我们发现可以上QQ但不能浏览网页时，我们会想到可能是域名服务器挂掉了；当我们用别人提供的hosts文件浏览到一个“不存在”的网页时，我们会了解到域名解析系统的脆弱。然而关于DNS还有一大堆故事值得我们去倾听，去思考。 1. DNS 起源要想访问网络上的一台计算机，我们必须要知道它的IP地址，但是这些地址（比如243.185.187.39）只是一串数字，没有规律，因此我们很难记住。并且如果一台计算机变更IP后，它必须通知所有的人。 显然，直接使用IP地址是一个愚蠢的方案。于是人们想出了一个替代的方法，即为每一台计算机起一个名字，然后建立计算机名字到地址的一个映射关系。我们访问计算机的名字，剩下的名字到地址的转换过程则由计算机自动完成。 2. hosts 映射早期，名字到地址的转换过程十分简单。每台计算机保存一个hosts文件，里面列出所有计算机名字和对应的IP地址，然后定期从一个维护此文件的站点更新里面的记录。当我们访问某个计算机名字时，先在hosts文件找到对应的IP，然后就可以建立连接。 早期的 ARPANET 就是这样做的，但是随着网络规模的扩大，这种方法渐渐吃不消了。主要有以下三个原因： hosts文件变得非常大； 主机名字会冲突； 集中的维护站点会不堪重负（需要给几百万机器提供hosts文件，想想就可怕）。 3. 域名系统为了解决上面的问题，1983年Paul Mockapetris提出了域名系统（DNS, Domain Name System)，这是一种层次的、基于域的命名方案，并且用一个分布式数据库系统加以实现。当我们需要访问一个域名（其实就是前面说的计算机的名字）时，应用程序会向DNS服务器发起一个DNS请求，DNS服务器返回该域名对应的IP地址。通过下面三种手段解决了上面的问题： 用户计算机上并没有存储所有的名字到IP的映射，这样避免了hosts文件过于庞大（现在各操作系统中hosts文件默认都是空的）。 规定了域名的命名规则，保证主机名字不会重复。 DNS服务器不再是单一的一台机器，而是一个层次的、合理组织的服务器集群。 这样访问一个域名的过程可以简化为下图： 4. DNS 协议那么如何具体实现这个所谓的域名系统呢，要知道管理一个超大型并且不断变化的域名到IP的映射集合可不是一个简单的事，况且还要去应付成千上万的DNS查询请求。人们最终想出了一套不错的协议，规定如何来实现这个系统，下面我们一起来看看吧。 4.1. 域名空间首先我们需要制定一套命名规则，防止域名出现重复。DNS关于域名的规则和我们生活中的快递系统类似，使用层次的地址结构。快递系统中要给某人邮寄物品，地址可能是这样：中国、广东省、广州市、番禺区、中山西路12号 XXX。而一个域名看起来则是这样的groups.google.com（为什么不是com.google.groups？我猜可能和老外写地址的习惯有关）。 对于Internet来说，域名层次结构的顶级（相当于国际快递地址中的国家部分）由 ICANN （互联网名称与数字地址分配机构）负责管理。目前，已经有超过250个顶级域名，每个顶级域名可以进一步划为一些子域（二级域名），这些子域可被再次划分（三级域名），依此类推。所有这些域名可以组织成一棵树，如下图所示（图片来自Computer Networks: 7-1 ）： 5. 域名资源记录DNS设计之初是用来建立域名到IP地址的映射，理论上对于每一个域名我们只需要在域名服务器上保存一条记录即可。这里的记录一般叫作域名资源记录，它是一个五元组，可以用以下格式表示： Domain_name Time_to_live Class Type Value 其中： Domain_name: 指出这条记录适用于哪个域名； Time_to_live: 用来表明记录的生存周期，也就是说最多可以缓存该记录多长时间（后面会讲到缓存机制）； Class: 一般总是IN； Type: 记录的类型； Value: 记录的值，如果是A记录，则value是一个IPv4地址。我们看到域名资源记录有一个Type字段，用来表明记录的类型。这是为什么呢？因为对于一个域名来说，通常并非只记录其IP地址，还可能需要一些其他种类的记录，一些常见的记录类型如下： 记录类型 含义 A 主机的IPv4地址 AAAA 主机的IPv6地址 NS 该域名所在域的权威域名服务器 MX 接受特定域名电子邮件的服务器域名 CNAME 当前域名的一个别名 MX 接受特定域名电子邮件的服务器域名 关于这些域名资源记录的实例我们将在下一篇文章（实践篇）看到。 5.1. 域名服务器我们知道不能只用一台域名服务器来响应所有的DNS查询，因为没有一台机器能够给全球的用户提供查询服务，计算能力、存储、带宽都不允许。只能合理组织一个域名服务器集群，使他们协同工作，共同提供域名解析服务。接下来首先要面对的一个问题是如何合理地将所有的域名资源记录存储到不同的域名服务器上。 前面说过域名的名字空间可以组织为一棵树，这里我们可以进一步将其划分为不重叠的区域（DNS zone），针对上图的域名空间，一种可能的域名划分如下图： 然后将每个区域与多个域名服务器（其中一个是master，其他slave服务器则用来提供数据备份、加快解析速度、保证服务可用性）关联起来，称这些域名服务器为该区域的权威域名服务器(Authoritative Name Servers )，它保存两类域名资源记录： 该区域内所有域名的域名资源记录。 父区域和子区域的域名服务器对应的域名资源记录（主要是NS记录）。 这样，所有的域名资源记录都保存在多个域名服务器中，并且所有的域名服务器也组成了一个层次的索引结构，便于我们后面进行域名解析。下面以一个简化的域名空间为例子，说明域名资源记录是如何保存在域名服务器中的，如下图a： 图中域名空间划分为A, B, C, D, E, F, G七个DNS区域，每个DNS区域都有多个权威域名服务器，这些域名服务器里面保存了许多域名解析记录。对于上图的NDS区域E来说，它的权威域名服务器里面保存的记录如图中表格所示。 仔细观察上图你可能会发现区域A、B并没有父区域，他们之间并没有一条路径连在一起。这将导致一个很麻烦的问题，那就是区域A的权威域名服务器可能根本不知道区域B的存在。认识到这一点后，你可能会想出一个很自然的解决方案，就是在A中记录B域名服务器的地址，同时在B中记录A的，这样它们两个就联系起来了。但是考虑到我们有超过250个顶级域名，这样做并不是很恰当。 而我们使用的域名系统则采用了一种更加聪明的方法，那就是引入根域名服务器，它保存了所有顶级区域的权威域名服务器记录。现在通过根域名服务器，我们可以找到所有的顶级区域的权威域名服务器，然后就可以往下一级一级找下去了。下图为全球根域名服务器的分布图，可以在这里找到。 现在为止，我们的权威域名服务器和根域名服务器其实组成了一个树，树根为根域名服务器，下面每个节点都是一个区域的权威域名服务器，对于图a中各个DNS区域的权威域名服务器，它们组成了下面这棵树（实际中，一个权威域名服务器可能保存有多个DNS区域的记录，因此权威域名服务器之间的联系并不构成一棵树。这部分的详细内容可以参考RFC 1034: 4. NAME SERVERS。下面为了容易理解，将其简化为一棵树）： 5.2. 域名解析我们已经有了一个域名服务器集群，该集群合理地保存了域名空间和域名资源记录的对应关系。现在我们要做的就是发送一个DNS请求给域名服务器，然后坐等它返回正确的域名资源记录，这个过程叫作域名解析。 严格来说，域名解析的过程最早要追溯到建立网络连接。因为每当连接上网络之后，计算机会自动获得一个默认的DNS服务器，当然你也可以用自己信任的DNS服务器，比如8.8.8.8（DNS服务器也有信任不信任之分，是的，实践篇会讲到），我们把这个域名服务器也叫作本地域名服务器。接下来当我们需要知道一个域名对应的资源记录时，会向本地域名服务器发起请求，如果该域名恰好在本地域名服务器所辖属的域名区域（DNS zone）内，那么可以直接返回记录。 如果在本地域名服务器没有发现该域名的资源记录，就需要在整个域名空间搜索该域名。而整个域名空间的资源记录存储在一个分层的、树状联系的一系列域名服务器上，所以本地域名服务器首先要从根域名服务器开始往下搜索。这里有一个问题就是本地域名服务器如何找到根域名服务器在哪里呢？其实域名服务器启动的时候，就会加载一个配置文件，里面保存了根域名服务器的NS记录（要知道根域名服务器地址一般非常稳定，不会轻易改变，并且数量很少，所以这个配置文件会很小）。找到根域名服务器之后，就可以一级一级地往下查找啦。 仍然以我们的图a为例，现在假设区域E内的某个用户想访问math.sysu.edu.cn，那么请求的过程如下： 用语言简单描述如下： 用户：喂，本地域名服务器，告诉我math.sysu.edu.cn的地址； 本地域名服务器：哎呀，我不知道啊，不在我的辖区，容我去问问老大哥吧。root老大，能告诉我math.sysu.edu.cn的地址吗； 根域名服务器：忙着呢，你去问B（.cn）； 本地域名服务器：喂，B，告诉我math.sysu.edu.cn的地址； B：你去问D（.edu.cn）； 本地域名服务器：喂，D，告诉我math.sysu.edu.cn的地址； D：你去问F（sysu.edu.cn）； 本地域名服务器：喂，F，告诉我math.sysu.edu.cn的地址； F：容老衲看看，哎呀，找到了，是X.X.X.X； 本地域名服务器：踏破铁鞋终于找到啦，喂用户，出来啊，我找到了，是X.X.X.X 仔细想想，这和我们邮寄快递实在是如出一辙啊，假设你从美国邮东西到广州市番禺区，首先快递送到中国（不过这里没有一个类似根域名服务器的中转站而已），然后往下到广东省，接下来是广州市，再往下是番禺了。 上面的是本地域名服务器的迭代解析过程，其实也可以递归查询，这里就不说了，道理差不多。 5.3. 缓存机制现在整个域名系统已经可以为我们提供域名解析服务了，当我们输入域名，计算机发送DNS请求，然后DNS服务器返回给我们解析的结果，一切看起来很完美。然而是不是可以更完美呢？ 回顾一下平时浏览网站的情况，我们会发现两个比较有意思的结论： 80%的时间我们都在看那些20%的网站，这就是大名鼎鼎的80/20 Rule； 我们会在一个网站的不同网页之间跳转，也就是不断地访问同一个域名，类似程序访问的局部性原理。 这两条结论很容易让我们联想到缓存机制。如果我们将已经访问过的那些域名的解析结果缓存在自己的计算机上，那么下次访问的时候可以直接读取结果，不用再次重复DNS查询过程，给自己和域名服务器都节省了麻烦。 当然，这样做的一个前提是要缓存的解析结果不会频繁更改，也就是说我十分钟后解析一个域名的结果和现在解析的结果是一样的。对大多数域名来说，这都是一个不争的事实。但是难免有一些“善变”的域名，他们可能会频繁更改自己的解析结果。为了使缓存机制适应这两类情况，我们在域名资源记录里面添加一个Time_to_live字段，表明这条记录最多可以缓存多久。对于那些“稳如泰山”的域名，给一个比较大的值，而那些“朝三暮四”的域名，则可以给定一个小的值。 我们既然可以在本机利用缓存，那么可不可以在域名服务器上也利用缓存机制呢，答案当然是可以的。因为对于域名服务器来说，上面的两条有意思的结论仍然有效。所以，域名服务器可以将那些访问过的域名资源记录缓存，用户再次发起请求时，可以直接返回缓存结果，不用去迭代或者递归解析。 关于DNS理论部分，更多内容还可以参考这两个文本： RFC 1034: Domain Names – Concepts and Facilities 6. 并没有结束上面一大堆理论，看上去有点不明所以是吧，没事，接下来会结合实践来更加清晰地认识DNS这一最基础的系统。 其实不止是DNS，还有HTTPS、TCP、UDP这些很基础的协议，都值得我们静下心去好好认识它们。因为，写DNS之前，我以为我已经完全搞明白了它，但是写的过程发现好多地方自己根本就不知道，之前完全是停留在一个很浮夸的层面上。所以，是时候找时间好好把这些协议过一遍，用自己的语言，从解决问题的角度，记录下这些经典协议的故事了。 【转载】http://blog.jobbole.com/94132/]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java TreeMap 源码分析]]></title>
    <url>%2F2015%2F11%2F02%2FJava-TreeMap-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1. TreeMap类签名123public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable 可以看到，相比HashMap来说，TreeMap多继承了一个接口 NavigableMap，也就是这个接口，决定了TreeMap与HashMap的不同： HashMap的key是无序的，TreeMap的key是有序的 1.1. 接口NavigableMap首先看下NavigableMap的签名1public interface NavigableMap&lt;K,V&gt; extends SortedMap&lt;K,V&gt; 发现NavigableMap继承了SortedMap，再看SortedMap的签名 1.1.1. SortedMap1public interface SortedMap&lt;K,V&gt; extends Map&lt;K,V&gt; SortedMap就像其名字那样，说明这个Map是有序的。这个顺序一般是指由 Comparable 接口提供的keys的自然序（natural ordering），或者也可以在创建SortedMap实例时，指定一个Comparator 来决定。 当我们在用集合视角（collection views，与HashMap一样，也是由entrySet、keySet与values方法提供）来迭代（iterate）一个SortedMap实例时会体现出key的顺序。 这里引申下关于Comparable与Comparator的区别（参考这里）： Comparable一般表示类的自然序，比如定义一个Student类，学号为默认排序 Comparator一般表示类在某种场合下的特殊分类，需要定制化排序。比如现在想按照Student类的age来排序 插入SortedMap中的key的类类都必须继承Comparable类（或指定一个comparator），这样才能确定如何比较（通过k1.compareTo(k2)或comparator.compare(k1, k2)）两个key，否则，在插入时，会报 ClassCastException 的异常。 此为，SortedMap中key的顺序性应该与equals方法保持一致。也就是说k1.compareTo(k2)或comparator.compare(k1, k2)为true时，k1.equals(k2)也应该为true。 介绍完了SortedMap，再来回到我们的NavigableMap上面来。NavigableMap是JDK1.6新增的，在SortedMap的基础上，增加了一些“导航方法”（navigation methods）来返回与搜索目标最近的元素。例如下面这些方法： lowerEntry，返回所有比给定Map.Entry小的元素 floorEntry，返回所有比给定Map.Entry小或相等的元素 ceilingEntry，返回所有比给定Map.Entry大或相等的元素 higherEntry，返回所有比给定Map.Entry大的元素 2. 设计理念（design concept）2.1. 红黑树（Red–black tree）TreeMap是用红黑树作为基础实现的，红黑树是一种二叉搜索树，让我们在一起回忆下二叉搜索树的一些性质 2.2. 二叉搜索树先看看二叉搜索树（binary search tree，BST）长什么样呢？二叉搜索树 相信大家对这个图都不陌生，关键点是： 左子树的值小于根节点，右子树的值大于根节点。 二叉搜索树的优势在于每进行一次判断就是能将问题的规模减少一半，所以如果二叉搜索树是平衡的话，查找元素的时间复杂度为log(n)，也就是树的高度。 我这里想到一个比较严肃的问题，如果说二叉搜索树将问题规模减少了一半，那么三叉搜索树不就将问题规模减少了三分之二，这不是更好嘛，以此类推，我们还可以有四叉搜索树，五叉搜索树……对于更一般的情况： n个元素，K叉树搜索树的K为多少时效率是最好的？K＝2时吗？ 2.3. K 叉搜索树如果大家按照我上面分析，很可能也陷入一个误区，就是 三叉搜索树在将问题规模减少三分之二时，所需比较操作的次数是两次（二叉搜索树再将问题规模减少一半时，只需要一次比较操作） 我们不能把这两次给忽略了，对于更一般的情况： n个元素，K叉树搜索树需要的平均比较次数为k*log(n/k)。 对于极端情况k＝n时，K叉树就转化为了线性表了，复杂度也就是O(n)了，如果用数学角度来解这个问题，相当于： n为固定值时，k取何值时，k*log(n/k)的取值最小？ k*log(n/k)根据对数的运算规则可以转化为ln(n)*k/ln(k)，ln(n)为常数，所以相当于取k/ln(k)的极小值。这个问题对于大一刚学高数的人来说再简单不过了，我们这里直接看结果 当k＝e时，k/ln(k)取最小值。 自然数e的取值大约为2.718左右，可以看到二叉树基本上就是这样最优解了。在Nodejs的REPL中进行下面的操作1234567891011function foo(k) &#123; return k/Math.log(k);&#125;&gt; foo(2)2.8853900817779268&gt; foo(3)&gt; 2.730717679880512&gt; foo(4)2.8853900817779268&gt; foo(5)3.1066746727980594 貌似k＝3时比k＝2时得到的结果还要小，那也就是说三叉搜索树应该比二叉搜索树更好些呀，但是为什么二叉树更流行呢？后来在万能的stackoverflow上找到了答案，主旨如下： 现在的CPU可以针对二重逻辑（binary logic）的代码做优化，三重逻辑会被分解为多个二重逻辑。 这样也就大概能理解为什么二叉树这么流行了，就是因为进行一次比较操作，我们最多可以将问题规模减少一半。好了这里扯的有点远了😊，我们再回到红黑树上来。 2.4. 红黑树性质先看看红黑树的样子：红黑树示例 上图是从wiki截来的，需要说明的一点是： 叶子节点为上图中的NIL节点，国内一些教材中没有这个NIL节点，我们在画图时有时也会省略这些NIL节点，但是我们需要明确，当我们说叶子节点时，指的就是这些NIL节点。 红黑树通过下面5条规则，保证了树是平衡的： 树的节点只有红与黑两种颜色 根节点为黑色的 叶子节点为黑色的 红色节点的字节点必定是黑色的 从任意一节点出发，到其后继的叶子节点的路径中，黑色节点的数目相同 满足了上面5个条件后，就能够保证： 根节点到叶子节点的最长路径不会大于根节点到叶子最短路径的2倍。 其实这个很好理解，主要是用了性质4与5，这里简单说下： 假设根节点到叶子节点最短的路径中，黑色节点数目为B，那么根据性质5，根节点到叶子节点的最长路径中，黑色节点数目也是B，最长的情况就是每两个黑色节点中间有个红色节点（也就是红黑相间的情况），所以红色节点最多为B－1个。这样就能证明上面的结论了。 2.5. 红黑树操作红黑树旋转示例（没有画出NIL节点） 关于红黑树的插入、删除、左旋、右旋这些操作，我觉得最好可以做到可视化，文字表达比较繁琐，我这里就不在献丑了，网上能找到的也比较多，像v_July_v的《红黑树从头至尾插入和删除结点的全程演示图》。我这里推荐个swf教学视频（视频为英文，大家不要害怕，重点是看图😊），7分钟左右，大家可以参考。 这里还有个交互式红黑树的可视化网页，大家可以上去自己操作操作，插入几个节点，删除几个节点玩玩，看看左旋右旋是怎么玩的。 3. 源码剖析由于红黑树的操作我这里不说了，所以这里基本上也就没什么源码可以讲了，因为这里面重要的算法都是From CLR，这里的CLR是指Cormen, Leiserson, Rivest，他们是算法导论的作者，也就是说TreeMap里面算法都是参照算法导论的伪代码。 因为红黑树是平衡的二叉搜索树，所以其put（包含update操作）、get、remove的时间复杂度都为log(n)。 4. 总结到目前为止，TreeMap与HashMap的的实现算是都介绍完了，可以看到它们实现的不同，决定了它们应用场景的不同： TreeMap的key是有序的，增删改查操作的时间复杂度为O(log(n))，为了保证红黑树平衡，在必要时会进行旋转HashMap的key是无序的，增删改查操作的时间复杂度为O(1)，为了做到动态扩容，在必要时会进行resize。 另外，我这里没有解释具体代码，难免有些标题党了，请大家见谅，后面理解的更深刻了再来填坑。😂 5. 参考http://stackoverflow.com/questions/21329662/explanation-of-red-black-tree-based-implementation-of-treemap-in-javahttp://javahungry.blogspot.com/2014/04/fail-fast-iterator-vs-fail-safe-iterator-difference-with-example-in-java.htmlhttps://en.wikipedia.org/wiki/Binary_search_treehttps://en.wikipedia.org/wiki/Red%E2%80%93black_tree 6. 本文转自http://liujiacai.net/blog/2015/09/04/java-treemap/]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
      <tags>
        <tag>TreeMap</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】2015年校招年薪]]></title>
    <url>%2F2015%2F11%2F02%2Foffercome2015%2F</url>
    <content type="text"><![CDATA[1. 印子每年的校招offer的数量、质量表明了各家公司对于整个招聘市场、人才供需的判断，也是我们OfferCome观察市场的一个窗口。每年这个季节，我们都会收到很多自称是渣硕的咨询Offer邮件。渣硕，意思是水平很渣的硕士。虽然今年校招尚未结束，不过大局已定，那今年的渣硕offer呢？是像很多媒体宣称的互联网寒冬嘛？ 2. 先说个对于校招Offer的看法：20W已成为渣硕的普通Offer（后文解释），30W将成为优秀学生的一个新的标杆（有待检验），6、70W将成为应届小牛的标杆（已经检验），大牛单独谈。（本文定义的普通学生是指北邮里会写代码的学生的前5、60%，优秀学生是指前10、20%，小牛是指清北里面的10、20%，大牛是戴文渊、楼教主这种。拿北邮做例子，是因为北邮会写程序的人基数大，方差小。） 然后，我们再强调下，这里的Offer都偏高，这里的Offer都偏高，这里的Offer都偏高！重要的事情说三遍！因为下面这些信息，来源于那些来咨询Offer的童鞋们，他们有个统一的特点：手里都拿着一堆Offer，又想不清各家的利弊。 3. 一、 各家互联网公司15年校招Offer情况3.1. 1、新秀：今年的新秀那自然是今日头条，一战成名方显英雄本色。今年收到了十几个咨询今日头条Offer的，基本清一色23K+股票，深深地让我感受到了张一鸣的决心——我们头条，就是要抢到最好的那批人，不管是校招还是社招。而且，是不限量地抢……我特别好奇，头条SP的价格是什么？ 3.2. 2、BAT：3.2.1. B：今年9月份的时候，北京这边所有公司都在等着B家出Offer，大家好决定今年的校招价格体系。没办法，B家招聘量，尤其是对于技术产品的招聘量太大，行业的脊柱。那今年B家呢？招聘数量没啥大变化，质量上了一个台阶，今年来咨询Offer的有不少17K。去年商搜、PS等核心团队来咨询的，14、15K的更多一些，17K很少见。今年感觉14、15K是人就有，17K的不少。13、14K的基本没见到。我觉得百度早该这样了，拿住最优秀的那批人，才有机会再翻盘。更何况，应届生涨2、3K才多少钱。比起社招来说，还是便宜。 3.2.2. A：大家都知道AB档的情况。我想说的是阿里星，被咨询了两个阿里星的Offer。太狠了，充分体现了什么叫做“要招非凡人，以平常心，做非凡事”。应届生砸6、70W的总包（含股票），在谷歌美国还没出Offer的情况下，基本秒杀所有家。 欢迎其他的阿里星来咨询，我们可以探讨下其他选择、职业发展等各种问题。我也很好奇，阿里星最后发了多少个。 3.2.3. T：数量增了不少，1500变成2000？我忘了具体数字了。质量没啥变化，还是那个价钱。12、13K。SP会再加一些，北京的户口概率算不低。某HR说的非常好，招对的，不招贵的，够用就好。老牌公司的培养体系，超低的流失率，给了T家底气阿。 3.3. 3、京东、唯品会、携程、360：3.3.1. 京东：有些团队很凶猛，从目前看19~28W的都有，20W+的一片片的。 3.3.2. 360：360貌似还没有大面积发offer，个别咨询的，有15、17K。 3.3.3. 唯品会：没见到。 3.3.4. 携程：没见到。 3.4. 4、这两年上市的新锐：3.4.1. 去哪儿：今年的去哪儿快成为上市公司的一个新标杆了，开了不少15~18K的offer，代表除了BAT之外的另外一股力量。考虑到去哪儿是给新人发16薪（12级及以上发19薪）。算下来年薪到了25W+了。（私以为，从后备团队就可以看出来了为什么携程一定要得到去哪儿。去哪儿有很多很多问题，但是去哪儿现在可以拉出来1K人的“工作1~5年+名校+能加班+有冲劲+实操经验丰富”的研发产品。携程连能加班的都找不出来1k人。） 3.4.2. 58：技术的从13~15K的都有，产品样本少，据说是10~15。大批量地招，从去年起，58对待自己的校招生培养很投入,也尝到了甜头，因此狠狠地招。 3.4.3. 汽车之家：很好奇今年会开多少。 3.5. 5、老牌的公司：3.5.1. 网易：游戏就不说了，依然那么璀璨。今年咨询网易游戏Offer的异常多，是说我的错觉还是背后有原因？常规的22~28w很多，SP的今年没见到咨询的。估计都低调地从了，不知道阿里星发了之后，会有跑的没。门户杭研：13K，在杭州还是挺舒服的。有道：老样子，15~17K，SP可以单独再谈，北京能解决一些户口。杭州也要。 3.5.2. 搜狐：搜狐集团：跟去年一样，15~17K，SP会更高一些。值得注意的是，对比搜狐家的招聘量，他的户口指标还是挺多的。搜狗：木知，好像今年很低调。就收到一个咨询的，20W。 3.6. 6、其他家上市公司就不谈了，要么招的量少，要么批发价不超过15K，对市场影响不大。前几天有人说收到某司offer，应届硕士批发价9k，挺伤人的，这为难HR团队阿，只能招人不能招人才阿，公司怎么培养后备团队呢？ 3.7. 7、美团滴滴小米3.7.1. 美团：还是老样子，13~15K的很多，记忆中有个17K的，更高的没见到了。量大。 3.7.2. 滴滴：据说是15K起？但是感觉找我们咨询offer的很少，是因为还没开始大规模发？ 3.7.3. 小米：见到的都是15K的，可能是没有SP咨询我，或者他们没有SP的习惯？不过户口解决总数量应该是北京互联网企业中最高的（if他们算互联网公司的话）。量不小，不过不如美团普及。 3.8. 8、其他创业团队今年的有几家非美团小米滴滴的创业公司，招应届生量大且价高的，巧的是，这里面除了蘑菇街，都是我们客户，看来我们选合作伙伴的眼光不错。 这几家是：头条、猿题库、链家网、宜信、蘑菇街。 3.8.1. 头条：前面说过了。量大且高。 3.8.2. 猿题库：见到的Offer不多，不过都不低，20K、20K+，还是走的精英路线。 3.8.3. 链家：今年招了很多，我们看到的多是15K*15，有个别的SP会更高一些。量大。地产的互联网化大有可为，今年鸟哥加入链家了，链家也是下了大力气招应届生阿，从之前那篇校招文章就可以看出来。一篇校招文章，不用做宣讲会也吸引了很多人投递。 3.8.4. 蘑菇街：乌泱泱的一片，13~15K都见到了。量大。 3.8.5. 其他：其他的咨询的少，个案没有代表性，就不讲了。 4. 二、OfferCome观点：4.1. 1、还有变数吗？今年有变数的基本结束了，虽然还剩谷歌。FLAG等：今年FB不在国内招，MS、Amazon的薪水一直中规中矩，应该也不会暴兵，所以应该不会有变数。T、L两家就不说了，影响力小。Uber、Airbnb什么的要是来中国大规模招聘就好了。G家，前两年进去的，很多签证还没解决，因此听消息人士称，今年规模不会大。要是G家年底真能重返中国，再次建设一个研发中心就好，G家整体氛围还是可以的，可以对于国内某司的价值观有改善作用。 金融系：还没大规模开始，不过他们今年不太好过的样子，不知道会不会最后发力。就算他们发力，以他们的作风，也是低调地在年终奖发力，给应届生的底薪不会很高。不知道今年会不会有国外金融系在国内大规模招人。除了四大行凭借户口砸走一批人外，应该不会有太多影响应届生市场的Offer了。 4.2. 2、薪水行情：开头已经说了。现在，我们重新解释下普通Offer为什么20W，优秀offer 30W？ 4.2.1. 普通Offer 20W：往年，只有B家给到13、14K，个别小公司给的也可能会有。前两年，阿里也提了起来。今年，BA、京东、360、去哪儿、美团滴滴小米，这几个大户，都把普通学生的offer提到了20W±（阿里今年的AB档offer可以视为一个意外，大家知道真实薪水水平），再加上创业团队的冲击，从今年起，渣硕的Offer将会站稳20W。 4.2.2. 优秀Offer 30W：我们写了“待校验”，因为今年主流的30W offer依然集中在5、6家公司手里，BAT没有大规模地改。如果有公司，凭借这批30W的人，改变了一些行业，或许会影响整个行情。如果百度今年还开那么夸张的年终奖，那也可能会导致其他公司开始大面积地开20K15的校招offer，否则拼不过百度的15、1716、20。 4.2.3. 小牛Offer 6、70W：这个我相信没有争议了。虽然今年海外Offer不多，但是这批人的量也不大，大陆一共百来人。除非谷歌、阿里星、网易游戏、海外的金融业都不在国内招人了，否则数字不会变。 4.2.4. 大牛Offer ：有些应届生的offer是单独谈的，例如戴文渊、楼教主等。 至此，我相信不会再有人质疑我们年中的文章《2015年互联网行业薪酬报告——2、3年经验35W将成为标配》 另外：大家总说我们OfferCome哄抬薪水，我想说，我们OfferCome只是站在外面，根据我们自己观察到的数据推算了整个市场。而这些Offer，都是各家公司根据自己的判断，跟薪酬组反复讨论发出来。Offer只是大力推动了我们候选人的薪资水平。然后，再强调一遍，我们谈论的Offer都偏高！都偏高！都偏高！重要事情说三遍，因为我们OfferCome只关注那些优质的人。 4.3. 3、为什么在寒冬季节，这么多公司依然去抢应届生？不是说寒冬嘛？不是都在裁员、抱团取暖吗？为什么？我们在给一些客户的讲座、猎头行业内的讲座时，很详细讲过我们OfferCome的看法：今天不是寒冬，是倒春寒；撇去的是泡沫，优质人才什么时候都不用担心春天冬天。下面简单说几句： 1）、优质人才供需严重不平衡请去我们OfferCome的主页，看我司之前的行业观点。文章最后也贴了一部分，还有几篇没在公众号发。那几篇文章全盘解释了，这些年，优秀的学生的流向是哪，薪水如何。来互联网的人，很少，根本不够这些互联网公司瓜分的。现在不抢，以后更抢不到。 2）、校招生，太便宜了对比社招，校招就跟大白菜一样，太便宜了。15K你能在社招领域招个什么人？25K铁定能招到一个3年工作经验，BAT前30%绩效的研发嘛？与其这样，不如校招抢个自己培养。只不过提前1、2年，把他明年的薪水给了他而已。 3）、 社招太难做了社招中，抢人的创业公司太多，谁都不知道谁会截胡。做校招的时候，AB轮公司抢不过CD轮公司，CD轮不太好抢过 创业三巨头和上市公司。 4）、校招对于团队培养的意义这话题HR亲们都比我理解更为深入，不说了。 4.4. 4、疑问：1）、腾讯明年的腾讯会怎么出价呢？以前除了个别几家，别家都跟腾讯差不多，因此腾讯可以拼品牌。今年变天了，明年呢？光把压力压在HR那，没用阿。 2）、这几家公司的校招情况意味着他们对于市场是如何判断的嘘，你猜。 3）、16年的整体行情今年，幸亏阿里没有大规模下场，否则，今年的校招、社招薪水就会直接崩盘。那问题来了，倒春寒结束后，明年的互联网市场行情会如何？明年的社招、校招行情会如何演变？且待我们OfferCome下文分解。 【转载】：原文链接： http://mp.weixin.qq.com/s?__biz=MjM5OTU2NTcyNA==&amp;mid=400414391&amp;idx=1&amp;sn=3c15366489da50a809cc8a08f5ea72c0&amp;scene=23&amp;srcid=1102dofv4wBvVe908YXblKqv#wechat_redirect OfferCome诚聘高级猎头顾问：30~80%的总薪水包比例，猎头百万年薪从此开始（全）2015年互联网行业薪酬报告——2、3年经验35W将成为标配乱花渐欲迷人眼—2014年互联网薪水分析（全） By OfferCome 转载本文请勿修改（包括文章最后的链接），并注明文章出处，否则必究。]]></content>
      <categories>
        <category>笔试面经</category>
      </categories>
      <tags>
        <tag>校招</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis-Bug源码解析]]></title>
    <url>%2F2015%2F11%2F02%2FMyBatis-Bug%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[0.1. BUG概述MyBatis的这个BUG，出现在条件判断标签中，当试图一个定义为String的属性跟一个英文单词比较时，就会出现bug，具体见下图： 这里我们定义的brandWord是String类型，当我们试图将其与单词 ‘Y’ 比较的时候，就会有下面的异常： 0.2. BUG源码解析初看这个异常的时候，会感觉到很奇怪，为什么最终抛出的 NumberFormatException，即试图将字符串 “Y”解析为Double。为什么Mybatis在解析 if 标签的时候，要把 “Y” 解析为 Double类型呢？ 关于这个问题，网上也有一些资料，但是感觉还是没有说到问题的关键。这些资料大都只是说明了解决方案，如把 ‘Y’改为’1’等，但是这并没有解释为什么会产生 NumberFormatException，即 mybatis 为何要把 “Y” 解析为 Double类型。 带着这个问题，我们来看mybatis解析的源码。还是那句话，源码是最好的学习资料，也是解决问题的最好资料，源码面前，一切没有秘密！ 关于分析bug源码，我们可以看异常抛出的栈，顺着异常栈，由外往里看： 首先我们看到 DefaultSqlSession.selectList方法：1234567891011public List selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement); return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException("Error querying database. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 在 executor.query(ms, wrapCollection(parameter), rowBounds, handler); 执行到BaseExecutor.class执行器中的query方法123456public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameter); CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); return query(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; 在query的方法中看到boundSql，是通过 ms.getBoundSql(parameter);获取的。 再点进去可以看到MappedStatement.class类中的getBoundSql方法123456789101112131415161718192021public BoundSql getBoundSql(Object parameterObject) &#123; BoundSql boundSql = sqlSource.getBoundSql(parameterObject); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings == null || parameterMappings.size() &lt;= 0) &#123; boundSql = new BoundSql(configuration, boundSql.getSql(), parameterMap.getParameterMappings(), parameterObject); &#125; // check for nested result maps in parameter mappings (issue #30) for (ParameterMapping pm : boundSql.getParameterMappings()) &#123; String rmId = pm.getResultMapId(); if (rmId != null) &#123; ResultMap rm = configuration.getResultMap(rmId); if (rm != null) &#123; hasNestedResultMaps |= rm.hasNestedResultMaps(); &#125; &#125; &#125; return boundSql; &#125; 看到其中有sqlSource.getBoundSql(parameterObject); sqlsource是一个接口12345678910/** * * This bean represets the content of a mapped statement read from an XML file * or an annotation. It creates the SQL that will be passed to the database out * of the input parameter received from the user. * */ public interface SqlSource &#123; BoundSql getBoundSql(Object parameterObject); &#125; 类中getBoundSql是一个核心方法，mybatis 也是通过这个方法来为我们构建sql。BoundSql 对象其中保存了经过参数解析，以及判断解析完成sql语句。比如 都回在这一层完成，具体的完成方法往下看，那最常用sqlSource的实现类是DynamicSqlSource.class12345678910111213141516171819202122232425public class DynamicSqlSource implements SqlSource &#123; private Configuration configuration; private SqlNode rootSqlNode; public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123; this.configuration = configuration; this.rootSqlNode = rootSqlNode; &#125; public BoundSql getBoundSql(Object parameterObject) &#123; DynamicContext context = new DynamicContext(configuration, parameterObject); rootSqlNode.apply(context); SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object&gt; entry : context.getBindings().entrySet()) &#123; boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); &#125; return boundSql; &#125; &#125; 核心方法是调用了rootSqlNode.apply(context); rootSqlNode是一个接口123public interface SqlNode &#123; boolean apply(DynamicContext context); &#125; 可以看到类中 rootSqlNode.apply(context); 的方法执行就是一个递归的调用，通过不同的 实现类执行不同的标签，每一次appll是完成了我们&lt;&gt;&lt;/&gt;一次标签中的sql创建，计算出标签中的那一段sql，mybatis通过不停的递归调用，来为我们完成了整个sql的拼接。那我们主要来看IF的实现类IfSqlNode.class1234567891011121314151617181920public class IfSqlNode implements SqlNode &#123; private ExpressionEvaluator evaluator; private String test; private SqlNode contents; public IfSqlNode(SqlNode contents, String test) &#123; this.test = test; this.contents = contents; this.evaluator = new ExpressionEvaluator(); &#125; public boolean apply(DynamicContext context) &#123; if (evaluator.evaluateBoolean(test, context.getBindings())) &#123; contents.apply(context); return true; &#125; return false; &#125; &#125; 可以看到IF的实现中，执行了 if (evaluator.evaluateBoolean(test, context.getBindings())) 如果返回是false的话直接返回，否则继续递归解析IF标签以下的标签，并且返回true。那继续来看 evaluator.evaluateBoolean 的方法123456789public class ExpressionEvaluator &#123; public boolean evaluateBoolean(String expression, Object parameterObject) &#123; Object value = OgnlCache.getValue(expression, parameterObject); if (value instanceof Boolean) return (Boolean) value; if (value instanceof Number) return !new BigDecimal(String.valueOf(value)).equals(BigDecimal.ZERO); return value != null; &#125; 关键点在于 OgnlCache.getValue，我们接着看它的代码：12345678public static Object getValue(String expression, Object root) &#123; try &#123; Map&lt;Object, OgnlClassResolver&gt; context = Ognl.createDefaultContext(root, new OgnlClassResolver()); return Ognl.getValue(parseExpression(expression), context, root); &#125; catch (OgnlException e) &#123; throw new BuilderException("Error evaluating expression '" + expression + "'. Cause: " + e, e); &#125;&#125; 可以看到，在OgnlCache.getValue中调用了Ognl.getValue，那我们接着来看Ognl.getValue。不过这里需要注意的一点是：由前面的异常栈图：我们知道，OgnlCache.getValue紧接着调用的是 org.apache.ibatis.ognl.Ognl 这个类的getValue方法，而这个类的源码，mybatis本身并没有提供，它的源码在ibatis的源码包中。1234567891011public static Object getValue(Object tree, Map context, Object root, Class resultType) throws OgnlException &#123; Object result; OgnlContext ognlContext = (OgnlContext) addDefaultContext(root, context); result = ((Node) tree).getValue(ognlContext, root); if (resultType != null) &#123; result = getTypeConverter(context).convertValue(context, root, null, null, result, resultType); &#125; return result;&#125; 接着又调用了SimpleNode以及ASTEq中的方法（这些方法的调用过程，可以在异常栈里面看到），然后又调用那个了OgnlOps类的equal方法。OgnlOps类对我们的分析比较重要，下面我们结合源码来详细说明。 0.3. OgnlOps类0.3.1. equal方法123456789public static boolean equal(Object v1, Object v2) &#123; if (v1 == null) return v2 == null; if (v1 == v2 || isEqual(v1, v2))//代码说明一 return true; if (v1 instanceof Number &amp;&amp; v2 instanceof Number) return ((Number) v1).doubleValue() == ((Number) v2).doubleValue(); return false;&#125; 说明：代码运行到这里时，我们知道，v1 是String类型，值为 “Y”,而 v2 是 ‘Y’,ognl会认为它是Character类型，而不是String类型。 我们来看详细的代码，显然这里 v1 不等于 null，而且 v1 不等于 v2。看到代码说明一，这里会去执行 isEqual(v1, v2) 方法，我们来看这个方法的源码。 0.3.2. isEqual方法1234567891011121314151617181920212223242526public static boolean isEqual(Object object1, Object object2) &#123; boolean result = false; if (object1 == object2) &#123; result = true; &#125; else &#123; if ((object1 != null) &amp;&amp; (object2 != null)) &#123; if (object1.getClass().isArray() &amp;&amp; object2.getClass().isArray() &amp;&amp; (object2.getClass() == object1.getClass())) &#123; result = (Array.getLength(object1) == Array.getLength(object2)); if (result) &#123; for (int i = 0, icount = Array.getLength(object1); result &amp;&amp; (i &lt; icount); i++) &#123; result = isEqual(Array.get(object1, i), Array.get(object2, i)); &#125; &#125; &#125; else &#123; if ((object1 != null) &amp;&amp; (object2 != null)) &#123; // Check for converted equivalence first, then equals() equivalence //代码说明二 result = (compareWithConversion(object1, object2, true) == 0) || object1.equals(object2); &#125; &#125; &#125; &#125; return result;&#125; 显然，object1 != object2, 而且 (object1 != null) &amp;&amp; (object2 != null)。看到代码说明二，这里又会调用compareWithConversion方法，那我们接着来看源码。 0.3.3. compareWithConversion方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public static int compareWithConversion(Object v1, Object v2, boolean equals) &#123; int result; if (v1 == v2) &#123; result = 0; &#125; else &#123; //代码说明三 int t1 = getNumericType(v1), t2 = getNumericType(v2), type = getNumericType(t1, t2, true); switch (type) &#123; case BIGINT: result = bigIntValue(v1).compareTo(bigIntValue(v2)); break; case BIGDEC: result = bigDecValue(v1).compareTo(bigDecValue(v2)); break; case NONNUMERIC: if ((t1 == NONNUMERIC) &amp;&amp; (t2 == NONNUMERIC)) &#123; if ((v1 == null) || (v2 == null)) &#123; result = (v1 == v2) ? 0 : 1; &#125; else &#123; if (v1.getClass().isAssignableFrom(v2.getClass()) || v2.getClass().isAssignableFrom(v1.getClass())) &#123; if (v1 instanceof Comparable) &#123; result = ((Comparable) v1).compareTo(v2); break; &#125; else &#123; if (equals) &#123; result = v1.equals(v2) ? 0 : 1; break; &#125; &#125; &#125; if (equals) &#123; // Equals comparison between non-numerics that are not of a common // superclass return not equal result = 1; break; &#125; else &#123; throw new IllegalArgumentException("invalid comparison: " + v1.getClass().getName() + " and " + v2.getClass().getName()); &#125; &#125; &#125; // else fall through case FLOAT: case DOUBLE: double dv1 = doubleValue(v1), dv2 = doubleValue(v2); return (dv1 == dv2) ? 0 : ((dv1 &lt; dv2) ? -1 : 1); default: long lv1 = longValue(v1), lv2 = longValue(v2); return (lv1 == lv2) ? 0 : ((lv1 &lt; lv2) ? -1 : 1); &#125; &#125; return result;&#125; 看到代码说明三，这里会对每个对象调用getNumericType方法，还是看源码; 0.3.4. getNumericType方法12345678910111213141516171819public static int getNumericType(Object value) &#123; int result = NONNUMERIC; if (value != null) &#123; Class c = value.getClass(); if (c == Integer.class) return INT; if (c == Double.class) return DOUBLE; if (c == Boolean.class) return BOOL; if (c == Byte.class) return BYTE; if (c == Character.class) return CHAR; if (c == Short.class) return SHORT; if (c == Long.class) return LONG; if (c == Float.class) return FLOAT; if (c == BigInteger.class) return BIGINT; if (c == BigDecimal.class) return BIGDEC; &#125; return NONNUMERIC;&#125; 这个方法的作用，就是根据传进来的对象value，得到它对应的数值型的值，如果value不能转化为数值型，那么返回NONNUMERIC。 好了，我们回到代码说明三：1234//代码说明三int t1 = getNumericType(v1), t2 = getNumericType(v2), type = getNumericType(t1, t2, true); 我们知道，这里的v1是String类型，那么 t1 的值是 NONNUMERIC； v2 是 Character类型，那么 t2 的值是 CHAR。 对应的type值，我们接着看源码：12345678910111213141516171819202122232425262728public static int getNumericType(int t1, int t2, boolean canBeNonNumeric) &#123; if (t1 == t2) return t1; //返回的是这一段代码的值 if (canBeNonNumeric &amp;&amp; (t1 == NONNUMERIC || t2 == NONNUMERIC || t1 == CHAR || t2 == CHAR)) return NONNUMERIC; if (t1 == NONNUMERIC) t1 = DOUBLE; // Try to interpret strings as doubles… if (t2 == NONNUMERIC) t2 = DOUBLE; // Try to interpret strings as doubles… if (t1 &gt;= MIN_REAL_TYPE) &#123; if (t2 &gt;= MIN_REAL_TYPE) return Math.max(t1, t2); if (t2 &lt; INT) return t1; if (t2 == BIGINT) return BIGDEC; return Math.max(DOUBLE, t1); &#125; else if (t2 &gt;= MIN_REAL_TYPE) &#123; if (t1 &lt; INT) return t2; if (t1 == BIGINT) return BIGDEC; return Math.max(DOUBLE, t2); &#125; else return Math.max(t1, t2);&#125; 很明显，type的值为NONNUMERIC。我们从代码说明三接着往下看:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public static int compareWithConversion(Object v1, Object v2, boolean equals) &#123; int result; if (v1 == v2) &#123; result = 0; &#125; else &#123; //代码说明三 int t1 = getNumericType(v1), t2 = getNumericType(v2), type = getNumericType(t1, t2, true); switch (type) &#123; case BIGINT: result = bigIntValue(v1).compareTo(bigIntValue(v2)); break; case BIGDEC: result = bigDecValue(v1).compareTo(bigDecValue(v2)); break; //代码说明四 case NONNUMERIC: //下面这个if直接跳过了 if ((t1 == NONNUMERIC) &amp;&amp; (t2 == NONNUMERIC)) &#123; if ((v1 == null) || (v2 == null)) &#123; result = (v1 == v2) ? 0 : 1; &#125; else &#123; if (v1.getClass().isAssignableFrom(v2.getClass()) || v2.getClass().isAssignableFrom(v1.getClass())) &#123; if (v1 instanceof Comparable) &#123; result = ((Comparable) v1).compareTo(v2); break; &#125; else &#123; if (equals) &#123; result = v1.equals(v2) ? 0 : 1; break; &#125; &#125; &#125; if (equals) &#123; // Equals comparison between non-numerics that are not of a common // superclass return not equal result = 1; break; &#125; else &#123; throw new IllegalArgumentException("invalid comparison: " + v1.getClass().getName() + " and " + v2.getClass().getName()); &#125; &#125; &#125; // else fall through //代码说明五 case FLOAT: case DOUBLE: double dv1 = doubleValue(v1), dv2 = doubleValue(v2); return (dv1 == dv2) ? 0 : ((dv1 &lt; dv2) ? -1 : 1); default: long lv1 = longValue(v1), lv2 = longValue(v2); return (lv1 == lv2) ? 0 : ((lv1 &lt; lv2) ? -1 : 1); &#125; &#125; return result;&#125; 因为type的值是NONNUMERIC，所以执行到代码说明四，这时 t1 的值为 NONNUMERIC，但是 t2 的值为 CHAR，所以 if直接跳过，问题就出现在这。我们知道，在switch case语句中，执行了一个case后，如果没有 break 语句，会接着执行后面的case，也就是说 代码说明五 那里的 case FLOAT,case DOUBLE都会被执行。看到这里，是不是对前面的 “mybatis 为什么要把 “Y” 解析为 Double类型呢”这个问题有点眉目了呢？别着急，还请耐着性子，接着往下看代码！12double dv1 = doubleValue(v1), dv2 = doubleValue(v2); 这里会求 v1（String类型，值为”Y”）的double value，我们来看doubleValue方法的代码： 0.3.5. doubleValue方法123456789101112131415161718192021public static double doubleValue(Object value) throws NumberFormatException &#123; if (value == null) return 0.0; Class c = value.getClass(); if (c.getSuperclass() == Number.class) return ((Number) value).doubleValue(); if (c == Boolean.class) return ((Boolean) value).booleanValue() ? 1 : 0; if (c == Character.class) return ((Character) value).charValue(); //代码说明六 String s = stringValue(value, true); //代码说明七 return (s.length() == 0) ? 0.0 : Double.parseDouble(s); &#125; 因为value是String类型，值为 “Y”,看到代码说明六的stringValue方法 0.3.6. stringValue方法12345678910111213public static String stringValue(Object value, boolean trim) &#123; String result; if (value == null) &#123; result = OgnlRuntime.NULL_STRING; &#125; else &#123; result = value.toString(); if (trim) &#123; result = result.trim(); &#125; &#125; return result;&#125; 很明显，传进来的value是String，调用了 toString方法后，返回的值还是String，即这里返回的是String “Y”。我们接着看代码说明七：12//代码说明七return (s.length() == 0) ? 0.0 : Double.parseDouble(s); 代码看到这里，一切都一目了然了：Double.parseDouble(“Y”) 当然会抛异常。 好了，漫长的源码分析之旅完成了，下面总结下出现这个bug（或者异常）的原因： mybatis之所以会出现这个异常，我觉得主要还是在代码说明四那里： 0.3.7. 异常原因当一个非数值型和一个数值型比较时，mybatis想着把他们都转化成Double来比较，而这个非数值型又不能被解析为Double，这时候，异常就产生了。 所以这也就能解释为什么 下面这种情况可以通过： 当 brandWord = “1”时，字符串 “1”可以被解析为Double，就没有异常了。 总的来说，对于上述的异常，有以下几种解决办法： 0.3.8. 解决办法]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdownpad2注册码]]></title>
    <url>%2F2015%2F11%2F02%2Fmarkdownpad2%E6%B3%A8%E5%86%8C%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1. 示例 2. 邮箱 Soar360@live.com 3. 授权秘钥 GBPduHjWfJU1mZqcPM3BikjYKF6xKhlKIys3i1MU2eJHqWGImDHzWdD6xhMNLGVpbP2M5SN6bnxn2kSE8qHqNY5QaaRxmO3YSMHxlv2EYpjdwLcPwfeTG7kUdnhKE0vVy4RidP6Y2wZ0q74f47fzsZo45JE2hfQBFi2O9Jldjp1mW8HUpTtLA2a5/sQytXJUQl/QKO0jUQY4pa5CCx20sV1ClOTZtAGngSOJtIOFXK599sBr5aIEFyH0K7H4BoNMiiDMnxt1rD8Vb/ikJdhGMMQr0R4B+L3nWU97eaVPTRKfWGDE8/eAgKzpGwrQQoDh+nzX1xoVQ8NAuH+s4UcSeQ==]]></content>
      <categories>
        <category>register-code</category>
      </categories>
      <tags>
        <tag>注册码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BAT等互联网公司面试分享]]></title>
    <url>%2F2015%2F11%2F01%2FBAT%E7%AD%89%E4%BA%92%E8%81%94%E7%BD%91%E5%85%AC%E5%8F%B8%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[1. 综述工作总算是告一段落了，在找工作的过程中，也得到了很多人的帮助，看了很多大神的面经。抽点时间也整理下自己的面经，希望能对找工作的同学有所帮助！ 1.1. 面试及offer概况从今年三月份找实习到最近的校招找工作，笔者前前后后面试的公司不少于20家，这些公司有大型互联网公司，比如百度，腾讯，阿里巴巴，360,美团等，也有初创O2O公司，比如闪电购，微店，挖财等。 笔者参加的这些面试，都没有参加笔试，大多是现场面试或者电话面试。笔试这关，可能对于像我这样经常做项目的同学来说，是一大弱项，所幸参加的面试，都没有笔试！ 算上实习和校招的offer，笔者拿到的offer如下： 360 云事业部 （实习） 阿里巴巴 大数据技术及产品部 （实习） 美团 外卖 （实习） 网易 互联网 闪电购 一号店 北京HZ 百度 地图 笔者参加的这些面试，多数都是与Java相关的岗位。Java这块，也是从大四到现在（研三）一直在学习，也做了很多Java web相关的一些项目。 1.2. offer选择实习时，笔者选择的是阿里巴巴的offer，因为阿里巴巴一直是我理想中的工作的地方！从大四学Java开始，就希望毕业后能够去阿里巴巴工作，去见见心中的偶像马云！能够去实习，当时非常高兴，感觉自己的梦想就要实现！奈何阿里巴巴今年发生大的变故，实习最后，还是没有能够留在阿里巴巴。关于阿里巴巴实习的故事，笔者会在另外一篇博客中专门细说！ 被阿里巴巴“扫地出门”后，那时自己很慌乱，好多实习的同学也都很混乱，然后我们平时交流的实习群就变为了“阿里巴巴实习生下家群”，群里面也有很多HR在发招聘信息，大家集体抱团取暖找工作！后面的那些面试就是从这开始的！ 笔者本身并不想去当北漂，所以一直比较倾向于选择网易互联网（杭州），奈何女票只有美团（北京）的offer，无奈还是要去北漂！不过想想毕竟BAT,毕竟百度地图，也还挺好的，最后选择了百度地图！ 2. 实习面试分享2.1. 3602.1.1. 概述360的面试还是比较轻松的。当时是因为我们实验室跟360有项目合作，360那边希望我们实验室派一个过去实习，所以当时试了下。他们的主要方向也是Java web，正好跟我的学习的方向比较接近。这次面试，总共只有一面技术面，通过以后就是后面HR跟我联系了。 2.1.2. 一面 上来就是自我介绍。跟他聊了下自己的学习，兴趣（技术方面），项目等等 然后就是聊项目，让我挑了一个自己比较熟悉的项目来说。我就给他说了我自己做的一个开源项目，类似于MVC后台框架，然后给他讲自己的设计，架构，前端，后端工作，以及怎么保证可扩展性，重用性，性能等等 然后问了我这个项目中遇到的问题，以及怎么去解决……所以平时做项目的过程中应该多注意去总结 问了我maven是什么东东，平时项目中怎么用 spring的IOC, AOP,以及项目中怎么用spring 数据库的存储引擎，以及区别 差不多就是这些，这次面试基本上还是围绕着Java相关的一些东西来问，重点是我给他讲的那个自己做的开源项目，可能是这点他觉得我还不错吧，一面就这样顺利的通过了。后来还让实验室的师兄（也是在360工作）打听了下，面试结果还不错^_^ 2.2. 阿里巴巴2.2.1. 概述阿里巴巴今年实习生招聘的动作很大，招的人也很多。很多在阿里工作的师兄都在发内推消息，当时也是找了在阿里巴巴工作的同学内推了下，（备注，内推我的是我的大腿以及大恩人，陈俊安！后文还有他！）他给我内推的部门是大数据技术及产品部。阿里巴巴实习招聘期间，我正好在帮实验室导师做项目，当时也没有太多时间复习（项目实在是太忙了），接到面试电话的时候，自己还在写项目的代码。 2.2.2. 一面一天下午，我在实验室写项目代码的时候，接到了来自杭州的电话，当时猜到应该是阿里巴巴的电话面试，于是赶紧找了个安静的地方接电话。 一上来也是自我介绍，还是跟他说了自己的学习，兴趣（技术方面），项目等等 问了下项目概括，然后就跟他说项目…… 问我项目中遇到什么问题，我就跟他说了fastjson和hibernate结合产生的死循环问题，然后自己是怎么去解决的…… 问了我spring注解的@Resource和@Autowire有什么区别…… 问了数据库存储引擎，sql优化，索引等…… 然后问我有什么问题，我就问了他部门做什么，他跟我说了部门的主打产品——生意参谋（很不错的产品，后面实习的时候就是参与到这个项目中的） 最后，他问我对加班怎么看（当时想，你们部门是有多忙，面试还要问加班怎么看，后面去实习的时候发现，要备战双十一，真的很忙！！），我跟他说会尽量在工作时间内把任务做完，如果做不完或者项目需要，加班也无所谓。 一面差不多就是这样，感觉面试官问的问题基本上还是答出来了的，后面就在等消息……等消息……等消息……一直等了半个多月，二面才来…… 2.2.3. 二面二面的时候，比一面更惨，当时因为项目需要，还在外面出差，也是只能丢下手中的工作，找个地方接电话…… 平时看哪些书，怎么学习 MySQL的锁，事务隔离级别 一面回答情况如何 自己有什么规划，喜不喜欢数据产品 也差不多是这样，太多详细的记不清楚了，反正二面没问太多具体的技术细节，后来去实习才知道，面试我的是主管。二面面完没过多久，去官网查看状态也是通过了（阿里面试这点倒是做得挺好的，面试完了以后，可以查到自己的面试结果），然后就等HR面……等HR面……等HR面…… 2.2.4. HR面二面面完，又是等了一个多星期，一直到阿里内推截止的最后一天的晚上，才接到HR的电话面试，想想这次面试过程也是醉了，一直等，一直等，一直等…… 自我介绍，兴趣，爱好 性格的优缺点 问了个实际的问题，项目中跟别人产品矛盾会怎么处理 家乡是哪里的，愿不愿意来杭州工作（当然愿意，阿里可是我理想中的工作） 有没有女朋友，（这个有），会不会影响到自己工作地点的选择，（这个果断说了不会） 差不多就这些，HR面的话，一般是不会有什么问题的 2.2.5. 总结三面面完以后，顺利的拿到了阿里的实习offer，后面也因为这个认识了重邮很多IT小伙伴们，这也算是一大收获吧！！！ 2.3. 美团2.3.1. 概述美团的面试，是直接把简历发给了面试官的邮箱的，一面的那个面试官，人特别好，不止是面试，还给我讲了很多，后面想想最后没有去美团实习，还是有点遗憾的…… 2.3.2. 一面 首先就是自我介绍，跟他说了自己学习的一些东西，还有项目 上来的第一个问题就是集合，而且这块说了很多，问了下常见的集合类，我说了ArrayList，LinkedList，HashMap，HashTable，ConcurrentHashMap以及对应的内部源码，重点问了内部的数据结构，扩容方式，以及并发读写问题还问了TreeSet，TreeMap以及内部的实现原理 GC：这个建议大家去看看周志明的《深入理解Java虚拟机》，看懂这个，应付面试的GC没有问题 Java类加载机制，虚拟机这块，还问了一个问题是，怎么样分配内存，解决并发问题（不在队和方法区分配），这个我没有答上来 并发：问了常用的并发类，原子操作的那几个类AtomicInteger，还有volatile关键字是否能够解决并发问题 前面都是Java基础的问题，聊了很久，后面就是问了些web开发以及数据库的问题：servlet和jsp的区别，struts2的运行流程，平时写struts2的话，是怎么开发的 问了下springMVC，mybatis，我说这些只是了解，平时用的不多，他就没问了（感觉面试官还是挺好的，我说不太会的，他就没问了） 网络这块，问了tcp和udp的区别，Linux问了ln、grep、AWK，问了下这些命令的常见用法 MySQL：问了下性能优化，然后我跟他说了下explain，然后他就问我explain之后的结构，以及每个字段的意义，问了下varchar底层占用的字节长度，还有 int 10这中，后面的10 是什么意义，还有myisam 以及innodb存储引擎的区别，底层索引的数据结构（没答好…） 最后问了下Activiti工作流引擎，http中post和get区别，cookie和session的区别，简单聊了下Hadoop（没问具体的技术细节） 基本上就这些了，感觉面试官还是挺好的，基本上是对着我的简历来问的，我说不太会的东西，他就说不问了，后面还问了下目前拿到的offer总体感觉是，Java的基础知识要深厚，平时要多看看源码，回答问题的时候，自己多说点，多扩展，把自己的技能都秀出来，注意去引导面试官。 3. 校招面试分享3.1. 写在前面本来在阿里实习还是挺愉快的，前面说过阿里一直是自己理想中的“归宿”，所以一直想着，也不需要再去找工作了，就留阿里了！奈何今年阿里实习生遇到重大变故，部门实习生九死一生，我最后还是没有留下来，只好又重新来找工作！ 3.2. 网易互联网3.2.1. 概述说实话，要不是因为女票，我肯定是要留网易的，网易还是挺不错的，虽然不如BAT那么霸气侧漏，但是网易工作相对比较轻松，福利也很好。可是……回归正题，网易的面试也是找的内推，投的也是Java岗位。因为有阿里实习的缘故，再加上自己的也在复习，所以还是比较轻松的拿到了offer。 3.2.2. 初面初面是电话面试，时间很短，十分钟都没到，感觉更像是做个提前的筛选。 Java多线程有哪几种方式 Java里面的transient关键字用处 Java序列化 有什么问题问他 很简单的几个问题，更像是提前筛选 3.2.3. 一面前面的电话面试没过多久，就接到电话说安去网易公司现场面 上来做了自我介绍 着重讲了项目，讲了设计，架构，解决的问题等……大概讲了半个小时 讲设计模式，让我现场画UML类图，装饰者模式的类图，（这个。。。我居然木有画出来。。伤心） HashMap源码，让我改进HashMap。。。（这个我说的答案他不是很满意。。。） ConcurrentHashMap，HashTable Java GC 差不多就是这样，一面没过多久就去二面了 3.2.4. 二面 上来也是自我介绍 集合什么的源码 memcached，结构，一致性hash算法 分布式集群设计管理等 排序算法，快排，堆排等 有什么问题问他 二面完了以后，差不多就中午吃饭了，然后就去网易食堂吃了饭。整体来说，网易食堂的饭菜还是可以的，量很足，而且完全免费，后来听说网易一天管5顿饭，而且都是完全免费的，福利真好！ 3.2.5. HR面吃完午饭差不多就去HR面了，很诧异的是HR居然是个男的！ 自我介绍。。。感觉最多的问题就是自我介绍，所以这个也要好好准备准备 兴趣爱好，关注哪些东西 用过网易哪些产品 平时会做哪些事情，我跟他说平时写些博客分享，然后他就问我分享的动机是什么。。。。 为什么会关注这个新闻，心里是怎么想的，还说我回答问题的时候有点罗嗦。。。。 网易的这个HR真的是。。。一直想探析我的心理活动，我也是醉了，为什么要关注这些新闻，心里是怎么想的，你的动机是什么~~我是来面试的，怎么感觉是进了警察局被审问了？？好吧，好在最后HR面也没有什么问题，拿到了网易互联网的offer 3.3. 闪电购3.3.1. 概述闪电购，一小时社区电商。 闪电购是一个线上便利店平台，其将各分区内的实体店接入，用户就可以基于LBS购买1公里范围的周边便利店商品，1小时免费送达。 闪电购也是自己十分喜欢的一家公司，CEO特别有魅力，虽然最后由于种种原因没有去成，这里还是给他们打个广告！有Android/IOS客户端，欢迎大家使用！方便买零食，水果什么的，一小时送达！ 闪电购是在阿里缩招之后，专门针对“阿里宝宝”举行了专场招聘会，还是很有诚意的，现场还给了很多零食。面试也是当天下午搞定了。 3.3.2. 一面 自我介绍，项目什么的 并发集合，ConcurrentHashMap，CopyOnWriteList等 数据库的索引，优化 数据的锁 3.3.3. 二面一面问了一些技术问题后，没一会就二面了，二面没有问技术问题，都是在说实习过程的一些事，没有什么好参考的，就不写了 3.3.4. 三面没想到三面是CTO和HR的综合面，他们人都挺好的，嘿嘿^_^ Java 的GC Java的类加载机制，这块我跟他说的比较多，详细的源码都跟他说了，所以平时还是多看看源码吧 HR问现在有没有其他公司offer 期望的工资是多少。 关于这个问题，相信有很多人有疑问，说得高，担心因为这个拿不到offer；说的低，又担心如果签了是不是就按照这个低工资来发……大家的担心都是有道理的，这里我说下自己的意见：98%的情况下，不会因为你期望的工资高而不给你offer，所以，按照自己的实际来。如果真的觉得自己很牛，那就大胆的说出你内心期望的工资；如果实力一般或者担心因为工资问题而拿不到offer，这里我教大家一招，“工资这块，我没有太多的想法，参照公司给应届生的平均待遇吧”一般这样说后，HR不会多问了，万一HR就一定想知道具体数额，那你就大声的说出自己的想法，我说过，98%的情况下，不会因为你期望的工资高而不给你offer我当时给HR的回答是，我期望能有BAT的待遇，不知道您们公司能给多少。 3.3.5. 总结总体来说，闪电购还是很好的，拿到offer后，还专门组织我们开了个见面会，公司的创始人等，跟我们一起坐在圆桌上聊天，氛围还是挺好的！最终因为个人原因没能去成！ 3.4. 百度3.4.1. 概述说起百度的面试，就不得不提到我大腿以及恩人陈俊安！！！能拿到百度地图的offer，完全是因为他帮我内推，直接把简历给力他们老大。前面实习的时候，是他帮我内推，然后拿到了阿里的实习offer，后来他去了百度，又帮我内推百度地图，帮我拿到了百度offer，真是人生中的贵人啊！百度的面试，整体还是比较轻松的，也许是因为直推的缘故，没有问题太多的技术细节问题，可能是阿里实习的经历帮了忙吧！ 3.4.2. 一面 Java面向对象的三大特征（封装，继承，多态），就跟他扯了一堆的三大特征，举了例子跟他说明 Java虚拟机的GC（这个扯淡起来就更多了。。。详细的可以看周志明的深入理解Java虚拟机） Java多线程的几种实现方式 MySQL存储引擎，有哪几种，有什么区别 MySQL的hash索引和btree索引 MySQL什么时候会导致索引失效（我感觉就是问sql语句怎么写，导致MySQL不会用到索引） 问了个逻辑题，36匹马，6条跑道，没有计时器，怎么选出前三名 差不多就这些了，大概问了半小时，反正都是些很基础的东西，感觉没有问很深很难的问题 3.4.3. 二面 讲下阿里巴巴实习所做的事，得到的锻炼以及成长，实习过程中，遇到的问题，怎么解决 平时会怎么去学习，学习方法以及学习的东西 讲了一个项目，跟他讲了自己写的一个Java web后台，代码在github上。。 问了下成绩，还让我把成绩单给他发邮件 说了下自己技术上的优势和劣势，非技术方面的优势和劣势 倾向于做服务器后端还是前端还是移动客户端 二面也没有问具体的细节，都是些能扯的东西，不过虽然没有问具体的技术细节，还是比较考技术这块的综合实力的 3.4.4. 总结百度也是我非常喜欢的一家公司，而且又是百度地图部门，允许我打个小广告。百度地图的导航，在岔路口的时候会有图片指导： 怎么样，是不是有图有真相，有了百度地图，以后再也不用担心走错路口了！！希望大家加入我们，把百度地图做的更好！百度地图，有你更精准！ 另外推荐大家用百度浏览器，注册登录后，在线可以积分，用百度搜索可以积分，打开网页也可以积分，积分可以换百度文库和爱奇艺的VIP，还可以在百度糯米上免费买电影票！！欢迎大家来用哦！ 4. 总结花了一下午的时间，把自己还记得起来的面试经过总结了下来！在找工作的过程中，得到过很多人的帮助，尤其是重邮IT小伙伴群里面小伙伴们！所以，也希望自己的这篇面经能够帮助到正在找工作或准备找工作的你！假使哪天你因为看到这篇博客而对你的找工作有了帮助，那就是我的荣幸了！ 最后送给同学们一句话，技术成就梦想，做一个有梦想的程序猿！ 我是王贤稳，我在百度地图等你！]]></content>
      <categories>
        <category>笔试面经</category>
      </categories>
      <tags>
        <tag>笔试</tag>
        <tag>面试</tag>
        <tag>面经</tag>
        <tag>BAT</tag>
      </tags>
  </entry>
</search>